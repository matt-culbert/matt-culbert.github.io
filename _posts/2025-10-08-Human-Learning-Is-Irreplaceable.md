<style> @font-face { font-family: 'TX-02'; src: url('/assets/lib/fonts/TX-02-Regular.woff2') format('woff2'); font-weight: normal; font-style: normal; } body { font-family: 'TX-02', sans-serif; } body{ word-spacing: 4px; }</style> 

What we call "AI" is really just a cancer attacking our ability to learn and we have very little time remaining to carve it out.
# A note

When I began writing this, it was June in Vermont and one of the hottest summers we've had. Some towns reported a heat index of 120 Fahrenheit. Now, it's October, and the temperature outside is 87. In October, in Vermont. To say that climate change is happening before our eyes would not describe our predicament sufficiently, and to ignore the role that the data centers powering these large language models play would be unconscionable. Sam Altman has said that future data centers will each draw more power than all of New York City, all while towns across the country are experiencing brown outs in their power grids and undrinkable tap water where these data centers are constructed. While this post solely focuses on human learning and doesn't address the issues with copyright and plagiarism, the impact to our environment is very real and happening right in front of us.
# Preface

With the rise in large language model (LLM) usage around the world, the people who have historically bemoaned the classic school education system have found new fuel for their argument. These critics argue that LLM's will democratize learning, reduce the burdensome cost for students, and free people up to learn what they want as they want. This is in line with the historical criticism that an education for technical people should not make students waste time on non-technical topics. These detractors will point to people like Steve Jobs, Mark Zuckerberg, and Bill Gates and point out they didn't even finish their elite degrees but turned out all the better for it. Teachers, on the other hand, argue that liberal arts courses and the classroom setting facilitates learning significantly better than one person could accomplish on their own. Teachers point to how students struggled immensely during the pandemic with remote learning and asynchronous classes and how students still struggle today determining what is real. 

I have broken my thoughts on this out into two sections. First, I want to offer a defense of in-person, classroom education that is focused on face to face interactive learning. Then second, I want to talk about the purpose of non-technical and gen ed courses, with a focus on how they can help STEM majors. By the end, I hope to answer these two questions: 
1) `"What is the point of the classroom anymore when I can simply lookup any piece of information or history?"`
   and 
2) `"Why should I care about my gen ed requirements when I'm STEM?"`
# An algorithm shouldn't be your teacher

There's is a valid debate to be had about the overall worthiness of a degree that you can go into life long debt for. College isn't for everyone and we should be more accepting of that. Trade schools are a valid alternative for secondary education and there are a wealth of jobs that don't even require that. There's also plenty of free courses offered by top schools. Harvard has their CS50 course, intro to computer science, online for anyone to take at a self paced speed.

There's also groups who want to even up self learning and higher ed, their goal being to offer people the same opportunities but without the strict classroom rigor and mountains of debt. UnCollege is one such group whose aim is to democratize learning and the NYTimes wrote a piece on them in 2012.

>([NYTimes](https://www.nytimes.com/2012/12/02/fashion/saying-no-to-college.html))
>The idea that a college diploma is an all-but-mandatory ticket to a successful career is showing fissures. Feeling squeezed by a sagging job market and mounting student debt, a groundswell of university-age heretics are pledging allegiance to new groups like UnCollege, dedicated to “hacking” higher education. Inspired by billionaire role models, and empowered by online college courses, they consider themselves a D.I.Y. vanguard, committed to changing the perception of dropping out from a personal failure to a sensible option, at least for a certain breed of risk-embracing maverick.
>
>Risky? Perhaps. But it worked for the founders of Twitter, Tumblr and a little company known as Apple.

The NYTimes, in their coverage of UnCollege, leans heavily on a comparison to now billionaire college dropouts. 

This idea of democratizing education has found a new champion lately in Silicon Valley billionaires like Sam Altman, the founder and CEO of OpenAI.

>(The Ezra Klein Show)
>EZRA KLEIN: \[...] So how does building A.I. allow for a Moore’s law in health, education, and housing?
>
>SAM ALTMAN: \[...] I think if A.I. and policy can work in harmony, or let’s even say technology and policy can work in harmony, we can get to a much better outcome much more quickly than we otherwise might. And I think — again, to stick on the example of higher ed — I have never seen more energy from the consumers, the people who are going to college or thinking about going to college soon, saying, what am I really doing here and maybe there’s some much better way. So that’s the kind of pressure where I think things can change super quickly. The prestige of a degree from a top college probably doesn’t go away that quickly, but maybe a lot of the rest of it does.

Sam indicated that while the "prestige" of a top school won't be quickly affected, the comparative quality of education vs cost may be seen as not worth it when viewed against an alternative provided by advancements in technology. This is the "Moore's law for everything" that Sam is talking about. But this idea of democratizing education for the masses hinges on the wrong assumption. The access to information isn't why people attend college, it's the guidance and mentorship from trusted advisors. That's something an algorithm will never be able to replace. But why?

These LLM's like OpenAI's are touted as "AI" but really it's nothing more than a long algorithm to guess at the next best word to follow a sentence. They work by teams coalescing billions of samples of writing into a database that the LLM can "learn" predictive patterns from. The LLM uses this database of reference material to determine how to generate responses to any given input, the responses being what the algorithm statistically thinks is the most likely correct follow-up to the prompt. In doing so, there is a problem - the LLM is limited by what data it has available. An initial assumption by you, the reader, may be that to fix this the designers can allow the LLM to scrape the internet for everything it can find. However these LLM's do not have human reasoning that we as consumers utilize to identify when something is false. If the LLM is trained on data, it is assumed to be true data unless categorically told this is false. 

This leads to another problem - the training data set used for generating a derivative response will reflect the bias of the design team. Since an LLM can only ever "know" what it is given, there is a reliance on the team designing it to choose a robust training set and to constantly update it with new information while removing out dated information. This ability to update information is only as strong as the team supporting it. Professors at colleges and universities devote their lives to learning about a given subject and staying up to date with tiny nuances, trends, and developments specific to their fields. It's impossible for a team of engineers to be able to do this at the scale required in an LLM.

The last problem - when a model is prompted about unknown information, or information otherwise not clearly in its training set, the model is liable to hallucinate a response using what it can reference to sound correct. Users are not informed of these massive gaps and liabilities in the LLM output, but instead companies like OpenAI push for them to be used as a replacement to traditional education. This problem of hallucinated output and users not understanding the risk has gotten so bad in schools that teachers are faced with students using quotes from books that don't exist. The students will just believe their LLM output to be correct and parrot it verbatim.

>(Kate Conroy to 404 Media)
>I learned that at least as of this time last year, on questions of literary analysis, ChatGPT will make up quotes that sound like they go with the themes of the books, and it can’t get page numbers correct. Luckily I have taught the same books for many years in a row and can instantly identify an incorrect quote and an incorrect page number. There’s something a little bit satisfying about handing a student back their essay and saying, “I can’t find this quote in the book, can you find it for me?” Meanwhile I know perfectly well they cannot.

I don't blame people for being dissatisfied at the astronomical cost of education and the elitism within institutions, but pushing for an algorithm to replace schools *clearly* doesn't solve the problem of education accessibility and instead exacerbates it. There's also a valid discussion to be had about if college is for you or your child. It's not for everyone and those who make the choice to not pursue it are valid. But be wary of a wolf in sheep's clothing. Billionaires do not have peoples best interests in mind so when you find them saying it's ok to drop out or not go to college, and instead use their technology as a replacement, ask why.
# We can't remove the human portion of interactions, so learning to navigate humans is critical

Detractors have often boiled the non-STEM school experience down to gender studies degrees or feminism in literature and then dismissed these subjects outright. Setting aside that when compared to a STEM [degree like IT](https://www.bls.gov/ooh/computer-and-information-technology/computer-support-specialists.htm) cultural studies degrees have a [higher median salary](https://www.bls.gov/ooh/field-of-degree/culture-and-gender-studies/culture-and-gender-studies-field-of-degree.htm) and more job opportunities, non-STEM courses play a very important role in preparing people for the world. The courses can vary from challenging prior held beliefs students may hold, to teaching students the concept of how to learn, and to how to incorporate diverse information from conflicting backgrounds. 

>([Reference](https://hipatiapress.com/hpjournals/index.php/ijep/article/view/3940/pdf))
>(A) liberal arts education enables students to acquire communication skills required for efficiently interacting with citizens from diverse societies and cultures

But students in STEM often think that these courses are only a distraction from what they went to school to study.

>([The College Voice](https://thecollegevoice.org/2013/02/18/an-argument-against-gen-eds/))
>General Education requirements are an unnecessary burden on our school’s students. Finishing that last, pesky Gen Ed is something students celebrate. Yes, exploring other fields might give them valuable insight into their own areas of specialty. However, Gen Eds are only piling extra work on students who would rather be focusing on what they can learn within their chosen major.

Students have a lot of difficulty translating the general ed classes they take into their chosen specialization. These courses often focus on the human element and, in contrast to structured systems, you have to navigate human issues like personal feelings and opinion that affect how a problem is even described. Learning to navigate these human problems isn't easy. It takes a lot of patience and trial and error to figure out the right questions to ask at the right time. But this is what liberal arts courses want to teach you. Courses are designed to teach students how to have disagreements with others in a way that both sides are understood. However, this aspect is disregarded by critics. From the same article about UnCollege, the Times also included a snippet from an anonymous "Professor X" which I found especially relevant to this.

>Last year, an anonymous academic who called himself Professor X, published “In the Basement of the Ivory Tower,” which argued that future police officers and nurses need not be force-fed Shakespeare.

There's a couple issues with this idea that certain professions shouldn't be "force-fed Shakespeare." First and foremost, police officers aren't required to have a college degree so they're unlikely to be in this scenario. The second issue with this claim is actually a product of the first issue: the courses that are taught would actually *help* in high stress scenarios where there's an expectation to understand fast. But this aspect of non-STEM is willfully disregarded. Not only is it disregarded, but colleges may no longer even be able to get students to the level of Professor X's strawman. Colleges are introducing courses to [teach students how to sit and read lengthy novels](https://www.thetimes.com/uk/education/article/universities-teaching-literature-students-how-to-cope-with-long-novels-8bwgscp7k). If these attacks on education continue, I am pessimistic that classes will have time to teach Shakespeare anymore.

# Closing remarks
Did you see [the report from MIT](https://arxiv.org/pdf/2506.08872v1) that using an LLM assistant to write papers makes you dumber? To say that I despise LLM's isn't enough. They're pitched to children and adults alike as a miracle cure-all for your learning needs but the harm they cause to our learning and long term abilities like memory and understanding is enormous. I saw someone start a book club and say that members can just ask ChatGPT to summarize it. What is even the purpose at that point? There's no appreciation for literature as the authors writing and intention just gets boiled down into a soup that your atrophied brains can absorb. The share of US adults reading below a sixth grade level and the overall adult illiteracy rate was at [a staggering 54% and 21% respectively](https://www.newsweek.com/map-reveals-us-adult-literacy-rates-state-2010175) in 2024. Expect that number to bloom uncontrollably as more and more people give up their want and ability to learn and understand for the slight convenience of summarizing everything. 
